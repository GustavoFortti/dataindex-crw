{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>back_word</th>\n",
       "      <th>location</th>\n",
       "      <th>subject</th>\n",
       "      <th>row_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3fc276b6</td>\n",
       "      <td>real</td>\n",
       "      <td>36</td>\n",
       "      <td>creatina</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3fc276b6</td>\n",
       "      <td>para</td>\n",
       "      <td>36</td>\n",
       "      <td>creatina</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3fc276b6</td>\n",
       "      <td>ganhos</td>\n",
       "      <td>36</td>\n",
       "      <td>creatina</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3fc276b6</td>\n",
       "      <td>reais</td>\n",
       "      <td>36</td>\n",
       "      <td>creatina</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3fc276b6</td>\n",
       "      <td>a</td>\n",
       "      <td>36</td>\n",
       "      <td>creatina</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ref back_word  location   subject  row_number\n",
       "0  3fc276b6      real        36  creatina           1\n",
       "1  3fc276b6      para        36  creatina           2\n",
       "2  3fc276b6    ganhos        36  creatina           3\n",
       "3  3fc276b6     reais        36  creatina           4\n",
       "4  3fc276b6         a        36  creatina           5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from functions import get_all_origins, find_pattern_for_quantity, convert_to_grams, relation_qnt_preco, remove_spaces, clean_text\n",
    "import re\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "back_words_contained_in_the_title = \"back_words_contained_in_the_title\"\n",
    "back_words_not_contained_in_the_title = \"back_words_not_contained_in_the_title\"\n",
    "back_words_without_title = \"back_words_without_title\"\n",
    "\n",
    "# df = pd.read_csv(\"./back_words.csv\")\n",
    "\n",
    "def analisys(file, palavras):\n",
    "    df = get_all_origins(file)\n",
    "    df['back_word'] = df['back_word'].str.replace('\\d+', '', regex=True)\n",
    "    df = df[df['back_word'].str.contains('[a-zA-Z]', regex=True)]\n",
    "    print(df.info())\n",
    "\n",
    "    grouped_df = df.groupby(['back_word', \"row_number\"]).size().reset_index(name='count')\n",
    "    grouped_df = grouped_df[grouped_df['back_word'].isin(palavras)]\n",
    "    print(grouped_df.sort_values(\"count\", ascending=False))\n",
    "\n",
    "df = get_all_origins(back_words_contained_in_the_title)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62bfa739",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 100\u001b[0m\n\u001b[1;32m     98\u001b[0m df_contained_in_the_title \u001b[38;5;241m=\u001b[39m get_all_origins(back_words_contained_in_the_title)\n\u001b[1;32m     99\u001b[0m df_not_contained_in_the_title \u001b[38;5;241m=\u001b[39m get_all_origins(back_words_not_contained_in_the_title)\n\u001b[0;32m--> 100\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_dataframes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_contained_in_the_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_not_contained_in_the_title\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m df\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    103\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./back_words.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[5], line 80\u001b[0m, in \u001b[0;36mprocess_dataframes\u001b[0;34m(df_contained, df_not_contained)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_dataframes\u001b[39m(df_contained, df_not_contained):\n\u001b[1;32m     79\u001b[0m     terms_1 \u001b[38;5;241m=\u001b[39m gen_all_terms(df_contained)\n\u001b[0;32m---> 80\u001b[0m     df_contained \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_contained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterms_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     df_contained[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     83\u001b[0m     terms_2 \u001b[38;5;241m=\u001b[39m gen_all_terms(df_not_contained)\n",
      "Cell \u001b[0;32mIn[5], line 73\u001b[0m, in \u001b[0;36mpreprocess_dataframe\u001b[0;34m(df, terms)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_dataframe\u001b[39m(df, terms):\n\u001b[1;32m     72\u001b[0m     df \u001b[38;5;241m=\u001b[39m preprocess_numbers(df)\n\u001b[0;32m---> 73\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpivot_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     df \u001b[38;5;241m=\u001b[39m shift_words(df)\n\u001b[1;32m     75\u001b[0m     df \u001b[38;5;241m=\u001b[39m normalize_terms(df, dataset, terms)\n",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m, in \u001b[0;36mpivot_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     30\u001b[0m pivot_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback_words\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pivot_df[[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x\u001b[38;5;241m.\u001b[39mdropna()), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pivot_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback_words\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback_words\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback_word_1, back_word_2, back_word_3, back_word_4, back_word_5\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m---> 32\u001b[0m \u001b[43mresult_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mback_word_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mback_word_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mback_word_3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mback_word_4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mback_word_5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback_word_1, back_word_2, back_word_3, back_word_4, back_word_5\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     33\u001b[0m result_df \u001b[38;5;241m=\u001b[39m result_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback_word_1, back_word_2, back_word_3, back_word_4, back_word_5\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_df\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4079\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4077\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_frame(key, value)\n\u001b[1;32m   4078\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[0;32m-> 4079\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4080\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   4081\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4121\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4117\u001b[0m     \u001b[38;5;66;03m# Note: unlike self.iloc[:, indexer] = value, this will\u001b[39;00m\n\u001b[1;32m   4118\u001b[0m     \u001b[38;5;66;03m#  never try to overwrite values inplace\u001b[39;00m\n\u001b[1;32m   4120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m-> 4121\u001b[0m         \u001b[43mcheck_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4122\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(key, value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m   4123\u001b[0m             \u001b[38;5;28mself\u001b[39m[k1] \u001b[38;5;241m=\u001b[39m value[k2]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexers/utils.py:390\u001b[0m, in \u001b[0;36mcheck_key_length\u001b[0;34m(columns, key, value)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(key):\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns must be same length as key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;66;03m# Missing keys in columns are represented as -1\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(key)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_brazilian_portuguese_words():\n",
    "    personal_pronouns = [\"Eu\", \"Tu\", \"Ele\", \"Ela\", \"Nós\", \"Vós\", \"Eles\", \"Elas\", \"Mim\", \"Ti\", \"Si\", \"Consigo\"]\n",
    "    oblique_pronouns = [\"Me\", \"Te\", \"Se\", \"Nos\", \"Vos\", \"O\", \"A\", \"Lhe\", \"Os\", \"As\", \"Nos\", \"Vos\", \"Se\", \"Convosco\", \"Lhes\", \"Contigo\"]\n",
    "    demonstrative_pronouns = [\"Este\", \"Esse\", \"Aquele\", \"Esta\", \"Essa\", \"Aquela\", \"Isto\", \"Isso\", \"Aquilo\", \"Estes\", \"Esses\", \"Aqueles\", \"Estas\", \"Essas\", \"Aquelas\", \"Iste\"]\n",
    "    possessive_pronouns = [\"Meu\", \"Teu\", \"Seu\", \"Nosso\", \"Vosso\", \"Seu\", \"Minha\", \"Tua\", \"Sua\", \"Nossa\", \"Vossa\", \"Sua\", \"Meus\", \"Teus\", \"Seus\", \"Nossos\", \"Vossos\", \"Minhas\", \"Tuas\", \"Suas\", \"Nossas\", \"Vossas\"]\n",
    "    indefinite_pronouns = [\"Alguém\", \"Ninguém\", \"Todo\", \"Algum\", \"Nenhum\", \"Outro\", \"Muito\", \"Pouco\", \"Tanto\", \"Cada\", \"Algo\", \"Tudo\", \"Nada\", \"Cada um\", \"Qualquer\", \"Poucos\", \"Muitos\", \"Vários\", \"Outrem\"]\n",
    "    relative_pronouns = [\"Que\", \"Qual\", \"Quem\", \"Onde\", \"Cujo\", \"O qual\", \"Cuja\", \"Quanto\"]\n",
    "    interrogative_pronouns = [\"Quem\", \"O que\", \"Qual\", \"Quanto\", \"Onde\", \"Quando\", \"Como\", \"Por que\", \"Qualquer coisa\", \"Quanto a\"]\n",
    "    prepositions = [\"A\", \"Ante\", \"Até\", \"Após\", \"Com\", \"Contra\", \"De\", \"Desde\", \"Em\", \"Entre\", \"Para\", \"Por\", \"Perante\", \"Sem\", \"Sob\", \"Sobre\", \"Trás\", \"Conforme\", \"Contudo\", \"Durante\", \"Exceto\", \"Mediant\", \"Menos\", \"Salvo\", \"Segundo\", \"Visto\"]\n",
    "    BRAZIL_PRONOUNS = personal_pronouns + oblique_pronouns + demonstrative_pronouns + possessive_pronouns + indefinite_pronouns + relative_pronouns + interrogative_pronouns + prepositions\n",
    "\n",
    "    conectores = ['e', 'ou', 'nem', 'mas', 'porque', 'como', 'apesar', 'além', 'entretanto', 'porém', 'todavia', 'logo', 'portanto', 'assim', 'contudo', 'embora', 'ainda', 'também', 'quer', 'seja', 'isto', 'aquilo']\n",
    "\n",
    "    palavra = [palavra.lower() for palavra in BRAZIL_PRONOUNS + conectores]\n",
    "    conjugacoes = np.genfromtxt('conjugações.txt', dtype=str)\n",
    "    dicionario = np.genfromtxt('palavras.txt', dtype=str)\n",
    "    \n",
    "    return np.unique(np.concatenate((palavra, conjugacoes, dicionario)))\n",
    "\n",
    "def preprocess_numbers(df):\n",
    "    df['back_word'] = df['back_word'].str.replace('\\d+', '', regex=True)\n",
    "    df = df[df['back_word'].str.contains('[a-zA-Z]', regex=True)]\n",
    "    return df\n",
    "\n",
    "def pivot_data(df):\n",
    "    pivot_df = df.pivot_table(index=['ref', 'location', 'subject'], columns='row_number', values='back_word', aggfunc=lambda x: ' '.join(x)).reset_index()\n",
    "    pivot_df['back_words'] = pivot_df[[1, 2, 3, 4, 5]].apply(lambda x: ','.join(x.dropna()), axis=1)\n",
    "    result_df = pivot_df[['ref', 'back_words', 'location', 'subject']].rename(columns={'back_words': 'back_word_1, back_word_2, back_word_3, back_word_4, back_word_5'})\n",
    "    result_df[['back_word_1', 'back_word_2', 'back_word_3', 'back_word_4', 'back_word_5']] = result_df['back_word_1, back_word_2, back_word_3, back_word_4, back_word_5'].str.split(',', expand=True, n=2)\n",
    "    result_df = result_df.drop(columns=['back_word_1, back_word_2, back_word_3, back_word_4, back_word_5'])\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def shift_words(df):\n",
    "    def shift_words_to_right(row):\n",
    "        words = [row['back_word_1'], row['back_word_2'], row['back_word_3'], row['back_word_4'], row['back_word_5']]\n",
    "        filtered_words = [w for w in words if w is not None]\n",
    "        none_filled = [None] * (3 - len(filtered_words))\n",
    "        return none_filled + filtered_words\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        new_words = shift_words_to_right(row)\n",
    "        df.at[index, 'back_word_1'], df.at[index, 'back_word_2'], df.at[index, 'back_word_3'], df.at[index, 'back_word_4'], df.at[index, 'back_word_5'] = new_words[0], new_words[1], new_words[2], new_words[3], new_words[4]\n",
    "    return df\n",
    "\n",
    "def normalize_terms(df, dataset, terms):\n",
    "    mask = np.isin(dataset, terms)\n",
    "    filtered_data_set = dataset[mask]\n",
    "    filtered_data_set = np.insert(filtered_data_set, 0, \"0\")\n",
    "\n",
    "    for col in [\"back_word_1\", \"back_word_2\", \"back_word_3\", \"back_word_4\", \"back_word_5\"]:\n",
    "        df[col] = df[col].apply(lambda x: np.where(filtered_data_set == x)[0][0] if x in filtered_data_set else x)\n",
    "        df[col] = df[col].where(~df[col].isnull(), other=\"0\")\n",
    "\n",
    "    df = df.astype(str)\n",
    "    return df\n",
    "\n",
    "def gen_all_terms(df):\n",
    "    terms = list(df['back_word'].values)\n",
    "    return np.array(list(set(terms)))\n",
    "\n",
    "def get_all_terms_from_dfs(dfs):\n",
    "    terms = []\n",
    "    for df in dfs:\n",
    "        terms.extend(list(df['back_word'].values))\n",
    "    return np.array(list(set(terms)))\n",
    "\n",
    "def preprocess_dataframe(df, terms):\n",
    "    df = preprocess_numbers(df)\n",
    "    df = pivot_data(df)\n",
    "    df = shift_words(df)\n",
    "    df = normalize_terms(df, dataset, terms)\n",
    "    return df\n",
    "\n",
    "def process_dataframes(df_contained, df_not_contained):\n",
    "    terms_1 = gen_all_terms(df_contained)\n",
    "    df_contained = preprocess_dataframe(df_contained, terms_1)\n",
    "    df_contained['title'] = 1\n",
    "\n",
    "    terms_2 = gen_all_terms(df_not_contained)\n",
    "    df_not_contained = preprocess_dataframe(df_not_contained, terms_2)\n",
    "    df_not_contained['title'] = 0\n",
    "\n",
    "    df = pd.concat([df_contained, df_not_contained])\n",
    "\n",
    "    df[\"location\"] = df[\"location\"].astype(int)\n",
    "    df[\"title\"] = df[\"title\"].astype(str)\n",
    "\n",
    "    combined_terms = np.concatenate((terms_1, terms_2))\n",
    "    terms = np.unique(combined_terms)\n",
    "    df = normalize_terms(df, dataset, terms)\n",
    "    return df\n",
    "\n",
    "dataset = load_brazilian_portuguese_words()\n",
    "df_contained_in_the_title = get_all_origins(back_words_contained_in_the_title)\n",
    "df_not_contained_in_the_title = get_all_origins(back_words_not_contained_in_the_title)\n",
    "df = process_dataframes(df_contained_in_the_title, df_not_contained_in_the_title)\n",
    "\n",
    "df.info()\n",
    "df.to_csv(\"./back_words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4352425f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69372 entries, 0 to 69371\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   location     69372 non-null  int64 \n",
      " 1   back_word_2  69372 non-null  object\n",
      " 2   back_word_3  69347 non-null  object\n",
      " 3   target       69372 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>back_word_2</th>\n",
       "      <th>back_word_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243</td>\n",
       "      <td>214</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2222</td>\n",
       "      <td>2628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>651</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location back_word_2 back_word_3 target\n",
       "0       243         214         824      1\n",
       "1         9           0        1791      1\n",
       "2        11        2222        2628      1\n",
       "3        64         651         160      1\n",
       "4       134           b           1      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./back_words.csv\")\n",
    "df.head()\n",
    "\n",
    "df[\"ref\"] = df[\"ref\"].astype(str)\n",
    "df[\"location\"] = df[\"location\"].astype(int)\n",
    "df[\"target\"] = df[\"title\"].astype(str)\n",
    "\n",
    "df = df.drop(columns=['title', 'ref', 'subject', 'back_word_1'])\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ca43cd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.9511280905355727\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in ['back_word_1', 'back_word_2', 'back_word_3', 'target']:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Separar em X (recursos) e y (alvo)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Treinar o modelo Decision Tree\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prever no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3b7ee99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Acurácia: 0.94838895696677\n",
      "Random Forest Acurácia: 0.9462985655589995\n",
      "XGBoost Acurácia: 0.9332516398760181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Extra Trees': 0.94838895696677,\n",
       " 'Random Forest': 0.9462985655589995,\n",
       " 'XGBoost': 0.9332516398760181}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    # Definir os modelos\n",
    "    models = {\n",
    "        'Extra Trees': ExtraTreesClassifier(random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(random_state=42),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "        'DecisionTree': DecisionTreeClassifier(random_state=42)\n",
    "    }\n",
    "\n",
    "    # Treinar cada modelo e avaliar a acurácia\n",
    "    accuracies = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies[name] = accuracy\n",
    "        print(f'{name} Acurácia: {accuracy}')\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "train_and_evaluate_models(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
