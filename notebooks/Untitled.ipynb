{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from functions import get_all_origins, find_pattern_for_quantity, convert_to_grams, relation_qnt_preco, remove_spaces, clean_text\n",
    "import re\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "back_words_contained_in_the_title = \"back_words_contained_in_the_title\"\n",
    "back_words_not_contained_in_the_title = \"back_words_not_contained_in_the_title\"\n",
    "back_words_without_title = \"back_words_without_title\"\n",
    "\n",
    "# df = pd.read_csv(\"./back_words.csv\")\n",
    "\n",
    "def analisys(file, palavras):\n",
    "    df = get_all_origins(file)\n",
    "    df['back_word'] = df['back_word'].str.replace('\\d+', '', regex=True)\n",
    "    df = df[df['back_word'].str.contains('[a-zA-Z]', regex=True)]\n",
    "    print(df.info())\n",
    "\n",
    "    grouped_df = df.groupby(['back_word', \"row_number\"]).size().reset_index(name='count')\n",
    "    grouped_df = grouped_df[grouped_df['back_word'].isin(palavras)]\n",
    "    print(grouped_df.sort_values(\"count\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "62bfa739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 69362 entries, 0 to 45758\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ref          69362 non-null  object\n",
      " 1   location     69362 non-null  object\n",
      " 2   subject      69362 non-null  object\n",
      " 3   back_word_1  69362 non-null  object\n",
      " 4   back_word_2  69362 non-null  object\n",
      " 5   back_word_3  69362 non-null  object\n",
      " 6   title        69362 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_brazilian_portuguese_words():\n",
    "    personal_pronouns = [\"Eu\", \"Tu\", \"Ele\", \"Ela\", \"Nós\", \"Vós\", \"Eles\", \"Elas\", \"Mim\", \"Ti\", \"Si\", \"Consigo\"]\n",
    "    oblique_pronouns = [\"Me\", \"Te\", \"Se\", \"Nos\", \"Vos\", \"O\", \"A\", \"Lhe\", \"Os\", \"As\", \"Nos\", \"Vos\", \"Se\", \"Convosco\", \"Lhes\", \"Contigo\"]\n",
    "    demonstrative_pronouns = [\"Este\", \"Esse\", \"Aquele\", \"Esta\", \"Essa\", \"Aquela\", \"Isto\", \"Isso\", \"Aquilo\", \"Estes\", \"Esses\", \"Aqueles\", \"Estas\", \"Essas\", \"Aquelas\", \"Iste\"]\n",
    "    possessive_pronouns = [\"Meu\", \"Teu\", \"Seu\", \"Nosso\", \"Vosso\", \"Seu\", \"Minha\", \"Tua\", \"Sua\", \"Nossa\", \"Vossa\", \"Sua\", \"Meus\", \"Teus\", \"Seus\", \"Nossos\", \"Vossos\", \"Minhas\", \"Tuas\", \"Suas\", \"Nossas\", \"Vossas\"]\n",
    "    indefinite_pronouns = [\"Alguém\", \"Ninguém\", \"Todo\", \"Algum\", \"Nenhum\", \"Outro\", \"Muito\", \"Pouco\", \"Tanto\", \"Cada\", \"Algo\", \"Tudo\", \"Nada\", \"Cada um\", \"Qualquer\", \"Poucos\", \"Muitos\", \"Vários\", \"Outrem\"]\n",
    "    relative_pronouns = [\"Que\", \"Qual\", \"Quem\", \"Onde\", \"Cujo\", \"O qual\", \"Cuja\", \"Quanto\"]\n",
    "    interrogative_pronouns = [\"Quem\", \"O que\", \"Qual\", \"Quanto\", \"Onde\", \"Quando\", \"Como\", \"Por que\", \"Qualquer coisa\", \"Quanto a\"]\n",
    "    prepositions = [\"A\", \"Ante\", \"Até\", \"Após\", \"Com\", \"Contra\", \"De\", \"Desde\", \"Em\", \"Entre\", \"Para\", \"Por\", \"Perante\", \"Sem\", \"Sob\", \"Sobre\", \"Trás\", \"Conforme\", \"Contudo\", \"Durante\", \"Exceto\", \"Mediant\", \"Menos\", \"Salvo\", \"Segundo\", \"Visto\"]\n",
    "    BRAZIL_PRONOUNS = personal_pronouns + oblique_pronouns + demonstrative_pronouns + possessive_pronouns + indefinite_pronouns + relative_pronouns + interrogative_pronouns + prepositions\n",
    "\n",
    "    conectores = ['e', 'ou', 'nem', 'mas', 'porque', 'como', 'apesar', 'além', 'entretanto', 'porém', 'todavia', 'logo', 'portanto', 'assim', 'contudo', 'embora', 'ainda', 'também', 'quer', 'seja', 'isto', 'aquilo']\n",
    "\n",
    "    palavra = [palavra.lower() for palavra in BRAZIL_PRONOUNS + conectores]\n",
    "    conjugacoes = np.genfromtxt('conjugações.txt', dtype=str)\n",
    "    dicionario = np.genfromtxt('palavras.txt', dtype=str)\n",
    "    \n",
    "    return np.unique(np.concatenate((palavra, conjugacoes, dicionario)))\n",
    "\n",
    "def preprocess_numbers(df):\n",
    "    df['back_word'] = df['back_word'].str.replace('\\d+', '', regex=True)\n",
    "    df = df[df['back_word'].str.contains('[a-zA-Z]', regex=True)]\n",
    "    return df\n",
    "\n",
    "def pivot_data(df):\n",
    "    pivot_df = df.pivot_table(index=['ref', 'location', 'subject'], columns='row_number', values='back_word', aggfunc=lambda x: ' '.join(x)).reset_index()\n",
    "    pivot_df['back_words'] = pivot_df[[1, 2, 3]].apply(lambda x: ','.join(x.dropna()), axis=1)\n",
    "    result_df = pivot_df[['ref', 'back_words', 'location', 'subject']].rename(columns={'back_words': 'back_word_1, back_word_2, back_word_3'})\n",
    "    result_df[['back_word_1', 'back_word_2', 'back_word_3']] = result_df['back_word_1, back_word_2, back_word_3'].str.split(',', expand=True, n=2)\n",
    "    result_df = result_df.drop(columns=['back_word_1, back_word_2, back_word_3'])\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def shift_words(df):\n",
    "    def shift_words_to_right(row):\n",
    "        words = [row['back_word_1'], row['back_word_2'], row['back_word_3']]\n",
    "        filtered_words = [w for w in words if w is not None]\n",
    "        none_filled = [None] * (3 - len(filtered_words))\n",
    "        return none_filled + filtered_words\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        new_words = shift_words_to_right(row)\n",
    "        df.at[index, 'back_word_1'], df.at[index, 'back_word_2'], df.at[index, 'back_word_3'] = new_words[0], new_words[1], new_words[2]\n",
    "    return df\n",
    "\n",
    "def normalize_terms(df, dataset, terms):\n",
    "    mask = np.isin(dataset, terms)\n",
    "    filtered_data_set = dataset[mask]\n",
    "    filtered_data_set = np.insert(filtered_data_set, 0, \"0\")\n",
    "\n",
    "    for col in [\"back_word_1\", \"back_word_2\", \"back_word_3\"]:\n",
    "        df[col] = df[col].apply(lambda x: np.where(filtered_data_set == x)[0][0] if x in filtered_data_set else x)\n",
    "        df[col] = df[col].where(~df[col].isnull(), other=\"0\")\n",
    "\n",
    "    df = df.astype(str)\n",
    "    return df\n",
    "\n",
    "def gen_all_terms(df):\n",
    "    terms = list(df['back_word'].values)\n",
    "    return np.array(list(set(terms)))\n",
    "\n",
    "def get_all_terms_from_dfs(dfs):\n",
    "    terms = []\n",
    "    for df in dfs:\n",
    "        terms.extend(list(df['back_word'].values))\n",
    "    return np.array(list(set(terms)))\n",
    "\n",
    "def preprocess_dataframe(df, terms):\n",
    "    df = preprocess_numbers(df)\n",
    "    df = pivot_data(df)\n",
    "    df = shift_words(df)\n",
    "    df = normalize_terms(df, dataset, terms)\n",
    "    return df\n",
    "\n",
    "def process_dataframes(df_contained, df_not_contained):\n",
    "    terms_1 = gen_all_terms(df_contained)\n",
    "    df_contained = preprocess_dataframe(df_contained, terms_1)\n",
    "    df_contained['title'] = 1\n",
    "\n",
    "    terms_2 = gen_all_terms(df_not_contained)\n",
    "    df_not_contained = preprocess_dataframe(df_not_contained, terms_2)\n",
    "    df_not_contained['title'] = 0\n",
    "\n",
    "    df = pd.concat([df_contained, df_not_contained])\n",
    "\n",
    "    df[\"location\"] = df[\"location\"].astype(int)\n",
    "    df[\"title\"] = df[\"title\"].astype(str)\n",
    "\n",
    "    combined_terms = np.concatenate((terms_1, terms_2))\n",
    "    terms = np.unique(combined_terms)\n",
    "    df = normalize_terms(df, dataset, terms)\n",
    "    return df\n",
    "\n",
    "dataset = load_brazilian_portuguese_words()\n",
    "df_contained_in_the_title = get_all_origins(back_words_contained_in_the_title)\n",
    "df_not_contained_in_the_title = get_all_origins(back_words_not_contained_in_the_title)\n",
    "df = process_dataframes(df_contained_in_the_title, df_not_contained_in_the_title)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6223d0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69362 entries, 0 to 69361\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ref          69362 non-null  object\n",
      " 1   location     69362 non-null  int64 \n",
      " 2   subject      69362 non-null  int64 \n",
      " 3   back_word_1  69362 non-null  object\n",
      " 4   back_word_2  69362 non-null  object\n",
      " 5   back_word_3  69362 non-null  object\n",
      " 6   target       69362 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# df.to_csv(\"./back_words.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"./back_words.csv\")\n",
    "\n",
    "df[\"ref\"] = df[\"ref\"].astype(str)\n",
    "df[\"location\"] = df[\"location\"].astype(int)\n",
    "df[\"target\"] = df[\"title\"].astype(str)\n",
    "\n",
    "df = df.drop(columns=['title'])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5da4b5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>location</th>\n",
       "      <th>subject</th>\n",
       "      <th>back_word_1</th>\n",
       "      <th>back_word_2</th>\n",
       "      <th>back_word_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>1191</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1918</td>\n",
       "      <td>1613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>2190</td>\n",
       "      <td>655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>496</td>\n",
       "      <td>655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>plant</td>\n",
       "      <td>464</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>1911</td>\n",
       "      <td>475</td>\n",
       "      <td>1613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>1613</td>\n",
       "      <td>165</td>\n",
       "      <td>655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>1824</td>\n",
       "      <td>303</td>\n",
       "      <td>648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>g</td>\n",
       "      <td>655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1044</td>\n",
       "      <td>2316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>2190</td>\n",
       "      <td>655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>647</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>496</td>\n",
       "      <td>655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>671</td>\n",
       "      <td>1</td>\n",
       "      <td>plant</td>\n",
       "      <td>464</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>1</td>\n",
       "      <td>655</td>\n",
       "      <td>2295</td>\n",
       "      <td>1613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>823</td>\n",
       "      <td>1</td>\n",
       "      <td>655</td>\n",
       "      <td>1044</td>\n",
       "      <td>655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>838</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>2190</td>\n",
       "      <td>655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>908</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>496</td>\n",
       "      <td>655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>932</td>\n",
       "      <td>1</td>\n",
       "      <td>plant</td>\n",
       "      <td>464</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1033</td>\n",
       "      <td>1</td>\n",
       "      <td>808</td>\n",
       "      <td>488</td>\n",
       "      <td>1613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ref  location  subject back_word_1 back_word_2 back_word_3 target\n",
       "0    0       243        1         600        1191           1      1\n",
       "1    1         9        1           0           0        1310      1\n",
       "2    1        11        1           0        1918        1613      1\n",
       "3    1        64        1         105        2190         655      1\n",
       "4    1       134        1           1         496         655      1\n",
       "5    1       158        1       plant         464           1      1\n",
       "6    1       272        1        1911         475        1613      1\n",
       "7    1       400        1        1613         165         655      1\n",
       "8    1       480        1        1824         303         648      1\n",
       "9    1       511        1           0           g         655      1\n",
       "10   1       549        1           0        1044        2316      1\n",
       "11   1       577        1         105        2190         655      1\n",
       "12   1       647        1           1         496         655      1\n",
       "13   1       671        1       plant         464           1      1\n",
       "14   1       730        1         655        2295        1613      1\n",
       "15   1       823        1         655        1044         655      1\n",
       "16   1       838        1         105        2190         655      1\n",
       "17   1       908        1           1         496         655      1\n",
       "18   1       932        1       plant         464           1      1\n",
       "19   1      1033        1         808         488        1613      1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ca43cd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in ['ref', 'subject', 'back_word_1', 'back_word_2', 'back_word_3', 'target']:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Separar em X (recursos) e y (alvo)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=42)\n",
    "\n",
    "# Treinar o modelo Decision Tree\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prever no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
