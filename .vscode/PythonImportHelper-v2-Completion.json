[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "isExtraImport": true,
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "openai",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "openai",
        "description": "openai",
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "create_or_read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_and_stack_csvs_dataframes",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "drop_duplicates_for_columns",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_and_stack_csvs_dataframes",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_and_stack_historical_csvs_dataframes",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "create_or_read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "create_or_read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "create_or_read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_and_stack_historical_csvs_dataframes",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "calc_string_diff_in_df_col",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "create_or_read_df",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_and_stack_historical_csvs_dataframes",
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "isExtraImport": true,
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "create_directory_if_not_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "create_file_if_not_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "DATE_FORMAT",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "file_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "file_exists_with_modification_time",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "path_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "read_file",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "read_json",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "save_file_with_line_breaks",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "save_json",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "DATE_FORMAT",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "create_directory_if_not_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "create_directory_if_not_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "file_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "path_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "DATE_FORMAT",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "create_directory_if_not_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "delete_directory_and_contents",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "delete_file",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "file_modified_within_x_hours",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "get_old_files_by_percent",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "list_directory",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "read_json",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "save_images",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "path_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "read_file",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "path_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "read_file",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "save_file",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "create_directory_if_not_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "list_directory",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "path_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "read_file",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "save_file",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "create_directory_if_not_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "delete_file",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "has_files",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "path_exists",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "list_directory",
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "isExtraImport": true,
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "get_pages_with_status_true",
        "importPath": "src.lib.utils.general_functions",
        "description": "src.lib.utils.general_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.general_functions",
        "documentation": {}
    },
    {
        "label": "get_pages_with_status_true",
        "importPath": "src.lib.utils.general_functions",
        "description": "src.lib.utils.general_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.general_functions",
        "documentation": {}
    },
    {
        "label": "generate_hash",
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "clean_string_break_line",
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "generate_hash",
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "find_in_text_with_wordlist",
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "clean_text",
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "find_in_text_with_wordlist",
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "remove_spaces",
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "DATE_FORMAT",
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "DATE_FORMAT",
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "levenshtein",
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "clean_text",
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "WORDLIST",
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "isExtraImport": true,
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "WORDLIST",
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "isExtraImport": true,
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "WORDLIST",
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "isExtraImport": true,
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "BLACK_LIST",
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "isExtraImport": true,
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "BLACK_LIST",
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "isExtraImport": true,
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "importlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib",
        "description": "importlib",
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "extract",
        "importPath": "src.lib.extract.extract",
        "description": "src.lib.extract.extract",
        "isExtraImport": true,
        "detail": "src.lib.extract.extract",
        "documentation": {}
    },
    {
        "label": "products_metadata_update_old_pages_by_ref",
        "importPath": "src.lib.extract.extract",
        "description": "src.lib.extract.extract",
        "isExtraImport": true,
        "detail": "src.lib.extract.extract",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "src.lib.load.load",
        "description": "src.lib.load.load",
        "isExtraImport": true,
        "detail": "src.lib.load.load",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "src.lib.extract.selenium_service",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "src.lib.extract.selenium_service",
        "description": "src.lib.extract.selenium_service",
        "detail": "src.lib.extract.selenium_service",
        "documentation": {}
    },
    {
        "label": "src.lib.utils.data_quality",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "src.lib.utils.data_quality",
        "description": "src.lib.utils.data_quality",
        "detail": "src.lib.utils.data_quality",
        "documentation": {}
    },
    {
        "label": "status_tag",
        "importPath": "src.lib.utils.data_quality",
        "description": "src.lib.utils.data_quality",
        "isExtraImport": true,
        "detail": "src.lib.utils.data_quality",
        "documentation": {}
    },
    {
        "label": "is_price",
        "importPath": "src.lib.utils.data_quality",
        "description": "src.lib.utils.data_quality",
        "isExtraImport": true,
        "detail": "src.lib.utils.data_quality",
        "documentation": {}
    },
    {
        "label": "crawler",
        "importPath": "src.lib.extract.crawler",
        "description": "src.lib.extract.crawler",
        "isExtraImport": true,
        "detail": "src.lib.extract.crawler",
        "documentation": {}
    },
    {
        "label": "Page",
        "importPath": "src.lib.extract.page_elements",
        "description": "src.lib.extract.page_elements",
        "isExtraImport": true,
        "detail": "src.lib.extract.page_elements",
        "documentation": {}
    },
    {
        "label": "Page",
        "importPath": "src.lib.extract.page_elements",
        "description": "src.lib.extract.page_elements",
        "isExtraImport": true,
        "detail": "src.lib.extract.page_elements",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "UserAgent",
        "importPath": "fake_useragent",
        "description": "fake_useragent",
        "isExtraImport": true,
        "detail": "fake_useragent",
        "documentation": {}
    },
    {
        "label": "UserAgent",
        "importPath": "fake_useragent",
        "description": "fake_useragent",
        "isExtraImport": true,
        "detail": "fake_useragent",
        "documentation": {}
    },
    {
        "label": "webdriver",
        "importPath": "selenium",
        "description": "selenium",
        "isExtraImport": true,
        "detail": "selenium",
        "documentation": {}
    },
    {
        "label": "TimeoutException",
        "importPath": "selenium.common.exceptions",
        "description": "selenium.common.exceptions",
        "isExtraImport": true,
        "detail": "selenium.common.exceptions",
        "documentation": {}
    },
    {
        "label": "WebDriverException",
        "importPath": "selenium.common.exceptions",
        "description": "selenium.common.exceptions",
        "isExtraImport": true,
        "detail": "selenium.common.exceptions",
        "documentation": {}
    },
    {
        "label": "Service",
        "importPath": "selenium.webdriver.chrome.service",
        "description": "selenium.webdriver.chrome.service",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.service",
        "documentation": {}
    },
    {
        "label": "ActionChains",
        "importPath": "selenium.webdriver.common.action_chains",
        "description": "selenium.webdriver.common.action_chains",
        "isExtraImport": true,
        "detail": "selenium.webdriver.common.action_chains",
        "documentation": {}
    },
    {
        "label": "By",
        "importPath": "selenium.webdriver.common.by",
        "description": "selenium.webdriver.common.by",
        "isExtraImport": true,
        "detail": "selenium.webdriver.common.by",
        "documentation": {}
    },
    {
        "label": "ChromeDriverManager",
        "importPath": "webdriver_manager.chrome",
        "description": "webdriver_manager.chrome",
        "isExtraImport": true,
        "detail": "webdriver_manager.chrome",
        "documentation": {}
    },
    {
        "label": "expected_conditions",
        "importPath": "selenium.webdriver.support",
        "description": "selenium.webdriver.support",
        "isExtraImport": true,
        "detail": "selenium.webdriver.support",
        "documentation": {}
    },
    {
        "label": "WebDriverWait",
        "importPath": "selenium.webdriver.support.ui",
        "description": "selenium.webdriver.support.ui",
        "isExtraImport": true,
        "detail": "selenium.webdriver.support.ui",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "parse_qs",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "importPath": "src.config.setup.shopify",
        "description": "src.config.setup.shopify",
        "isExtraImport": true,
        "detail": "src.config.setup.shopify",
        "documentation": {}
    },
    {
        "label": "HEADERS",
        "importPath": "src.config.setup.shopify",
        "description": "src.config.setup.shopify",
        "isExtraImport": true,
        "detail": "src.config.setup.shopify",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "process_and_ingest_products",
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "isExtraImport": true,
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "html2text",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "html2text",
        "description": "html2text",
        "detail": "html2text",
        "documentation": {}
    },
    {
        "label": "apply_generic_filters",
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "create_price_discount_percent_col",
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "create_product_collection_col",
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "create_product_definition_col",
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "create_quantity_column",
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "filter_nulls",
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "remove_blacklisted_products",
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "isExtraImport": true,
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "imagehash",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "imagehash",
        "description": "imagehash",
        "detail": "imagehash",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "calculate_precise_image_hash",
        "importPath": "src.lib.utils.image_functions",
        "description": "src.lib.utils.image_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.image_functions",
        "documentation": {}
    },
    {
        "label": "convert_image",
        "importPath": "src.lib.utils.image_functions",
        "description": "src.lib.utils.image_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.image_functions",
        "documentation": {}
    },
    {
        "label": "load_product_info",
        "importPath": "src.lib.transform.product_info",
        "description": "src.lib.transform.product_info",
        "isExtraImport": true,
        "detail": "src.lib.transform.product_info",
        "documentation": {}
    },
    {
        "label": "check_url_existence",
        "importPath": "src.lib.utils.web_functions",
        "description": "src.lib.utils.web_functions",
        "isExtraImport": true,
        "detail": "src.lib.utils.web_functions",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "as_completed",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "unicodedata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unicodedata",
        "description": "unicodedata",
        "detail": "unicodedata",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "configure_display",
        "importPath": "src.config.setup.display",
        "description": "src.config.setup.display",
        "isExtraImport": true,
        "detail": "src.config.setup.display",
        "documentation": {}
    },
    {
        "label": "configure_image_server",
        "importPath": "src.config.setup.image_server",
        "description": "src.config.setup.image_server",
        "isExtraImport": true,
        "detail": "src.config.setup.image_server",
        "documentation": {}
    },
    {
        "label": "get_used_displays",
        "kind": 2,
        "importPath": "src.config.setup.display",
        "description": "src.config.setup.display",
        "peekOfCode": "def get_used_displays():\n    \"\"\"\n    Retorna um conjunto de nmeros de display atualmente em uso.\n    \"\"\"\n    try:\n        # Executa o comando ps aux\n        process = subprocess.Popen(['ps', 'aux'], stdout=subprocess.PIPE)\n        # Filtra os processos que contm 'Xvfb'\n        grep_process = subprocess.Popen(['grep', 'Xvfb'], stdin=process.stdout, stdout=subprocess.PIPE)\n        process.stdout.close()  # Fecha a entrada do pipe",
        "detail": "src.config.setup.display",
        "documentation": {}
    },
    {
        "label": "find_available_display",
        "kind": 2,
        "importPath": "src.config.setup.display",
        "description": "src.config.setup.display",
        "peekOfCode": "def find_available_display(start=99, end=200):\n    \"\"\"\n    Encontra um nmero de display disponvel entre start e end.\n    Retorna a string do display (por exemplo, ':99') ou None se no encontrar.\n    \"\"\"\n    used_displays = get_used_displays()\n    for display_num in range(start, end):\n        if display_num not in used_displays:\n            return f\":{display_num}\"\n    return None",
        "detail": "src.config.setup.display",
        "documentation": {}
    },
    {
        "label": "start_xvfb",
        "kind": 2,
        "importPath": "src.config.setup.display",
        "description": "src.config.setup.display",
        "peekOfCode": "def start_xvfb(display):\n    \"\"\"\n    Inicia o Xvfb no display especificado.\n    Retorna o objeto subprocess.Popen ou None se falhar.\n    \"\"\"\n    try:\n        xvfb_command = ['Xvfb', display, '-screen', '0', '1280x720x24']\n        xvfb_process = subprocess.Popen(xvfb_command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n        # Aguarda um pouco para garantir que o Xvfb inicie\n        time.sleep(2)",
        "detail": "src.config.setup.display",
        "documentation": {}
    },
    {
        "label": "terminate_process",
        "kind": 2,
        "importPath": "src.config.setup.display",
        "description": "src.config.setup.display",
        "peekOfCode": "def terminate_process(process):\n    \"\"\"\n    Termina o processo fornecido de forma graciosa, forando se necessrio.\n    \"\"\"\n    try:\n        if process.poll() is None:\n            process.terminate()\n            try:\n                process.wait(timeout=5)\n                message(f\"Processo {process.pid} encerrado.\")",
        "detail": "src.config.setup.display",
        "documentation": {}
    },
    {
        "label": "configure_display_and_test_chrome",
        "kind": 2,
        "importPath": "src.config.setup.display",
        "description": "src.config.setup.display",
        "peekOfCode": "def configure_display_and_test_chrome():\n    \"\"\"\n    Encontra um display disponvel, inicia o Xvfb, configura a varivel DISPLAY,\n    lana o Chrome em modo headless e verifica se funciona.\n    Retorna True se bem-sucedido, False caso contrrio.\n    \"\"\"\n    # Encontra um display disponvel\n    display = find_available_display()\n    if not display:\n        message(\"Nenhum DISPLAY disponvel encontrado.\")",
        "detail": "src.config.setup.display",
        "documentation": {}
    },
    {
        "label": "configure_display",
        "kind": 2,
        "importPath": "src.config.setup.display",
        "description": "src.config.setup.display",
        "peekOfCode": "def configure_display():\n    message(\"FUNCTION CONFIGURE DISPLAY\")\n    sucesso = configure_display_and_test_chrome()\n    if sucesso:\n        message(\"Configurao do DISPLAY e teste do Chrome concludos com sucesso.\")\n    else:\n        message(\"Falha na configurao do DISPLAY e/ou no teste do Chrome.\")",
        "detail": "src.config.setup.display",
        "documentation": {}
    },
    {
        "label": "configure_image_server",
        "kind": 2,
        "importPath": "src.config.setup.image_server",
        "description": "src.config.setup.image_server",
        "peekOfCode": "def configure_image_server():\n    os.environ['DATAINDEX_IMG_PATH'] = os.path.join(LOCAL, '..', 'image-server')\n    os.environ['DATAINDEX_IMG_URL'] = GIT_CONF[\"dataindex_img_url\"]\n    img_path = os.environ.get('DATAINDEX_IMG_PATH')\n    if os.path.isdir(img_path):\n        message(f\"{img_path} Ok\")\n    else:\n        clone_repository(GIT_CONF[\"remote_url\"])\n        setup_git_config(img_path, GIT_CONF['username'], GIT_CONF['email'], GIT_CONF['remote_name'], GIT_CONF['remote_url'])\ndef clone_repository(remote_url):",
        "detail": "src.config.setup.image_server",
        "documentation": {}
    },
    {
        "label": "clone_repository",
        "kind": 2,
        "importPath": "src.config.setup.image_server",
        "description": "src.config.setup.image_server",
        "peekOfCode": "def clone_repository(remote_url):\n    try:\n        original_dir = os.getcwd()\n        os.chdir(LOCAL + \"/..\")\n        subprocess.check_call(['git', 'clone', remote_url])\n        message(f\"Repositrio clonado em {LOCAL}\")\n    except subprocess.CalledProcessError as e:\n        message(f\"Erro ao executar o comando Git: {e}\")\n    except Exception as e:\n        message(f\"Erro ao clonar o repositrio: {e}\")",
        "detail": "src.config.setup.image_server",
        "documentation": {}
    },
    {
        "label": "setup_git_config",
        "kind": 2,
        "importPath": "src.config.setup.image_server",
        "description": "src.config.setup.image_server",
        "peekOfCode": "def setup_git_config(project_dir, username, email, remote_name, remote_url):\n    try:\n        if not os.path.exists(project_dir):\n            os.makedirs(project_dir)\n        original_dir = os.getcwd()\n        os.chdir(project_dir)\n        subprocess.check_call(['git', 'config', 'init.defaultBranch', 'master'])\n        subprocess.check_call(['git', 'config', 'user.name', username])\n        subprocess.check_call(['git', 'config', 'user.email', email])\n        remote_check = subprocess.check_output(['git', 'remote']).decode('utf-8').strip()",
        "detail": "src.config.setup.image_server",
        "documentation": {}
    },
    {
        "label": "LOCAL",
        "kind": 5,
        "importPath": "src.config.setup.image_server",
        "description": "src.config.setup.image_server",
        "peekOfCode": "LOCAL = os.getenv('LOCAL')\nGIT_CONF = {\n    \"username\": \"Gustavo Fortti\",\n    \"email\": \"gustavofortti@gmail.com\",\n    \"remote_name\": \"origin\",\n    \"remote_url\": \"https://github.com/GustavoFortti/dataindex-img.git\",\n    \"dataindex_img_url\": \"https://raw.githubusercontent.com/GustavoFortti/dataindex-img/master/imgs/\"\n}\ndef configure_image_server():\n    os.environ['DATAINDEX_IMG_PATH'] = os.path.join(LOCAL, '..', 'image-server')",
        "detail": "src.config.setup.image_server",
        "documentation": {}
    },
    {
        "label": "GIT_CONF",
        "kind": 5,
        "importPath": "src.config.setup.image_server",
        "description": "src.config.setup.image_server",
        "peekOfCode": "GIT_CONF = {\n    \"username\": \"Gustavo Fortti\",\n    \"email\": \"gustavofortti@gmail.com\",\n    \"remote_name\": \"origin\",\n    \"remote_url\": \"https://github.com/GustavoFortti/dataindex-img.git\",\n    \"dataindex_img_url\": \"https://raw.githubusercontent.com/GustavoFortti/dataindex-img/master/imgs/\"\n}\ndef configure_image_server():\n    os.environ['DATAINDEX_IMG_PATH'] = os.path.join(LOCAL, '..', 'image-server')\n    os.environ['DATAINDEX_IMG_URL'] = GIT_CONF[\"dataindex_img_url\"]",
        "detail": "src.config.setup.image_server",
        "documentation": {}
    },
    {
        "label": "ACCESS_TOKEN",
        "kind": 5,
        "importPath": "src.config.setup.shopify",
        "description": "src.config.setup.shopify",
        "peekOfCode": "ACCESS_TOKEN = \"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\"\nSHOP_NAME = \"2ef5d6-14\"\nAPI_VERSION = \"2024-07\"\nBASE_URL = f\"https://{SHOP_NAME}.myshopify.com/admin/api/{API_VERSION}/\"\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"X-Shopify-Access-Token\": ACCESS_TOKEN\n}",
        "detail": "src.config.setup.shopify",
        "documentation": {}
    },
    {
        "label": "SHOP_NAME",
        "kind": 5,
        "importPath": "src.config.setup.shopify",
        "description": "src.config.setup.shopify",
        "peekOfCode": "SHOP_NAME = \"2ef5d6-14\"\nAPI_VERSION = \"2024-07\"\nBASE_URL = f\"https://{SHOP_NAME}.myshopify.com/admin/api/{API_VERSION}/\"\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"X-Shopify-Access-Token\": ACCESS_TOKEN\n}",
        "detail": "src.config.setup.shopify",
        "documentation": {}
    },
    {
        "label": "API_VERSION",
        "kind": 5,
        "importPath": "src.config.setup.shopify",
        "description": "src.config.setup.shopify",
        "peekOfCode": "API_VERSION = \"2024-07\"\nBASE_URL = f\"https://{SHOP_NAME}.myshopify.com/admin/api/{API_VERSION}/\"\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"X-Shopify-Access-Token\": ACCESS_TOKEN\n}",
        "detail": "src.config.setup.shopify",
        "documentation": {}
    },
    {
        "label": "BASE_URL",
        "kind": 5,
        "importPath": "src.config.setup.shopify",
        "description": "src.config.setup.shopify",
        "peekOfCode": "BASE_URL = f\"https://{SHOP_NAME}.myshopify.com/admin/api/{API_VERSION}/\"\nHEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"X-Shopify-Access-Token\": ACCESS_TOKEN\n}",
        "detail": "src.config.setup.shopify",
        "documentation": {}
    },
    {
        "label": "HEADERS",
        "kind": 5,
        "importPath": "src.config.setup.shopify",
        "description": "src.config.setup.shopify",
        "peekOfCode": "HEADERS = {\n    \"Content-Type\": \"application/json\",\n    \"X-Shopify-Access-Token\": ACCESS_TOKEN\n}",
        "detail": "src.config.setup.shopify",
        "documentation": {}
    },
    {
        "label": "set_config",
        "kind": 2,
        "importPath": "src.jobs.data_intelligence.product_info.job",
        "description": "src.jobs.data_intelligence.product_info.job",
        "peekOfCode": "def set_config(args: Any, local: str) -> Dict[str, Any]:\n    \"\"\"\n    Sets up the configuration dictionary based on the job arguments and local environment.\n    Args:\n        args (Any): Job arguments.\n        local (str): Local environment path.\n    Returns:\n        Dict[str, Any]: Configuration dictionary for the job.\n    \"\"\"\n    config = {",
        "detail": "src.jobs.data_intelligence.product_info.job",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "src.jobs.data_intelligence.product_info.job",
        "description": "src.jobs.data_intelligence.product_info.job",
        "peekOfCode": "def run(args: Any) -> None:\n    \"\"\"\n    Executa o trabalho de extrao e processamento de dados.\n    Args:\n        args (Any): Argumentos do trabalho.\n    \"\"\"\n    message(\"STARTING THE JOB\")\n    global CONF\n    local = os.getenv('LOCAL')\n    CONF = set_config(args, local)",
        "detail": "src.jobs.data_intelligence.product_info.job",
        "documentation": {}
    },
    {
        "label": "refine_description",
        "kind": 2,
        "importPath": "src.jobs.data_intelligence.product_info.job",
        "description": "src.jobs.data_intelligence.product_info.job",
        "peekOfCode": "def refine_description(description: str) -> Optional[str]:\n    \"\"\"\n    Uses the OpenAI API to generate a refined version of the product description.\n    Args:\n        description (str): The product description to be refined.\n    Returns:\n        Optional[str]: Refined text or None in case of an error.\n    \"\"\"\n    try:\n        # Set up the OpenAI client",
        "detail": "src.jobs.data_intelligence.product_info.job",
        "documentation": {}
    },
    {
        "label": "set_conf",
        "kind": 2,
        "importPath": "src.jobs.data_shelf.history_price.job",
        "description": "src.jobs.data_shelf.history_price.job",
        "peekOfCode": "def set_conf(args, local):\n    conf = {}\n    conf[\"local\"] = local\n    conf[\"job_name\"] = args.job_name\n    conf[\"page_name\"] = args.page_name\n    conf[\"page_type\"] = args.page_type\n    conf[\"country\"] = args.country\n    conf[\"src_data_path\"] = f\"{local}/data/{conf['page_type']}/{conf['country']}\"\n    conf[\"data_path\"] = f\"{conf['src_data_path']}/history_price\"\n    conf[\"pages_path\"] = f\"{local}/src/jobs/slave_page/pages/{conf['country']}\"",
        "detail": "src.jobs.data_shelf.history_price.job",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "src.jobs.data_shelf.history_price.job",
        "description": "src.jobs.data_shelf.history_price.job",
        "peekOfCode": "def run(args):\n    global LOCAL\n    LOCAL = os.getenv('LOCAL')\n    conf = set_conf(args, LOCAL)\n    print(\"JOB_NAME: \" + conf[\"job_name\"])\n    conf.update(vars(args))\n    src_data_path = conf[\"src_data_path\"]\n    data_path = conf['data_path']\n    create_directory_if_not_exists(data_path)\n    message(\"read data\")",
        "detail": "src.jobs.data_shelf.history_price.job",
        "documentation": {}
    },
    {
        "label": "set_conf",
        "kind": 2,
        "importPath": "src.jobs.master_page.master.job",
        "description": "src.jobs.master_page.master.job",
        "peekOfCode": "def set_conf(args, local):\n    conf = {}\n    conf[\"local\"] = local\n    conf[\"job_name\"] = args.job_name\n    conf[\"page_name\"] = args.page_name\n    conf[\"page_type\"] = args.page_type\n    conf[\"country\"] = args.country\n    conf[\"src_data_path\"] = f\"{local}/data/{conf['page_type']}/{conf['country']}\"\n    conf[\"wordlist\"] = WORDLIST[conf['page_type']]\n    return conf",
        "detail": "src.jobs.master_page.master.job",
        "documentation": {}
    },
    {
        "label": "update_conf_with_page_config",
        "kind": 2,
        "importPath": "src.jobs.master_page.master.job",
        "description": "src.jobs.master_page.master.job",
        "peekOfCode": "def update_conf_with_page_config(conf, page_conf, local, args):\n    conf[\"name\"] = page_conf.JOB_NAME\n    conf[\"brand\"] = page_conf.BRAND\n    conf[\"url\"] = page_conf.URL\n    conf[\"product_definition_tag_map\"] = page_conf.PRODUCT_DEFINITION_TAG_MAP\n    conf[\"product_description_tag_map\"] = page_conf.PRODUCT_DESCRIPTION_TAG_MAP\n    conf[\"product_nutricional_table_tag_map\"] = page_conf.PRODUCT_NUTRICIONAL_TABLE_TAG_MAP\n    conf[\"dynamic_scroll\"] = page_conf.DYNAMIC_SCROLL\n    conf[\"user_agent\"] = page_conf.USER_AGENT\n    conf[\"data_path\"] = f\"{conf['src_data_path']}/{page_conf.JOB_NAME}\"",
        "detail": "src.jobs.master_page.master.job",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "src.jobs.master_page.master.job",
        "description": "src.jobs.master_page.master.job",
        "peekOfCode": "def run(args):\n    message(\"INICIANDO O JOB\")\n    local = os.getenv('LOCAL')\n    conf = set_conf(args, local)\n    module_name = f\"src.jobs.slave_page.pages.{conf['country']}.{conf['page_name']}.conf\"\n    page_conf = importlib.import_module(module_name)\n    conf = update_conf_with_page_config(conf, page_conf, local, args)\n    module_name = f\"src.jobs.slave_page.pages.{conf['country']}.{conf['page_name']}.dry\"\n    dry = importlib.import_module(module_name)\n    options = {",
        "detail": "src.jobs.master_page.master.job",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "peekOfCode": "JOB_NAME = \"adaptogen\"\nBRAND = \"adaptogen\"\nURL = \"https://adaptogen.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': '#tab-beneficios'},\n    {'tag': None, 'path': '#tab-tabela_nutricional'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "peekOfCode": "BRAND = \"adaptogen\"\nURL = \"https://adaptogen.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': '#tab-beneficios'},\n    {'tag': None, 'path': '#tab-tabela_nutricional'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "peekOfCode": "URL = \"https://adaptogen.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': '#tab-beneficios'},\n    {'tag': None, 'path': '#tab-tabela_nutricional'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': '#tab-beneficios'},\n    {'tag': None, 'path': '#tab-tabela_nutricional'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': '#tab-beneficios'},\n    {'tag': None, 'path': '#tab-tabela_nutricional'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#tab-description'}",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': '#tab-beneficios'},\n    {'tag': None, 'path': '#tab-tabela_nutricional'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#tab-description'}\n]",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#tab-description'}\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#tab-description'}\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.dry",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.dry",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('li', class_='product-type-simple')\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a')\n    return product_link_element['href'] if product_link_element else None\ndef get_title(conf, soup):\n    title_element = soup.find('h2', class_='woocommerce-loop-product__title')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a')\n    return product_link_element['href'] if product_link_element else None\ndef get_title(conf, soup):\n    title_element = soup.find('h2', class_='woocommerce-loop-product__title')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    price_container = soup.find(class_=\"a_vista\")\n    if (price_container):\n        price_element = price_container.find('p')",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('h2', class_='woocommerce-loop-product__title')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    price_container = soup.find(class_=\"a_vista\")\n    if (price_container):\n        price_element = price_container.find('p')\n        price = price_element.contents[0].strip()\n    return price\ndef get_image_url(conf, soup):",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    price_container = soup.find(class_=\"a_vista\")\n    if (price_container):\n        price_element = price_container.find('p')\n        price = price_element.contents[0].strip()\n    return price\ndef get_image_url(conf, soup):\n    image_element = soup.find('img', class_='entered lazyloaded')\n    return image_element['src'] if image_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    image_element = soup.find('img', class_='entered lazyloaded')\n    return image_element['src'] if image_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.adaptogen.page_url",
        "description": "src.jobs.slave_page.pages.brazil.adaptogen.page_url",
        "peekOfCode": "def get_url(conf, url):\n    conf[\"index\"] = None\n    return url",
        "detail": "src.jobs.slave_page.pages.brazil.adaptogen.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "peekOfCode": "JOB_NAME = \"atlhetica_nutrition\"\nBRAND = \"atlhetica nutrition\"\nURL = \"https://www.atlheticanutrition.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "peekOfCode": "BRAND = \"atlhetica nutrition\"\nURL = \"https://www.atlheticanutrition.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "peekOfCode": "URL = \"https://www.atlheticanutrition.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div:nth-child(1) > div > section > div > div > div > div'}",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div:nth-child(1) > div > section > div > div > div > div'}\n]",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div:nth-child(1) > div > section > div > div > div > div'}\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div:nth-child(1) > div > section > div > div > div > div'}\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.8,\n    \"scroll_step\": 500,",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div:nth-child(1) > div > section > div > div > div > div'}\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.8,\n    \"scroll_step\": 500,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.8,\n    \"scroll_step\": 500,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.dry",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.dry",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('div', class_='vtex-search-result-3-x-galleryItem')\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='vtex-product-summary-2-x-clearLink')\n    return conf[\"url\"] + product_link_element['href'] if product_link_element else None\ndef get_title(conf, soup):\n    title_element = soup.find('span', class_='vtex-product-summary-2-x-brandName')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='vtex-product-summary-2-x-clearLink')\n    return conf[\"url\"] + product_link_element['href'] if product_link_element else None\ndef get_title(conf, soup):\n    title_element = soup.find('span', class_='vtex-product-summary-2-x-brandName')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    # Busca pelo elemento que contm o preo de venda no riscado\n    selling_price_element = soup.find(class_=\"vtex-store-components-3-x-sellingPriceValue\")\n    if not selling_price_element:",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('span', class_='vtex-product-summary-2-x-brandName')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    # Busca pelo elemento que contm o preo de venda no riscado\n    selling_price_element = soup.find(class_=\"vtex-store-components-3-x-sellingPriceValue\")\n    if not selling_price_element:\n        # Se no encontrar o preo de venda, tenta buscar por qualquer preo disponvel\n        selling_price_element = soup.find(class_=\"vtex-product-summary-2-x-currencyContainer\")\n    if selling_price_element:",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    # Busca pelo elemento que contm o preo de venda no riscado\n    selling_price_element = soup.find(class_=\"vtex-store-components-3-x-sellingPriceValue\")\n    if not selling_price_element:\n        # Se no encontrar o preo de venda, tenta buscar por qualquer preo disponvel\n        selling_price_element = soup.find(class_=\"vtex-product-summary-2-x-currencyContainer\")\n    if selling_price_element:\n        # Captura as diferentes partes do preo\n        currency_code = selling_price_element.find(class_=\"vtex-product-summary-2-x-currencyCode\").get_text(strip=True)\n        currency_integer = selling_price_element.find(class_=\"vtex-product-summary-2-x-currencyInteger\").get_text(strip=True)",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    image_element = soup.find('img', class_='vtex-product-summary-2-x-imageNormal')\n    return image_element['src'] if image_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_url",
        "description": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(conf[\"index\"])\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.atlhetica_nutrition.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "peekOfCode": "JOB_NAME = \"black_skull\"\nBRAND = \"black skull\"\nURL = \"https://www.blackskullusa.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "peekOfCode": "BRAND = \"black skull\"\nURL = \"https://www.blackskullusa.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "peekOfCode": "URL = \"https://www.blackskullusa.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div:nth-child(1) > div.vtex-tab-layout-0-x-container > div.vtex-tab-layout-0-x-contentContainer.w-100'}    ",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div:nth-child(1) > div.vtex-tab-layout-0-x-container > div.vtex-tab-layout-0-x-contentContainer.w-100'}    \n]",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div:nth-child(1) > div.vtex-tab-layout-0-x-container > div.vtex-tab-layout-0-x-contentContainer.w-100'}    \n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div:nth-child(1) > div.vtex-tab-layout-0-x-container > div.vtex-tab-layout-0-x-contentContainer.w-100'}    \n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div:nth-child(1) > div.vtex-tab-layout-0-x-container > div.vtex-tab-layout-0-x-contentContainer.w-100'}    \n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.dry",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.dry",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('div', class_='vtex-search-result-3-x-galleryItem')\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='vtex-product-summary-2-x-clearLink')\n    return conf[\"url\"] + product_link_element['href'] if product_link_element else None\ndef get_title(conf, soup):\n    title_element = soup.find('span', class_='vtex-product-summary-2-x-brandName')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='vtex-product-summary-2-x-clearLink')\n    return conf[\"url\"] + product_link_element['href'] if product_link_element else None\ndef get_title(conf, soup):\n    title_element = soup.find('span', class_='vtex-product-summary-2-x-brandName')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    price = None\n    price_element = soup.find(\"span\", class_=\"vtex-product-price-1-x-sellingPriceValue\")\n    if price_element:",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('span', class_='vtex-product-summary-2-x-brandName')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    price = None\n    price_element = soup.find(\"span\", class_=\"vtex-product-price-1-x-sellingPriceValue\")\n    if price_element:\n        currency_code = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyCode\").get_text(strip=True)\n        currency_integer = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyInteger\").get_text(strip=True)\n        currency_decimal = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyDecimal\").get_text(strip=True)",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    price = None\n    price_element = soup.find(\"span\", class_=\"vtex-product-price-1-x-sellingPriceValue\")\n    if price_element:\n        currency_code = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyCode\").get_text(strip=True)\n        currency_integer = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyInteger\").get_text(strip=True)\n        currency_decimal = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyDecimal\").get_text(strip=True)\n        currency_fraction = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyFraction\").get_text(strip=True)\n        price = f\"{currency_code} {currency_integer}{currency_decimal}{currency_fraction}\"\n    return price",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    image_element = soup.find('img', class_='vtex-product-summary-2-x-imageNormal')\n    return image_element['src'] if image_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.black_skull.page_url",
        "description": "src.jobs.slave_page.pages.brazil.black_skull.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(conf[\"index\"])\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.black_skull.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "peekOfCode": "JOB_NAME = \"boldsnacks\"\nBRAND = \"bold snacks\"\nURL = \"https://www.boldsnacks.com.br/\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "peekOfCode": "BRAND = \"bold snacks\"\nURL = \"https://www.boldsnacks.com.br/\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "peekOfCode": "URL = \"https://www.boldsnacks.com.br/\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ProductSection-template--17547208458430__main > div.productView-container.container > div > div.productView-top > div.halo-productView-right.productView-details.clearfix > div'},",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ProductSection-template--17547208458430__main > div.productView-container.container > div > div.productView-top > div.halo-productView-right.productView-details.clearfix > div'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ProductSection-template--17547208458430__main > div.productView-container.container > div > div.productView-top > div.halo-productView-right.productView-details.clearfix > div'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ProductSection-template--17547208458430__main > div.productView-container.container > div > div.productView-top > div.halo-productView-right.productView-details.clearfix > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ProductSection-template--17547208458430__main > div.productView-container.container > div > div.productView-top > div.halo-productView-right.productView-details.clearfix > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.dry",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    def_string = \"barrinha \"\n    df['title'] = def_string + df['title']\n    df = transform(CONF, df)\n    df['name'] = df['name'].str.slice(len(def_string))\n    df['title_extract'] = df['title_extract'].str.slice(len(def_string))\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.dry",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('li', class_='product collection-product-list')\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='card-link')\n    product_link = conf[\"url\"] + product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('a', class_='card-title center link-underline card-title-ellipsis')\n    title = title_element.get_text().strip() if title_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='card-link')\n    product_link = conf[\"url\"] + product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('a', class_='card-title center link-underline card-title-ellipsis')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    def format_price(price_text):",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('a', class_='card-title center link-underline card-title-ellipsis')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    def format_price(price_text):\n        cleaned_price = price_text.strip()\n        if \",\" in cleaned_price:\n            return None\n        else:",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    def format_price(price_text):\n        cleaned_price = price_text.strip()\n        if \",\" in cleaned_price:\n            return None\n        else:\n            return cleaned_price + \",00\"\n    price_sale_span = soup.find('span', class_='price-item--sale')\n    if price_sale_span:\n        price_text = price_sale_span.get_text()",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    div_container = soup.find('div', class_='card-product__wrapper')\n    if div_container:\n        image_element = div_container.find('img')\n        if image_element and 'data-srcset' in image_element.attrs:\n            srcset = image_element['data-srcset']\n            images = srcset.split(\",\")\n            middle_image = images[len(images) // 2].split(\" \")[0].strip()\n            image_url = \"https:\" + middle_image if middle_image.startswith(\"//\") else middle_image\n            return image_url",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.boldsnacks.page_url",
        "description": "src.jobs.slave_page.pages.brazil.boldsnacks.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(conf[\"index\"])\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.boldsnacks.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "peekOfCode": "JOB_NAME = \"dark_lab\"\nBRAND = \"dark lab\"\nURL = \"https://darklabsuplementos.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "peekOfCode": "BRAND = \"dark lab\"\nURL = \"https://darklabsuplementos.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "peekOfCode": "URL = \"https://darklabsuplementos.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#single-product > div > div:nth-child(2) > div > div.px-3'},",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#single-product > div > div:nth-child(2) > div > div.px-3'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#single-product > div > div:nth-child(2) > div > div.px-3'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#single-product > div > div:nth-child(2) > div > div.px-3'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#single-product > div > div:nth-child(2) > div > div.px-3'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.dry",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.dry",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('div', class_='item-with-sidebar')\n    return items\ndef get_product_url(conf, soup):\n    product_link_container = soup.find('div', class_='item-image')\n    product_link_element = product_link_container.find('a') if product_link_container else None\n    product_link = product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('div', class_='js-item-name')",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_container = soup.find('div', class_='item-image')\n    product_link_element = product_link_container.find('a') if product_link_container else None\n    product_link = product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('div', class_='js-item-name')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('div', class_='js-item-name')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    price_element = soup.find('span', class_='js-price-display')\n    price = price_element.get_text().strip() if price_element else None\n    return price\ndef get_image_url(conf, soup):\n    link_imagem = None",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    price_element = soup.find('span', class_='js-price-display')\n    price = price_element.get_text().strip() if price_element else None\n    return price\ndef get_image_url(conf, soup):\n    link_imagem = None\n    image_container = soup.find('div', class_='item-image')\n    image_element = image_container.find('img') if image_container else None\n    try:\n        link_imagem = \"https:\" + image_element.get('srcset').split(' ')[0] if image_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    link_imagem = None\n    image_container = soup.find('div', class_='item-image')\n    image_element = image_container.find('img') if image_container else None\n    try:\n        link_imagem = \"https:\" + image_element.get('srcset').split(' ')[0] if image_element else None\n    except:\n        pass\n    try:\n        link_imagem = \"https:\" + image_element.get('data-srcset').split(' ')[0] if image_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dark_lab.page_url",
        "description": "src.jobs.slave_page.pages.brazil.dark_lab.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(conf[\"index\"])\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.dark_lab.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "description": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "peekOfCode": "JOB_NAME = \"darkness\"\nBRAND = \"darkness\"\nURL = \"https://www.darkness.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "description": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "peekOfCode": "BRAND = \"darkness\"\nURL = \"https://www.darkness.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "description": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "peekOfCode": "URL = \"https://www.darkness.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "description": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': 'section', 'class': 'product-information'}, ",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "description": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': 'section', 'class': 'product-information'}, \n    {'tag': 'div', 'class': '__bs-nutri-table-container'}, ",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "description": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': 'section', 'class': 'product-information'}, \n    {'tag': 'div', 'class': '__bs-nutri-table-container'}, \n    {'tag': 'div', 'class': 'col-md-6'},",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "description": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': 'section', 'class': 'product-information'}, \n    {'tag': 'div', 'class': '__bs-nutri-table-container'}, \n    {'tag': 'div', 'class': 'col-md-6'},\n    {'tag': 'div', 'class': '__bs-evora-list-text'}, \n    {'tag': 'div', 'id': 'descricao'},\n    {'tag': 'div', 'id': 'sugestoes'},",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "description": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': 'section', 'class': 'product-information'}, \n    {'tag': 'div', 'class': '__bs-nutri-table-container'}, \n    {'tag': 'div', 'class': 'col-md-6'},\n    {'tag': 'div', 'class': '__bs-evora-list-text'}, \n    {'tag': 'div', 'id': 'descricao'},\n    {'tag': 'div', 'id': 'sugestoes'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "description": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 500,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.dry",
        "description": "src.jobs.slave_page.pages.brazil.darkness.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving transform\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.dry",
        "description": "src.jobs.slave_page.pages.brazil.darkness.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('div', class_='vtex-search-result-3-x-galleryItem')\n    return items\ndef get_product_url(conf, item):\n    product_link_element = item.find('a', class_='vtex-product-summary-2-x-clearLink')\n    return conf[\"url\"] + product_link_element['href'] if product_link_element else None\ndef get_title(conf, item):\n    title_element = item.find('span', class_='vtex-product-summary-2-x-brandName')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, item):",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "peekOfCode": "def get_product_url(conf, item):\n    product_link_element = item.find('a', class_='vtex-product-summary-2-x-clearLink')\n    return conf[\"url\"] + product_link_element['href'] if product_link_element else None\ndef get_title(conf, item):\n    title_element = item.find('span', class_='vtex-product-summary-2-x-brandName')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, item):\n    price_element = item.find(\"span\", class_=\"vtex-product-price-1-x-sellingPriceValue\")\n    if price_element:\n        # Extrai as diferentes partes do preo",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "peekOfCode": "def get_title(conf, item):\n    title_element = item.find('span', class_='vtex-product-summary-2-x-brandName')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, item):\n    price_element = item.find(\"span\", class_=\"vtex-product-price-1-x-sellingPriceValue\")\n    if price_element:\n        # Extrai as diferentes partes do preo\n        currency_code = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyCode\").get_text(strip=True)\n        currency_integer = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyInteger\").get_text(strip=True)\n        currency_decimal = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyDecimal\").get_text(strip=True)",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "peekOfCode": "def get_price(conf, item):\n    price_element = item.find(\"span\", class_=\"vtex-product-price-1-x-sellingPriceValue\")\n    if price_element:\n        # Extrai as diferentes partes do preo\n        currency_code = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyCode\").get_text(strip=True)\n        currency_integer = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyInteger\").get_text(strip=True)\n        currency_decimal = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyDecimal\").get_text(strip=True)\n        currency_fraction = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyFraction\").get_text(strip=True)\n        # Verifica se h espao entre o cdigo da moeda e o valor inteiro\n        currency_literal = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyLiteral\")",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "peekOfCode": "def get_image_url(conf, item):\n    image_element = item.find('img', class_='vtex-product-summary-2-x-imageNormal')\n    return image_element['src'] if image_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.darkness.page_url",
        "description": "src.jobs.slave_page.pages.brazil.darkness.page_url",
        "peekOfCode": "def get_url(conf, url):\n    return url",
        "detail": "src.jobs.slave_page.pages.brazil.darkness.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "peekOfCode": "JOB_NAME = \"dux_nutrition_lab\"\nBRAND = \"dux nutrition lab\"\nURL = \"https://www.duxnutrition.com\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "peekOfCode": "BRAND = \"dux nutrition lab\"\nURL = \"https://www.duxnutrition.com\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "peekOfCode": "URL = \"https://www.duxnutrition.com\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ProductDescriptionAccordion > div.vtex-flex-layout-0-x-flexRow.vtex-flex-layout-0-x-flexRow--productDescriptionAccordion.vtex-flex-layout-0-x-flexRow--container.vtex-flex-layout-0-x-flexRow--block > section > div'},",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ProductDescriptionAccordion > div.vtex-flex-layout-0-x-flexRow.vtex-flex-layout-0-x-flexRow--productDescriptionAccordion.vtex-flex-layout-0-x-flexRow--container.vtex-flex-layout-0-x-flexRow--block > section > div'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ProductDescriptionAccordion > div.vtex-flex-layout-0-x-flexRow.vtex-flex-layout-0-x-flexRow--productDescriptionAccordion.vtex-flex-layout-0-x-flexRow--container.vtex-flex-layout-0-x-flexRow--block > section > div'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ProductDescriptionAccordion > div.vtex-flex-layout-0-x-flexRow.vtex-flex-layout-0-x-flexRow--productDescriptionAccordion.vtex-flex-layout-0-x-flexRow--container.vtex-flex-layout-0-x-flexRow--block > section > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ProductDescriptionAccordion > div.vtex-flex-layout-0-x-flexRow.vtex-flex-layout-0-x-flexRow--productDescriptionAccordion.vtex-flex-layout-0-x-flexRow--container.vtex-flex-layout-0-x-flexRow--block > section > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.dry",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.dry",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    # Busca todos os itens no HTML com a classe especificada\n    items = soup.find_all('div', class_='duxnutrition-search-result-3-x-galleryItem')\n    return items\ndef get_product_url(conf, soup):\n    # Busca o link do produto no HTML\n    product_link_element = soup.find('a', class_='vtex-product-summary-2-x-clearLink')\n    product_link = conf[\"url\"] + product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    # Busca o link do produto no HTML\n    product_link_element = soup.find('a', class_='vtex-product-summary-2-x-clearLink')\n    product_link = conf[\"url\"] + product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    # Busca o ttulo do produto no HTML\n    title_element = soup.find('span', class_='vtex-product-summary-2-x-productBrand')\n    title = title_element.get_text().strip() if title_element else None\n    return title",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    # Busca o ttulo do produto no HTML\n    title_element = soup.find('span', class_='vtex-product-summary-2-x-productBrand')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    # Busca o preo do produto no HTML\n    price = None\n    price_element = soup.find('span', class_='vtex-store-components-3-x-sellingPriceValue')\n    if price_element:",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    # Busca o preo do produto no HTML\n    price = None\n    price_element = soup.find('span', class_='vtex-store-components-3-x-sellingPriceValue')\n    if price_element:\n        price = price_element.get_text().strip()\n    return price\ndef get_image_url(conf, soup):\n    # Busca a URL da imagem do produto no HTML\n    image_element = soup.find('img', class_='vtex-product-summary-2-x-imageNormal')",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    # Busca a URL da imagem do produto no HTML\n    image_element = soup.find('img', class_='vtex-product-summary-2-x-imageNormal')\n    if image_element and 'src' in image_element.attrs:\n        return image_element['src']\n    return None",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_url",
        "description": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(conf[\"index\"])\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.dux_nutrition_lab.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "peekOfCode": "JOB_NAME = \"growth_supplements\"\nBRAND = \"growth supplements\"\nURL = \"https://www.gsuplementos.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "peekOfCode": "BRAND = \"growth supplements\"\nURL = \"https://www.gsuplementos.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "peekOfCode": "URL = \"https://www.gsuplementos.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#breadcrumb'},",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#breadcrumb'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#breadcrumb'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#breadcrumb'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#breadcrumb'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.dry",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df['name'] = df['name'].str.replace('- growth supplements', '')\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.dry",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    return soup.find_all('a', class_='cardprod text-decoration-none')\ndef get_product_url(conf, soup):\n    import re\n    if not isinstance(soup, str):\n        html_content = str(soup)\n    else:\n        html_content = soup\n    pattern = r'<a[^>]*class=\"[^\"]*cardprod[^\"]*text-decoration-none[^\"]*\"[^>]*href=\"([^\"]+)\"'\n    match = re.search(pattern, html_content)",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    import re\n    if not isinstance(soup, str):\n        html_content = str(soup)\n    else:\n        html_content = soup\n    pattern = r'<a[^>]*class=\"[^\"]*cardprod[^\"]*text-decoration-none[^\"]*\"[^>]*href=\"([^\"]+)\"'\n    match = re.search(pattern, html_content)\n    if match:\n        product_link_element = conf['url'] + match.group(1).strip() ",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('h3', class_='cardprod-nomeProduto-t1')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    price_element = soup.find('span', class_='cardprod-valor')\n    if price_element:\n        # Obtm apenas o texto direto dentro do span, ignorando elementos filhos\n        price_text = ''.join(price_element.find_all(string=True, recursive=False)).strip()\n        # Remove o smbolo \"R$\" e quaisquer espaos\n        price_without_symbol = price_text.strip()",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    price_element = soup.find('span', class_='cardprod-valor')\n    if price_element:\n        # Obtm apenas o texto direto dentro do span, ignorando elementos filhos\n        price_text = ''.join(price_element.find_all(string=True, recursive=False)).strip()\n        # Remove o smbolo \"R$\" e quaisquer espaos\n        price_without_symbol = price_text.strip()\n        return price_without_symbol\n    return None\ndef get_image_url(conf, soup):",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    image_element = soup.find('img')\n    return image_element['src'] if image_element and image_element.has_attr('src') else None",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.growth_supplements.page_url",
        "description": "src.jobs.slave_page.pages.brazil.growth_supplements.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(conf[\"index\"])\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.growth_supplements.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "description": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "peekOfCode": "JOB_NAME = \"ifood\"\nBRAND = \"ifood\"\nURL = \"https://ifood.com.br/\"\nSTATUS = False\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "description": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "peekOfCode": "BRAND = \"ifood\"\nURL = \"https://ifood.com.br/\"\nSTATUS = False\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "description": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "peekOfCode": "URL = \"https://ifood.com.br/\"\nSTATUS = False\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "description": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "peekOfCode": "STATUS = False\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "description": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "description": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "description": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "description": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "description": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.dry",
        "description": "src.jobs.slave_page.pages.brazil.ifood.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.dry",
        "description": "src.jobs.slave_page.pages.brazil.ifood.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('li', class_='product collection-product-list')\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='card-link')\n    product_link = conf[\"url\"] + product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('a', class_='card-title center link-underline card-title-ellipsis')\n    title = title_element.get_text().strip() if title_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='card-link')\n    product_link = conf[\"url\"] + product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('a', class_='card-title center link-underline card-title-ellipsis')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    def format_price(price_text):",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('a', class_='card-title center link-underline card-title-ellipsis')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    def format_price(price_text):\n        cleaned_price = price_text.strip()\n        if \",\" in cleaned_price:\n            return None\n        else:",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    def format_price(price_text):\n        cleaned_price = price_text.strip()\n        if \",\" in cleaned_price:\n            return None\n        else:\n            return cleaned_price + \",00\"\n    price_sale_span = soup.find('span', class_='price-item--sale')\n    if price_sale_span:\n        price_text = price_sale_span.get_text()",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    div_container = soup.find('div', class_='card-product__wrapper')\n    if div_container:\n        image_element = div_container.find('img')\n        if image_element and 'data-srcset' in image_element.attrs:\n            srcset = image_element['data-srcset']\n            images = srcset.split(\",\")\n            middle_image = images[len(images) // 2].split(\" \")[0].strip()\n            image_url = \"https:\" + middle_image if middle_image.startswith(\"//\") else middle_image\n            return image_url",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.ifood.page_url",
        "description": "src.jobs.slave_page.pages.brazil.ifood.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(conf[\"index\"])\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.ifood.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "peekOfCode": "JOB_NAME = \"integralmedica\"\nBRAND = \"integralmedica\"\nURL = \"https://www.integralmedica.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "peekOfCode": "BRAND = \"integralmedica\"\nURL = \"https://www.integralmedica.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "peekOfCode": "URL = \"https://www.integralmedica.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div > div > div > div:nth-child(3) > div > div > div:nth-child(3) > div'},",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div > div > div > div:nth-child(3) > div > div > div:nth-child(3) > div'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div > div > div > div:nth-child(3) > div > div > div:nth-child(3) > div'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div > div > div > div:nth-child(3) > div > div > div:nth-child(3) > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(3) > div > div > div > div > div:nth-child(3) > div > div > div:nth-child(3) > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.dry",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.dry",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('div', class_='vtex-search-result-3-x-galleryItem vtex-search-result-3-x-galleryItem--normal vtex-search-result-3-x-galleryItem--grid pa4')\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='vtex-product-summary-2-x-clearLink vtex-product-summary-2-x-clearLink--default h-100 flex flex-column')\n    product_link = conf[\"url\"] + product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('span', class_='vtex-product-summary-2-x-productBrand vtex-product-summary-2-x-brandName t-body')\n    title = title_element.get_text().strip() if title_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='vtex-product-summary-2-x-clearLink vtex-product-summary-2-x-clearLink--default h-100 flex flex-column')\n    product_link = conf[\"url\"] + product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('span', class_='vtex-product-summary-2-x-productBrand vtex-product-summary-2-x-brandName t-body')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    price_element = soup.find('span', class_='vtex-product-price-1-x-sellingPriceValue vtex-product-price-1-x-sellingPriceValue--shelfDefault')",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('span', class_='vtex-product-summary-2-x-productBrand vtex-product-summary-2-x-brandName t-body')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    price_element = soup.find('span', class_='vtex-product-price-1-x-sellingPriceValue vtex-product-price-1-x-sellingPriceValue--shelfDefault')\n    price = price_element.get_text().strip() if price_element else None\n    return price\ndef get_image_url(conf, soup):\n    image_element = soup.find('img', class_='vtex-product-summary-2-x-imageNormal vtex-product-summary-2-x-image vtex-product-summary-2-x-image--shelfDefault')",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    price_element = soup.find('span', class_='vtex-product-price-1-x-sellingPriceValue vtex-product-price-1-x-sellingPriceValue--shelfDefault')\n    price = price_element.get_text().strip() if price_element else None\n    return price\ndef get_image_url(conf, soup):\n    image_element = soup.find('img', class_='vtex-product-summary-2-x-imageNormal vtex-product-summary-2-x-image vtex-product-summary-2-x-image--shelfDefault')\n    link_imagem = image_element['src'] if image_element else None\n    return link_imagem",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    image_element = soup.find('img', class_='vtex-product-summary-2-x-imageNormal vtex-product-summary-2-x-image vtex-product-summary-2-x-image--shelfDefault')\n    link_imagem = image_element['src'] if image_element else None\n    return link_imagem",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.integralmedica.page_url",
        "description": "src.jobs.slave_page.pages.brazil.integralmedica.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(conf[\"index\"])\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.integralmedica.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "peekOfCode": "JOB_NAME = \"iridium_labs\"\nBRAND = \"iridium labs\"\nURL = \"https://www.iridiumlabs.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "peekOfCode": "BRAND = \"iridium labs\"\nURL = \"https://www.iridiumlabs.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "peekOfCode": "URL = \"https://www.iridiumlabs.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#shopify-section-template--14719947636839__main > div > div > div > div > div.t4s-col-md-6.t4s-col-12.t4s-col-item.t4s-product__info-wrapper.t4s-pr'},",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#shopify-section-template--14719947636839__main > div > div > div > div > div.t4s-col-md-6.t4s-col-12.t4s-col-item.t4s-product__info-wrapper.t4s-pr'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#shopify-section-template--14719947636839__main > div > div > div > div > div.t4s-col-md-6.t4s-col-12.t4s-col-item.t4s-product__info-wrapper.t4s-pr'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#shopify-section-template--14719947636839__main > div > div > div > div > div.t4s-col-md-6.t4s-col-12.t4s-col-item.t4s-product__info-wrapper.t4s-pr'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#shopify-section-template--14719947636839__main > div > div > div > div > div.t4s-col-md-6.t4s-col-12.t4s-col-item.t4s-product__info-wrapper.t4s-pr'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.dry",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.dry",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    import re\n    items = []\n    items_container = soup.find_all('div', class_='t4s-product-wrapper')\n    for item in items_container:\n        if (not re.search(\"cdn.shopify.com\", str(item))):\n            items.append(item)\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='t4s-full-width-link')",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='t4s-full-width-link')\n    return conf[\"url\"] + product_link_element['href'] if product_link_element else None\ndef get_title(conf, soup):\n    title_element = soup.find('h3', class_='t4s-product-title')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    import re\n    final_price = None\n    price_container = soup.find(class_=\"t4s-product-price\")",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('h3', class_='t4s-product-title')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    import re\n    final_price = None\n    price_container = soup.find(class_=\"t4s-product-price\")\n    if price_container:\n        # Verifica se existe um desconto\n        discount_price_element = price_container.find(\"ins\")",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    import re\n    final_price = None\n    price_container = soup.find(class_=\"t4s-product-price\")\n    if price_container:\n        # Verifica se existe um desconto\n        discount_price_element = price_container.find(\"ins\")\n        if discount_price_element:\n            final_price = discount_price_element.text.strip()\n        else:",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    import re\n    image_element = soup.find(class_='t4s-product-main-img')\n    if image_element:\n        # Extrai a URL base da imagem do 'data-src'\n        if 'data-src' in image_element.attrs:\n            base_image_url = \"https:\" + image_element['data-src']\n            # Extrai os tamanhos do atributo 'data-widths'\n            if 'data-widths' in image_element.attrs:\n                widths = image_element['data-widths']",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.iridium_labs.page_url",
        "description": "src.jobs.slave_page.pages.brazil.iridium_labs.page_url",
        "peekOfCode": "def get_url(conf, url):\n    return url",
        "detail": "src.jobs.slave_page.pages.brazil.iridium_labs.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "peekOfCode": "JOB_NAME = \"max_titanium\"\nBRAND = \"max titanium\"\nURL = \"https://www.maxtitanium.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "peekOfCode": "BRAND = \"max titanium\"\nURL = \"https://www.maxtitanium.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "peekOfCode": "URL = \"https://www.maxtitanium.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(2) > div:nth-child(6) > section > div > div > div > div:nth-child(1) > div > div > div > div > div:nth-child(2) > div > div > div > div > table > tbody'},",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(2) > div:nth-child(6) > section > div > div > div > div:nth-child(1) > div > div > div > div > div:nth-child(2) > div > div > div > div > table > tbody'},\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(1) > div.vtex-flex-layout-0-x-flexRow.vtex-flex-layout-0-x-flexRow--breadcrumb'},",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(2) > div:nth-child(6) > section > div > div > div > div:nth-child(1) > div > div > div > div > div:nth-child(2) > div > div > div > div > table > tbody'},\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(1) > div.vtex-flex-layout-0-x-flexRow.vtex-flex-layout-0-x-flexRow--breadcrumb'},\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(2) > div.vtex-flex-layout-0-x-flexRow.vtex-flex-layout-0-x-flexRow--breadcrumb'},",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(2) > div:nth-child(6) > section > div > div > div > div:nth-child(1) > div > div > div > div > div:nth-child(2) > div > div > div > div > table > tbody'},\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(1) > div.vtex-flex-layout-0-x-flexRow.vtex-flex-layout-0-x-flexRow--breadcrumb'},\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(2) > div.vtex-flex-layout-0-x-flexRow.vtex-flex-layout-0-x-flexRow--breadcrumb'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(2) > div:nth-child(6) > section > div > div > div > div:nth-child(1) > div > div > div > div > div:nth-child(2) > div > div > div > div > table > tbody'},\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(1) > div.vtex-flex-layout-0-x-flexRow.vtex-flex-layout-0-x-flexRow--breadcrumb'},\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(2) > div.vtex-flex-layout-0-x-flexRow.vtex-flex-layout-0-x-flexRow--breadcrumb'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 500,\n    \"percentage\": 0.07,",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 500,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.dry",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.dry",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('div', class_='vtex-search-result-3-x-galleryItem')\n    return items\ndef get_product_url(conf, item):\n    product_link_element = item.find('a', class_='vtex-product-summary-2-x-clearLink')\n    return conf[\"url\"] + product_link_element['href'] if product_link_element else None\ndef get_title(conf, item):\n    title_element = item.find('span', class_='vtex-product-summary-2-x-brandName')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, item):",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "peekOfCode": "def get_product_url(conf, item):\n    product_link_element = item.find('a', class_='vtex-product-summary-2-x-clearLink')\n    return conf[\"url\"] + product_link_element['href'] if product_link_element else None\ndef get_title(conf, item):\n    title_element = item.find('span', class_='vtex-product-summary-2-x-brandName')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, item):\n    price_element = item.find(\"span\", class_=\"vtex-product-price-1-x-sellingPriceWithTax\")\n    if price_element:\n        currency_code = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyCode\").get_text(strip=True)",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "peekOfCode": "def get_title(conf, item):\n    title_element = item.find('span', class_='vtex-product-summary-2-x-brandName')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, item):\n    price_element = item.find(\"span\", class_=\"vtex-product-price-1-x-sellingPriceWithTax\")\n    if price_element:\n        currency_code = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyCode\").get_text(strip=True)\n        currency_integer = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyInteger\").get_text(strip=True)\n        currency_decimal = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyDecimal\").get_text(strip=True)\n        currency_fraction = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyFraction\").get_text(strip=True)",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "peekOfCode": "def get_price(conf, item):\n    price_element = item.find(\"span\", class_=\"vtex-product-price-1-x-sellingPriceWithTax\")\n    if price_element:\n        currency_code = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyCode\").get_text(strip=True)\n        currency_integer = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyInteger\").get_text(strip=True)\n        currency_decimal = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyDecimal\").get_text(strip=True)\n        currency_fraction = price_element.find(\"span\", class_=\"vtex-product-price-1-x-currencyFraction\").get_text(strip=True)\n        price = f\"{currency_code} {currency_integer}{currency_decimal}{currency_fraction}\"\n        return price\n    return None",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "peekOfCode": "def get_image_url(conf, item):\n    image_element = item.find('img', class_='vtex-product-summary-2-x-imageNormal')\n    return image_element['src'] if image_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.max_titanium.page_url",
        "description": "src.jobs.slave_page.pages.brazil.max_titanium.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(conf[\"index\"])\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.max_titanium.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "peekOfCode": "JOB_NAME = \"mercadolivre\"\nBRAND = \"mercado livre\"\nURL = \"https://lista.mercadolivre.com.br/\"\nSTATUS = True\nUSER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:115.0) Gecko/20100101 Firefox/115.0\"\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': '#ui-pdp-main-container > div.ui-pdp-container__col.col-3.ui-pdp-container--column-center.pb-16 > div > div:nth-child(7) > div > div'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "peekOfCode": "BRAND = \"mercado livre\"\nURL = \"https://lista.mercadolivre.com.br/\"\nSTATUS = True\nUSER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:115.0) Gecko/20100101 Firefox/115.0\"\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': '#ui-pdp-main-container > div.ui-pdp-container__col.col-3.ui-pdp-container--column-center.pb-16 > div > div:nth-child(7) > div > div'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "peekOfCode": "URL = \"https://lista.mercadolivre.com.br/\"\nSTATUS = True\nUSER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:115.0) Gecko/20100101 Firefox/115.0\"\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': '#ui-pdp-main-container > div.ui-pdp-container__col.col-3.ui-pdp-container--column-center.pb-16 > div > div:nth-child(7) > div > div'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:115.0) Gecko/20100101 Firefox/115.0\"\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': '#ui-pdp-main-container > div.ui-pdp-container__col.col-3.ui-pdp-container--column-center.pb-16 > div > div:nth-child(7) > div > div'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ui-pdp-main-container > div.ui-pdp-container__col.col-3.ui-pdp-container--column-center.pb-16 > div > div:nth-child(7) > div > div'},",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "peekOfCode": "USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:115.0) Gecko/20100101 Firefox/115.0\"\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': '#ui-pdp-main-container > div.ui-pdp-container__col.col-3.ui-pdp-container--column-center.pb-16 > div > div:nth-child(7) > div > div'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ui-pdp-main-container > div.ui-pdp-container__col.col-3.ui-pdp-container--column-center.pb-16 > div > div:nth-child(7) > div > div'},\n    {'tag': None, 'path': '#description'},",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': '#ui-pdp-main-container > div.ui-pdp-container__col.col-3.ui-pdp-container--column-center.pb-16 > div > div:nth-child(7) > div > div'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ui-pdp-main-container > div.ui-pdp-container__col.col-3.ui-pdp-container--column-center.pb-16 > div > div:nth-child(7) > div > div'},\n    {'tag': None, 'path': '#description'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ui-pdp-main-container > div.ui-pdp-container__col.col-3.ui-pdp-container--column-center.pb-16 > div > div:nth-child(7) > div > div'},\n    {'tag': None, 'path': '#description'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#ui-pdp-main-container > div.ui-pdp-container__col.col-3.ui-pdp-container--column-center.pb-16 > div > div:nth-child(7) > div > div'},\n    {'tag': None, 'path': '#description'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1500,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.2,",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1500,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.2,\n    \"max_return\": 2000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.dry",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.dry",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('li', class_='ui-search-layout__item')\n    return items\ndef get_product_url(conf, soup):\n    import re\n    print(soup)\n    # Atualiza para buscar o link de todas as estruturas\n    product_link_element = soup.find('a', href=re.compile(r'^https://www\\.mercadolivre\\.com\\.br/'))\n    if not product_link_element:\n        product_link_element = soup.find('a', href=re.compile(r'^https://produto\\.mercadolivre\\.com\\.br/'))",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    import re\n    print(soup)\n    # Atualiza para buscar o link de todas as estruturas\n    product_link_element = soup.find('a', href=re.compile(r'^https://www\\.mercadolivre\\.com\\.br/'))\n    if not product_link_element:\n        product_link_element = soup.find('a', href=re.compile(r'^https://produto\\.mercadolivre\\.com\\.br/'))\n    if product_link_element and product_link_element.get('href'):\n        return product_link_element['href'].strip()\n    return None",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    # Atualiza para buscar o ttulo em todas as estruturas\n    title_element = soup.find('h2', class_='ui-search-item__title')\n    if not title_element:\n        title_element = soup.find('h2', class_='poly-component__title')\n    if not title_element:\n        title_element = soup.find('h2', class_='ui-search-item__group__element')\n    if title_element:\n        link_element = title_element.find('a')\n        if link_element:",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    # Atualiza para buscar o preo em todas as estruturas\n    # Encontra a parte inteira do preo\n    fraction_element = soup.find('span', class_='andes-money-amount__fraction')\n    if not fraction_element:\n        fraction_element = soup.find('span', class_='poly-price__current').find('span', class_='andes-money-amount__fraction')\n    if not fraction_element:\n        fraction_element = soup.find('div', class_='ui-search-price__second-line').find('span', class_='andes-money-amount__fraction')\n    fraction_text = fraction_element.get_text().strip() if fraction_element else None\n    # Encontra os centavos do preo",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    # Atualiza para buscar a imagem em todas as estruturas\n    image_element = soup.find('img', class_='ui-search-result-image__element')\n    if not image_element:\n        image_element = soup.find('img', class_='poly-component__picture')\n    if not image_element:\n        image_element = soup.find('img', class_='ui-search-result__image')\n    image_url = image_element['src'] if image_element else None\n    return image_url",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.mercadolivre.page_url",
        "description": "src.jobs.slave_page.pages.brazil.mercadolivre.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if conf['index'] is None:\n        conf['index'] = 1\n        return url\n    soup = conf['soup']\n    next_page = soup.find('a', class_='andes-pagination__link', title='Seguinte')\n    if next_page is None:\n        conf['index'] = None\n        return None\n    next_page_url = next_page.get('href') if next_page else None",
        "detail": "src.jobs.slave_page.pages.brazil.mercadolivre.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "peekOfCode": "JOB_NAME = \"mercadolivre\"\nBRAND = \"mercado livre\"\nURL = \"https://lista.mercadolivre.com.br/\"\nSTATUS = False\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "peekOfCode": "BRAND = \"mercado livre\"\nURL = \"https://lista.mercadolivre.com.br/\"\nSTATUS = False\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "peekOfCode": "URL = \"https://lista.mercadolivre.com.br/\"\nSTATUS = False\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "peekOfCode": "STATUS = False\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#maincontent > div.columns > div > div.product.attribute.description > div > div > div'},",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#maincontent > div.columns > div > div.product.attribute.description > div > div > div'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#maincontent > div.columns > div > div.product.attribute.description > div > div > div'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#maincontent > div.columns > div > div.product.attribute.description > div > div > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1.3,\n    \"scroll_step\": 700,",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#maincontent > div.columns > div > div.product.attribute.description > div > div > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1.3,\n    \"scroll_step\": 700,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 2000,",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1.3,\n    \"scroll_step\": 700,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 2000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.dry",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.dry",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('li', class_='ui-search-layout__item')\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='ui-search-link')\n    product_link = product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('h2', class_='ui-search-item__title')\n    if title_element:",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='ui-search-link')\n    product_link = product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('h2', class_='ui-search-item__title')\n    if title_element:\n        link_element = title_element.find('a')\n        if link_element:\n            title = link_element.get_text().strip()",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('h2', class_='ui-search-item__title')\n    if title_element:\n        link_element = title_element.find('a')\n        if link_element:\n            title = link_element.get_text().strip()\n            return title\n    return None\ndef get_price(conf, soup):\n    # Encontra a parte inteira do preo",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    # Encontra a parte inteira do preo\n    fraction_element = soup.find('span', class_='andes-money-amount__fraction')\n    fraction_text = fraction_element.get_text().strip() if fraction_element else None\n    # Encontra os centavos do preo\n    cents_element = soup.find('span', class_='andes-money-amount__cents')\n    cents_text = cents_element.get_text().strip() if cents_element else None\n    if fraction_text and cents_text:\n        price = f\"R$ {fraction_text},{cents_text}\"\n    elif fraction_text:",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    image_element = soup.find('img', class_='ui-search-result-image__element')\n    image_url = image_element['src'] if image_element else None\n    return image_url",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.netshoes.page_url",
        "description": "src.jobs.slave_page.pages.brazil.netshoes.page_url",
        "peekOfCode": "def get_url(conf, url):\n    return url",
        "detail": "src.jobs.slave_page.pages.brazil.netshoes.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "peekOfCode": "JOB_NAME = \"new_millen\"\nBRAND = \"new millen\"\nURL = \"https://loja.newmillen.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "peekOfCode": "BRAND = \"new millen\"\nURL = \"https://loja.newmillen.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "peekOfCode": "URL = \"https://loja.newmillen.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#product-description'},",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#product-description'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#product-description'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#product-description'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#product-description'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.dry",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.dry",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('div', class_='item item-rounded item-product box-rounded p-0')\n    return items\ndef get_product_url(conf, soup):\n    product_link_container = soup.find('div', class_='position-relative')\n    if (product_link_container):\n        product_link_element = product_link_container.find('a')\n        return product_link_element['href'] if product_link_element else None\ndef get_title(conf, soup):\n    title_element = soup.find('div', class_='js-item-name item-name mb-3')",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_container = soup.find('div', class_='position-relative')\n    if (product_link_container):\n        product_link_element = product_link_container.find('a')\n        return product_link_element['href'] if product_link_element else None\ndef get_title(conf, soup):\n    title_element = soup.find('div', class_='js-item-name item-name mb-3')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    price_element = soup.find(\"span\", class_=\"js-price-display item-price\")",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('div', class_='js-item-name item-name mb-3')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    price_element = soup.find(\"span\", class_=\"js-price-display item-price\")\n    price = price_element.get_text() if price_element else None\n    return price\ndef get_image_url(conf, soup):\n    image_container = soup.find('div', class_='position-relative')\n    if (image_container):",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    price_element = soup.find(\"span\", class_=\"js-price-display item-price\")\n    price = price_element.get_text() if price_element else None\n    return price\ndef get_image_url(conf, soup):\n    image_container = soup.find('div', class_='position-relative')\n    if (image_container):\n        image_element = soup.find('img')\n        return \"https:\" + image_element['srcset'].split(\" \")[0] if image_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    image_container = soup.find('div', class_='position-relative')\n    if (image_container):\n        image_element = soup.find('img')\n        return \"https:\" + image_element['srcset'].split(\" \")[0] if image_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.new_millen.page_url",
        "description": "src.jobs.slave_page.pages.brazil.new_millen.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(conf[\"index\"])\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.new_millen.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "peekOfCode": "JOB_NAME = \"nutrata\"\nBRAND = \"nutrata\"\nURL = \"https://loja.nutrata.com.br/\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "peekOfCode": "BRAND = \"nutrata\"\nURL = \"https://loja.nutrata.com.br/\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "peekOfCode": "URL = \"https://loja.nutrata.com.br/\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#descricao > div.board'},",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#descricao > div.board'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#descricao > div.board'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#descricao > div.board'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#descricao > div.board'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.dry",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.dry",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items_container = soup.find_all('div', class_='product-card')\n    items = [item for item in items_container if item.find('div', class_='product-price-sale') is not None]\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a', href=True)\n    product_link = product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('p', class_='product-title')",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a', href=True)\n    product_link = product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('p', class_='product-title')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    price_element = soup.find('div', class_='product-price-sale')",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('p', class_='product-title')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    price_element = soup.find('div', class_='product-price-sale')\n    price = price_element.get_text().strip() if price_element else None\n    return price\ndef get_image_url(conf, soup):\n    import re",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    price_element = soup.find('div', class_='product-price-sale')\n    price = price_element.get_text().strip() if price_element else None\n    return price\ndef get_image_url(conf, soup):\n    import re\n    image_container = soup.find('div', class_='product-image')\n    link_imagem = None\n    if image_container:\n        style_attr = image_container.get('style', '')",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    import re\n    image_container = soup.find('div', class_='product-image')\n    link_imagem = None\n    if image_container:\n        style_attr = image_container.get('style', '')\n        match = re.search(r'url\\(\"([^\"]+)\"\\)', style_attr)\n        link_imagem = match.group(1) if match else None\n    return link_imagem",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.nutrata.page_url",
        "description": "src.jobs.slave_page.pages.brazil.nutrata.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(1)\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.nutrata.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "peekOfCode": "JOB_NAME = \"oficialfarma\"\nBRAND = \"oficial farma\"\nURL = \"https://www.oficialfarma.com.br/\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "peekOfCode": "BRAND = \"oficial farma\"\nURL = \"https://www.oficialfarma.com.br/\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "peekOfCode": "URL = \"https://www.oficialfarma.com.br/\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#maincontent > div.columns > div > div.product.attribute.description > div > div > div'},",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#maincontent > div.columns > div > div.product.attribute.description > div > div > div'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#maincontent > div.columns > div > div.product.attribute.description > div > div > div'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#maincontent > div.columns > div > div.product.attribute.description > div > div > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1.3,\n    \"scroll_step\": 700,",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#maincontent > div.columns > div > div.product.attribute.description > div > div > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1.3,\n    \"scroll_step\": 700,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 2000,",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1.3,\n    \"scroll_step\": 700,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 2000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.dry",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.dry",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('li', class_='item product product-item')\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='product-item-link')\n    product_link = product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('strong', class_='product name product-item-name').find('a')\n    title = title_element.get_text().strip() if title_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='product-item-link')\n    product_link = product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('strong', class_='product name product-item-name').find('a')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    price_element = soup.find('span', class_='price-wrapper')",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('strong', class_='product name product-item-name').find('a')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    price_element = soup.find('span', class_='price-wrapper')\n    price_text = price_element.get_text().strip() if price_element else None\n    return price_text\ndef get_image_url(conf, soup):\n    image_element = soup.find('img', class_='product-image-photo')",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    price_element = soup.find('span', class_='price-wrapper')\n    price_text = price_element.get_text().strip() if price_element else None\n    return price_text\ndef get_image_url(conf, soup):\n    image_element = soup.find('img', class_='product-image-photo')\n    image_url = image_element['src'] if image_element else None\n    return image_url",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    image_element = soup.find('img', class_='product-image-photo')\n    image_url = image_element['src'] if image_element else None\n    return image_url",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.oficialfarma.page_url",
        "description": "src.jobs.slave_page.pages.brazil.oficialfarma.page_url",
        "peekOfCode": "def get_url(conf, url):\n    return url",
        "detail": "src.jobs.slave_page.pages.brazil.oficialfarma.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "peekOfCode": "JOB_NAME = \"probiotica\"\nBRAND = \"probiotica\"\nURL = \"https://www.probiotica.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(4) > div > div:nth-child(2) > div:nth-child(2) > section > div > div > div > div:nth-child(13) > div > div > div.pr10.items-stretch.vtex-flex-layout-0-x-stretchChildrenWidth.flex'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "peekOfCode": "BRAND = \"probiotica\"\nURL = \"https://www.probiotica.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(4) > div > div:nth-child(2) > div:nth-child(2) > section > div > div > div > div:nth-child(13) > div > div > div.pr10.items-stretch.vtex-flex-layout-0-x-stretchChildrenWidth.flex'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "peekOfCode": "URL = \"https://www.probiotica.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(4) > div > div:nth-child(2) > div:nth-child(2) > section > div > div > div > div:nth-child(13) > div > div > div.pr10.items-stretch.vtex-flex-layout-0-x-stretchChildrenWidth.flex'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(4) > div > div:nth-child(2) > div:nth-child(2) > section > div > div > div > div:nth-child(13) > div > div > div.pr10.items-stretch.vtex-flex-layout-0-x-stretchChildrenWidth.flex'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(4) > div > div:nth-child(2) > div:nth-child(2) > section > div > div > div > div:nth-child(1) > div > div'},",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(4) > div > div:nth-child(2) > div:nth-child(2) > section > div > div > div > div:nth-child(13) > div > div > div.pr10.items-stretch.vtex-flex-layout-0-x-stretchChildrenWidth.flex'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(4) > div > div:nth-child(2) > div:nth-child(2) > section > div > div > div > div:nth-child(1) > div > div'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(4) > div > div:nth-child(2) > div:nth-child(2) > section > div > div > div > div:nth-child(13) > div > div > div.pr10.items-stretch.vtex-flex-layout-0-x-stretchChildrenWidth.flex'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(4) > div > div:nth-child(2) > div:nth-child(2) > section > div > div > div > div:nth-child(1) > div > div'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(4) > div > div:nth-child(2) > div:nth-child(2) > section > div > div > div > div:nth-child(1) > div > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(4) > div > div:nth-child(2) > div:nth-child(2) > section > div > div > div > div:nth-child(1) > div > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.dry",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.dry",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('div', class_='vtex-search-result-3-x-galleryItem')\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='vtex-product-summary-2-x-clearLink')\n    product_link = conf[\"url\"] + product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('h2', class_='vtex-product-summary-2-x-productNameContainer')\n    if title_element:",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='vtex-product-summary-2-x-clearLink')\n    product_link = conf[\"url\"] + product_link_element['href'] if product_link_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('h2', class_='vtex-product-summary-2-x-productNameContainer')\n    if title_element:\n        span_element = title_element.find('span', class_='vtex-product-summary-2-x-productBrand')\n        title = span_element.text.strip() if span_element else None\n    else:",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('h2', class_='vtex-product-summary-2-x-productNameContainer')\n    if title_element:\n        span_element = title_element.find('span', class_='vtex-product-summary-2-x-productBrand')\n        title = span_element.text.strip() if span_element else None\n    else:\n        title = None\n    return title\ndef get_price(conf, soup):\n    price = None",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    price = None\n    price_element = soup.find('span', class_='vtex-product-price-1-x-sellingPriceValue')\n    if price_element:\n        currency_code = price_element.find('span', class_='vtex-product-price-1-x-currencyCode').text.strip()\n        currency_literal = price_element.find('span', class_='vtex-product-price-1-x-currencyLiteral').text.strip()\n        currency_integer = price_element.find('span', class_='vtex-product-price-1-x-currencyInteger').text.strip()\n        currency_decimal = price_element.find('span', class_='vtex-product-price-1-x-currencyDecimal').text.strip()\n        currency_fraction = price_element.find('span', class_='vtex-product-price-1-x-currencyFraction').text.strip()\n        price = f\"{currency_code}{currency_literal}{currency_integer}{currency_decimal}{currency_fraction}\"",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    image_element = soup.find('img', class_='vtex-product-summary-2-x-imageNormal vtex-product-summary-2-x-image')\n    link_imagem = image_element['src'] if image_element else None\n    return link_imagem",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.probiotica.page_url",
        "description": "src.jobs.slave_page.pages.brazil.probiotica.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(conf[\"index\"])\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.probiotica.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "description": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "peekOfCode": "JOB_NAME = \"puravida\"\nBRAND = \"puravida\"\nURL = \"https://www.puravida.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "description": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "peekOfCode": "BRAND = \"puravida\"\nURL = \"https://www.puravida.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "description": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "peekOfCode": "URL = \"https://www.puravida.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "description": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#product-content > div:nth-child(2) > div'},",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "description": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#product-content > div:nth-child(2) > div'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "description": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#product-content > div:nth-child(2) > div'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "description": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#product-content > div:nth-child(2) > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "description": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#product-content > div:nth-child(2) > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "description": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.dry",
        "description": "src.jobs.slave_page.pages.brazil.puravida.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.dry",
        "description": "src.jobs.slave_page.pages.brazil.puravida.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    # Procura por todos os itens de produtos na pgina\n    items = soup.select('div[id^=\"product-new-spot-item-\"]')\n    return items\ndef get_product_url(conf, soup):\n    import re\n    # Converte o objeto soup para string, se necessrio\n    if not isinstance(soup, str):\n        html_content = str(soup)\n    else:",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    import re\n    # Converte o objeto soup para string, se necessrio\n    if not isinstance(soup, str):\n        html_content = str(soup)\n    else:\n        html_content = soup\n    # Expresso regular para encontrar o href dentro da tag <a> com a classe 'spot-product-info'\n    pattern = r'<a[^>]*class=\"[^\"]*spot-product-info[^\"]*\"[^>]*href=\"([^\"]+)\"'\n    # Buscar a primeira correspondncia do padro",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    # Procura pelo elemento 'p' com a classe 'product-name' para obter o ttulo\n    title_element = soup.find('p', class_='product-name')\n    # Extrai o texto e remove espaos em branco desnecessrios, se o elemento for encontrado\n    title = title_element.text.strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    import re\n    # Procura pela div que contm o preo\n    price_element = soup.find('div', class_='product-price')",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    import re\n    # Procura pela div que contm o preo\n    price_element = soup.find('div', class_='product-price')\n    if price_element:\n        price_text = price_element.get_text(strip=True)\n        # Usa regex para capturar o valor numrico aps 'R$'\n        match = re.search(r'R\\$\\s*([\\d.,]+)', price_text)\n        if match:\n            price = match.group(1)",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    # Procura pelo primeiro elemento 'img' dentro de um 'picture' associado ao produto\n    image_container = soup.find('picture')\n    image_element = image_container.find('img') if image_container else None\n    # Extrai o atributo 'src' do elemento de imagem, se encontrado\n    link_imagem = image_element['src'] if image_element else None\n    return link_imagem",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.puravida.page_url",
        "description": "src.jobs.slave_page.pages.brazil.puravida.page_url",
        "peekOfCode": "def get_url(conf, url):\n    return url",
        "detail": "src.jobs.slave_page.pages.brazil.puravida.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "description": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "peekOfCode": "JOB_NAME = \"truesource\"\nBRAND = \"truesource\"\nURL = \"https://www.truesource.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "description": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "peekOfCode": "BRAND = \"truesource\"\nURL = \"https://www.truesource.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "description": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "peekOfCode": "URL = \"https://www.truesource.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "description": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#\\\\39 21277609-0 > div > div:nth-child(2)'}",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "description": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#\\\\39 21277609-0 > div > div:nth-child(2)'}\n]",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "description": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#\\\\39 21277609-0 > div > div:nth-child(2)'}\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "description": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#\\\\39 21277609-0 > div > div:nth-child(2)'}\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "description": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': '#\\\\39 21277609-0 > div > div:nth-child(2)'}\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "description": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 1,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.dry",
        "description": "src.jobs.slave_page.pages.brazil.truesource.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df['name'] = df['name'].str.replace(' - True Source', '')\n    df['name'] = df['name'].str.replace('True Source', '')\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.dry",
        "description": "src.jobs.slave_page.pages.brazil.truesource.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('div', class_='w-full lg:max-w-[260px]')\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='flex items-center justify-center relative h-full bg-ice')\n    product_url = conf[\"url\"] + product_link_element['href'] if product_link_element else None\n    return product_url\ndef get_title(conf, soup):\n    title_element = soup.find('h3', class_='text-dark text-sm text-ellipsis font-bold line-clamp-2 h-10')\n    title = title_element.get_text(strip=True) if title_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a', class_='flex items-center justify-center relative h-full bg-ice')\n    product_url = conf[\"url\"] + product_link_element['href'] if product_link_element else None\n    return product_url\ndef get_title(conf, soup):\n    title_element = soup.find('h3', class_='text-dark text-sm text-ellipsis font-bold line-clamp-2 h-10')\n    title = title_element.get_text(strip=True) if title_element else None\n    return title\ndef get_price(conf, soup):\n    price_element = soup.find('span', class_='text-dark text-xs lg:text-sm')",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('h3', class_='text-dark text-sm text-ellipsis font-bold line-clamp-2 h-10')\n    title = title_element.get_text(strip=True) if title_element else None\n    return title\ndef get_price(conf, soup):\n    price_element = soup.find('span', class_='text-dark text-xs lg:text-sm')\n    price = price_element.get_text(strip=True) if price_element else None\n    return price\ndef get_image_url(conf, soup):\n    image_element = soup.find('img')",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    price_element = soup.find('span', class_='text-dark text-xs lg:text-sm')\n    price = price_element.get_text(strip=True) if price_element else None\n    return price\ndef get_image_url(conf, soup):\n    image_element = soup.find('img')\n    image_url = image_element['src'] if image_element else None\n    return image_url",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    image_element = soup.find('img')\n    image_url = image_element['src'] if image_element else None\n    return image_url",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.truesource.page_url",
        "description": "src.jobs.slave_page.pages.brazil.truesource.page_url",
        "peekOfCode": "def get_url(conf, url):\n    if (not conf[\"index\"]):\n        conf[\"index\"] = 1\n        return url + str(conf[\"index\"])\n    conf[\"index\"] += 1\n    return url + str(conf[\"index\"])",
        "detail": "src.jobs.slave_page.pages.brazil.truesource.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "peekOfCode": "JOB_NAME = \"under_labz\"\nBRAND = \"under labz\"\nURL = \"https://underlabz.com.br\"\nSTATUS = False\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "peekOfCode": "BRAND = \"under labz\"\nURL = \"https://underlabz.com.br\"\nSTATUS = False\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "peekOfCode": "URL = \"https://underlabz.com.br\"\nSTATUS = False\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "peekOfCode": "STATUS = False\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.5,\n    \"scroll_step\": 1000,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.3,\n    \"max_return\": 4000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.dry",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.dry",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('li', class_='collection-product-card')\n    return items\ndef get_product_url(conf, soup):\n    product_link_element = soup.find('a')\n    return conf[\"url\"] + product_link_element['href'] if product_link_element else None\ndef get_title(conf, soup):\n    title_element = soup.find('h3', class_='card__title')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_link_element = soup.find('a')\n    return conf[\"url\"] + product_link_element['href'] if product_link_element else None\ndef get_title(conf, soup):\n    title_element = soup.find('h3', class_='card__title')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    # Busca o elemento de preo na seo de preos em promoo\n    price_element = soup.find('span', class_='price-item price-item--sale')\n    # Caso no haja preo em promoo, busca o preo regular",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('h3', class_='card__title')\n    return title_element.get_text().strip() if title_element else None\ndef get_price(conf, soup):\n    # Busca o elemento de preo na seo de preos em promoo\n    price_element = soup.find('span', class_='price-item price-item--sale')\n    # Caso no haja preo em promoo, busca o preo regular\n    if not price_element:\n        price_element = soup.find('span', class_='price-item price-item--regular')\n    return price_element.get_text().strip() if price_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    # Busca o elemento de preo na seo de preos em promoo\n    price_element = soup.find('span', class_='price-item price-item--sale')\n    # Caso no haja preo em promoo, busca o preo regular\n    if not price_element:\n        price_element = soup.find('span', class_='price-item price-item--regular')\n    return price_element.get_text().strip() if price_element else None\ndef get_image_url(conf, soup):\n    image_element = soup.find('img', class_='motion-reduce media--first')\n    return \"https:\" + image_element['src'] if image_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    image_element = soup.find('img', class_='motion-reduce media--first')\n    return \"https:\" + image_element['src'] if image_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.under_labz.page_url",
        "description": "src.jobs.slave_page.pages.brazil.under_labz.page_url",
        "peekOfCode": "def get_url(conf, url):\n    return url",
        "detail": "src.jobs.slave_page.pages.brazil.under_labz.page_url",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "peekOfCode": "JOB_NAME = \"vitafor\"\nBRAND = \"vitafor\"\nURL = \"https://www.vitafor.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(4) > div > section > div > div > div > div.vitafor-store-theme-9-x-description'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "documentation": {}
    },
    {
        "label": "BRAND",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "peekOfCode": "BRAND = \"vitafor\"\nURL = \"https://www.vitafor.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(4) > div > section > div > div > div > div.vitafor-store-theme-9-x-description'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "peekOfCode": "URL = \"https://www.vitafor.com.br\"\nSTATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(4) > div > section > div > div > div > div.vitafor-store-theme-9-x-description'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "documentation": {}
    },
    {
        "label": "STATUS",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "peekOfCode": "STATUS = True\nUSER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(4) > div > section > div > div > div > div.vitafor-store-theme-9-x-description'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(4) > div'},",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "peekOfCode": "USER_AGENT = None\nPRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(4) > div > section > div > div > div > div.vitafor-store-theme-9-x-description'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(4) > div'},\n]",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DESCRIPTION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "peekOfCode": "PRODUCT_DESCRIPTION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(4) > div > section > div > div > div > div.vitafor-store-theme-9-x-description'},\n]\nPRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(4) > div'},\n]\nDYNAMIC_SCROLL = {",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "peekOfCode": "PRODUCT_NUTRICIONAL_TABLE_TAG_MAP = [\n    {'tag': None, 'path': ''},\n]\nPRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(4) > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.7,\n    \"scroll_step\": 1500,",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "documentation": {}
    },
    {
        "label": "PRODUCT_DEFINITION_TAG_MAP",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "peekOfCode": "PRODUCT_DEFINITION_TAG_MAP = [\n    {'tag': None, 'path': 'body > div.render-container.render-route-store-product > div > div.vtex-store__template.bg-base > div > div > div > div:nth-child(5) > div > div:nth-child(4) > div'},\n]\nDYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.7,\n    \"scroll_step\": 1500,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.1,\n    \"max_return\": 2000,",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "documentation": {}
    },
    {
        "label": "DYNAMIC_SCROLL",
        "kind": 5,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "peekOfCode": "DYNAMIC_SCROLL = {\n    \"start_time_sleep\": 1,\n    \"time_sleep\": 0.7,\n    \"scroll_step\": 1500,\n    \"percentage\": 0.07,\n    \"return_percentage\": 0.1,\n    \"max_return\": 2000,\n    \"max_attempts\": 3\n}",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.conf",
        "documentation": {}
    },
    {
        "label": "create_products_transform_csl",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.dry",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.dry",
        "peekOfCode": "def create_products_transform_csl():\n    df = read_df(CONF['path_products_extract_csl'], dtype={'ref': str})\n    df = transform(CONF, df)\n    df['name'] = df['name'].str.replace(' - vitafor', '')\n    df.to_csv(CONF['path_products_transform_csl'], index=False)\n    print(\"Success in saving products_transform_csl\")\ndef dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.dry",
        "documentation": {}
    },
    {
        "label": "dry",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.dry",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.dry",
        "peekOfCode": "def dry(conf):\n    global CONF\n    CONF = conf\n    print(\"Data Dry\")\n    create_products_transform_csl()",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.dry",
        "documentation": {}
    },
    {
        "label": "get_items",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "peekOfCode": "def get_items(conf, soup):\n    items = soup.find_all('section', class_='vtex-product-summary-2-x-container')\n    return items\ndef get_product_url(conf, soup):\n    product_element = soup.find(class_='vtex-product-summary-2-x-clearLink')\n    product_link = conf[\"url\"] + product_element['href'] if product_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('h3', class_='vtex-product-summary-2-x-productNameContainer')\n    title = title_element.get_text().strip() if title_element else None",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "documentation": {}
    },
    {
        "label": "get_product_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "peekOfCode": "def get_product_url(conf, soup):\n    product_element = soup.find(class_='vtex-product-summary-2-x-clearLink')\n    product_link = conf[\"url\"] + product_element['href'] if product_element else None\n    return product_link\ndef get_title(conf, soup):\n    title_element = soup.find('h3', class_='vtex-product-summary-2-x-productNameContainer')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    # Encontra o continer que contm o preo",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "documentation": {}
    },
    {
        "label": "get_title",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "peekOfCode": "def get_title(conf, soup):\n    title_element = soup.find('h3', class_='vtex-product-summary-2-x-productNameContainer')\n    title = title_element.get_text().strip() if title_element else None\n    return title\ndef get_price(conf, soup):\n    # Encontra o continer que contm o preo\n    price_container = soup.find('span', class_='vitafor-store-theme-9-x-customPrice')\n    if price_container:\n        # Captura o texto do preo e remove espaos extras\n        price = price_container.get_text(strip=True)",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "documentation": {}
    },
    {
        "label": "get_price",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "peekOfCode": "def get_price(conf, soup):\n    # Encontra o continer que contm o preo\n    price_container = soup.find('span', class_='vitafor-store-theme-9-x-customPrice')\n    if price_container:\n        # Captura o texto do preo e remove espaos extras\n        price = price_container.get_text(strip=True)\n        return price\n    else:\n        return None\ndef get_image_url(conf, soup):",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "documentation": {}
    },
    {
        "label": "get_image_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "peekOfCode": "def get_image_url(conf, soup):\n    image_element = soup.find('img', class_='vtex-product-summary-2-x-imageNormal')\n    image_link = image_element['src'] if image_element else None\n    return image_link",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.page_elements",
        "documentation": {}
    },
    {
        "label": "get_url",
        "kind": 2,
        "importPath": "src.jobs.slave_page.pages.brazil.vitafor.page_url",
        "description": "src.jobs.slave_page.pages.brazil.vitafor.page_url",
        "peekOfCode": "def get_url(conf, url):\n    return url",
        "detail": "src.jobs.slave_page.pages.brazil.vitafor.page_url",
        "documentation": {}
    },
    {
        "label": "crawler",
        "kind": 2,
        "importPath": "src.lib.extract.crawler",
        "description": "src.lib.extract.crawler",
        "peekOfCode": "def crawler(page, url):\n    message(\"exec crawler\")\n    if ((\"driver\" not in page.conf.keys()) or (not page.conf[\"driver\"])):\n        message(\"initialize_selenium\")\n        page.conf[\"driver\"] = se.initialize_selenium(page.conf)\n    load_page(page, url)\ndef load_page(page, url):\n    message(\"exec load_page\")\n    driver = page.conf[\"driver\"]\n    if (page.conf['products_update']):",
        "detail": "src.lib.extract.crawler",
        "documentation": {}
    },
    {
        "label": "load_page",
        "kind": 2,
        "importPath": "src.lib.extract.crawler",
        "description": "src.lib.extract.crawler",
        "peekOfCode": "def load_page(page, url):\n    message(\"exec load_page\")\n    driver = page.conf[\"driver\"]\n    if (page.conf['products_update']):\n        message(\"PRODUCTS_UPDATE\")\n        element_selector = None\n        se.load_url(driver, url, element_selector)\n        time_sleep = page.conf['dynamic_scroll']['time_sleep']\n        scroll_step = page.conf['dynamic_scroll']['scroll_step']\n        percentage = page.conf['dynamic_scroll']['percentage']",
        "detail": "src.lib.extract.crawler",
        "documentation": {}
    },
    {
        "label": "extract_data",
        "kind": 2,
        "importPath": "src.lib.extract.crawler",
        "description": "src.lib.extract.crawler",
        "peekOfCode": "def extract_data(page, soup):\n    message(\"exec extract_data\")\n    path_products_extract_temp = page.conf['path_products_extract_temp']\n    df_products_temp = create_or_read_df(path_products_extract_temp, page.conf['df_products'].columns)\n    size_products_temp = len(df_products_temp)\n    items = page.get_items(soup)\n    size_items = len(items)\n    message(f\"size_items = {size_items}\")\n    page.conf['size_items'] = size_items\n    if (size_items == 0):",
        "detail": "src.lib.extract.crawler",
        "documentation": {}
    },
    {
        "label": "extract",
        "kind": 2,
        "importPath": "src.lib.extract.extract",
        "description": "src.lib.extract.extract",
        "peekOfCode": "def extract(conf: dict):\n    message(\"EXTRACT\")\n    page = Page(conf)\n    if (conf['exec_flag'] == \"new_page\"):\n        message(\"initializing_new_page\")\n        delete_directory_and_contents(f\"{conf[\"data_path\"]}/*\")\n        conf[\"products_update\"] = True\n        products_update(page)\n        conf[\"products_update\"] = False\n        conf[\"products_metadata_update\"] = True",
        "detail": "src.lib.extract.extract",
        "documentation": {}
    },
    {
        "label": "products_update",
        "kind": 2,
        "importPath": "src.lib.extract.extract",
        "description": "src.lib.extract.extract",
        "peekOfCode": "def products_update(page):\n    seed_path = page.conf['seed_path'] + \"/seed.json\"\n    seeds = read_json(seed_path)\n    delete_file(page.conf['path_products_extract_temp'])\n    columns = [\"ref\", \"title\" ,\"price\" ,\"image_url\", \"product_url\", \"ing_date\"]\n    df_products = create_or_read_df(page.conf['path_products_extract_csl'], columns)\n    data_atual = date.today()\n    page.conf['formatted_date'] = data_atual.strftime(DATE_FORMAT)\n    page.conf['df_products'] = df_products\n    page.conf[\"size_items\"] = 0",
        "detail": "src.lib.extract.extract",
        "documentation": {}
    },
    {
        "label": "products_metadata_update",
        "kind": 2,
        "importPath": "src.lib.extract.extract",
        "description": "src.lib.extract.extract",
        "peekOfCode": "def products_metadata_update(page):\n    message(\"products_metadata_update\")\n    page.conf['path_products_extract_csl'] = f\"{page.conf['data_path']}/products_extract_csl.csv\"\n    df_products_extract_csl = read_df(page.conf['path_products_extract_csl'], dtype={'ref': str})\n    urls = df_products_extract_csl['product_url'].values\n    for value, url in enumerate(urls):\n        size_urls = len(urls) - 1\n        message(f\"seed: {url}\")\n        message(f\"index: {value} / {size_urls}\")\n        crawler(page, url)",
        "detail": "src.lib.extract.extract",
        "documentation": {}
    },
    {
        "label": "products_metadata_update_old_pages",
        "kind": 2,
        "importPath": "src.lib.extract.extract",
        "description": "src.lib.extract.extract",
        "peekOfCode": "def products_metadata_update_old_pages(page):\n    message(\"PRODUCTS_METADATA_UPDATE_OLD_PAGES\")\n    products_extract_csl = f\"{page.conf['data_path']}/products_extract_csl.csv\"\n    page.conf['path_products_extract_csl'] = products_extract_csl\n    df_products_extract_csl = read_df(products_extract_csl, dtype={'ref': str})\n    pagas_path = page.conf['data_path'] + \"/products\"\n    old_files = get_old_files_by_percent(pagas_path, True, 5)\n    refs = [i.replace(\".txt\", \"\") for i in old_files]\n    df_products_extract_csl = df_products_extract_csl[df_products_extract_csl['ref'].isin(refs)]\n    refs_to_delete = list(set(refs) - set(df_products_extract_csl['ref']))",
        "detail": "src.lib.extract.extract",
        "documentation": {}
    },
    {
        "label": "products_metadata_update_old_pages_by_ref",
        "kind": 2,
        "importPath": "src.lib.extract.extract",
        "description": "src.lib.extract.extract",
        "peekOfCode": "def products_metadata_update_old_pages_by_ref(conf: dict, Page: object, url: str):\n    message(\"update_old_page by ref if page is with error in tags\")\n    conf[\"scroll_page\"] = True\n    conf[\"status_job\"] = False\n    conf[\"products_metadata_update\"] = True\n    conf[\"products_update\"] = False\n    page = Page(conf)\n    message(f\"seed: {url}\")\n    crawler(page, url)\ndef products_metadata_create_pages_if_not_exist(page):",
        "detail": "src.lib.extract.extract",
        "documentation": {}
    },
    {
        "label": "products_metadata_create_pages_if_not_exist",
        "kind": 2,
        "importPath": "src.lib.extract.extract",
        "description": "src.lib.extract.extract",
        "peekOfCode": "def products_metadata_create_pages_if_not_exist(page):\n    message(\"PRODUCTS_METADATA_CREATE_PAGES_IF_NOT_EXIST\")\n    products_extract_csl = f\"{page.conf['data_path']}/products_extract_csl.csv\"\n    page.conf['path_products_extract_csl'] = products_extract_csl\n    df_products_extract_csl = read_df(products_extract_csl, dtype={'ref': str})\n    pagas_path = page.conf['data_path'] + \"/products\"\n    all_pages = [i for i in list_directory(pagas_path)]\n    refs = [f\"{i}.txt\" for i in df_products_extract_csl['ref'].values]\n    pages_to_create = [i.replace(\".txt\", \"\") for i in refs if i not in all_pages]\n    df_products_extract_csl = df_products_extract_csl[df_products_extract_csl[\"ref\"].isin(pages_to_create)]",
        "detail": "src.lib.extract.extract",
        "documentation": {}
    },
    {
        "label": "Page",
        "kind": 6,
        "importPath": "src.lib.extract.page_elements",
        "description": "src.lib.extract.page_elements",
        "peekOfCode": "class Page():\n    def __init__(self, conf) -> None:\n        self.conf = conf\n        self.conf[\"index\"] = None\n        page_type = self.conf[\"page_type\"]\n        country = self.conf[\"country\"]\n        page_name = self.conf[\"page_name\"]\n        page_elements_str = f\"src.jobs.slave_page.pages.{country}.{page_name}.page_elements\"\n        self.page_elements = importlib.import_module(page_elements_str)\n        page_url_str = f\"src.jobs.slave_page.pages.{country}.{page_name}.page_url\"",
        "detail": "src.lib.extract.page_elements",
        "documentation": {}
    },
    {
        "label": "initialize_selenium",
        "kind": 2,
        "importPath": "src.lib.extract.selenium_service",
        "description": "src.lib.extract.selenium_service",
        "peekOfCode": "def initialize_selenium(conf):\n    options = webdriver.ChromeOptions()\n    display = os.getenv('DISPLAY')\n    message(f\"DISPLAY - {display}\")\n    options.add_argument(\"--no-sandbox\")\n    options.add_argument(\"--disable-dev-shm-usage\")\n    options.add_argument(\"--disable-software-rasterizer\")\n    options.add_argument(\"--disable-gpu\")\n    options.add_argument(\"--remote-debugging-port=9222\")\n    options.add_argument(\"--window-size=1920,1080\")",
        "detail": "src.lib.extract.selenium_service",
        "documentation": {}
    },
    {
        "label": "get_desktop_user_agent",
        "kind": 2,
        "importPath": "src.lib.extract.selenium_service",
        "description": "src.lib.extract.selenium_service",
        "peekOfCode": "def get_desktop_user_agent():\n    ua = UserAgent()\n    user_agent = ua.random\n    # Repetir at que obtenhamos um user-agent que no seja de dispositivos mveis\n    while 'Mobile' in user_agent or 'Android' in user_agent or 'iPhone' in user_agent:\n        user_agent = ua.random\n    return user_agent\ndef load_url(driver, url, element_selector=None, timeout=30):\n    driver.get(url)\n    driver.implicitly_wait(100)",
        "detail": "src.lib.extract.selenium_service",
        "documentation": {}
    },
    {
        "label": "load_url",
        "kind": 2,
        "importPath": "src.lib.extract.selenium_service",
        "description": "src.lib.extract.selenium_service",
        "peekOfCode": "def load_url(driver, url, element_selector=None, timeout=30):\n    driver.get(url)\n    driver.implicitly_wait(100)\n    if element_selector:\n        try:\n            element_present = EC.presence_of_element_located((By.CSS_SELECTOR, element_selector))\n            WebDriverWait(driver, timeout).until(element_present)\n        except TimeoutException:\n            message(f\"Timed out waiting for element {element_selector} to be present\")\ndef get_page_source(driver, retry_delay=5):",
        "detail": "src.lib.extract.selenium_service",
        "documentation": {}
    },
    {
        "label": "get_page_source",
        "kind": 2,
        "importPath": "src.lib.extract.selenium_service",
        "description": "src.lib.extract.selenium_service",
        "peekOfCode": "def get_page_source(driver, retry_delay=5):\n    try:\n        message(\"Tentando obter a pgina atual...\")\n        page_html = driver.page_source\n        soup = BeautifulSoup(page_html, 'html.parser')\n        return soup, page_html  # Retorna o objeto BeautifulSoup se o page_source for obtido com sucesso\n    except WebDriverException as e:\n        message(f\"Erro ao obter o page_source: {e}. Tentando recarregar aps {retry_delay} segundos...\")\n        time.sleep(retry_delay)  # Espera antes de tentar novamente\n        try:",
        "detail": "src.lib.extract.selenium_service",
        "documentation": {}
    },
    {
        "label": "dynamic_scroll",
        "kind": 2,
        "importPath": "src.lib.extract.selenium_service",
        "description": "src.lib.extract.selenium_service",
        "peekOfCode": "def dynamic_scroll(driver, time_sleep=0.7, scroll_step=1000, percentage=0.06, return_percentage=0.3, max_return=4000, max_attempts=3):\n    total_height = driver.execute_script(\"return document.body.scrollHeight\")\n    scroll_increment = min(total_height * percentage, scroll_step)\n    last_scrolled_height = 0\n    attempt_count = 0  # Contador para rastrear tentativas sem mudana na posio de rolagem\n    # Obtenha o primeiro elemento visvel para mover o mouse at ele (usando o body como exemplo)\n    body_element = driver.find_element(By.TAG_NAME, \"body\")\n    action = ActionChains(driver)\n    while True:\n        driver.execute_script(f\"window.scrollBy(0, {scroll_increment});\")",
        "detail": "src.lib.extract.selenium_service",
        "documentation": {}
    },
    {
        "label": "retry_on_failure",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def retry_on_failure(max_retries, wait_seconds):\n    def decorator_retry(func):\n        @functools.wraps(func)\n        def wrapper_retry(*args, **kwargs):\n            retries = 0\n            while True:\n                try:\n                    return func(*args, **kwargs)\n                except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:\n                    retries += 1",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "test_connection",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def test_connection() -> None:\n    \"\"\"\n    Testa a conexo com a API da Shopify.\n    \"\"\"\n    url = f\"{BASE_URL}products.json\"\n    response = requests.get(url, headers=HEADERS)\n    if response.status_code == 200:\n        message(\"Conexo bem-sucedida! A API est acessvel.\")\n        return True\n    else:",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "format_product_for_shopify",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def format_product_for_shopify(row: pd.Series) -> Tuple[dict, dict]:\n    \"\"\"\n    Formata os dados de um produto para o formato esperado pela API da Shopify.\n    Returns:\n    - product_data: dict com dados do produto\n    - variant_data: dict com dados da variante\n    \"\"\"\n    try:\n        description_ai = None\n        path_description_ai = f\"{CONF[\"data_path\"]}/products/{row['ref']}_description_ai.txt\"",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "get_all_skus_with_product_ids",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def get_all_skus_with_product_ids() -> dict:\n    \"\"\"\n    Obtm todas as SKUs de todos os produtos da Shopify, incluindo o product_id e o vendor.\n    Returns:\n    - dict: Um dicionrio onde as chaves so SKUs e os valores so listas de dicionrios\n            contendo 'variant_id', 'product_id' e 'vendor'.\n    \"\"\"\n    try:\n        session = requests.Session()\n        session.headers.update(HEADERS)",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "find_duplicate_skus",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def find_duplicate_skus(sku_data: dict) -> dict:\n    \"\"\"\n    Encontra SKUs duplicadas no dicionrio de SKUs.\n    Args:\n    - sku_data (dict): O dicionrio retornado pela funo get_all_skus_with_product_ids.\n    Returns:\n    - dict: Um dicionrio onde as chaves so SKUs duplicadas e os valores so listas\n            de variantes (com 'variant_id', 'product_id', 'vendor') associadas a essa SKU.\n    \"\"\"\n    duplicate_skus = {}",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "delete_duplicates_products",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def delete_duplicates_products(duplicate_skus):\n    if duplicate_skus:\n        message(f\"Encontrado {len(duplicate_skus)} SKUs duplicadas.\")\n        # Deletar todos os produtos e variantes encontrados\n        session = requests.Session()\n        session.headers.update(HEADERS)\n        for sku, variants in duplicate_skus.items():\n            for variant in variants:\n                product_id = variant['product_id']\n                variant_id = variant['variant_id']",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "delete_extra_skus",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def delete_extra_skus(skus_to_delete: list):\n    if skus_to_delete:\n        message(f\"Encontrado {len(skus_to_delete)} SKUs para deletar.\")\n        session = requests.Session()\n        session.headers.update(HEADERS)\n        # Deletar todos os produtos e variantes encontrados\n        for item in skus_to_delete:\n            product_id = item['product_id']\n            variant_id = item['variant_id']\n            sku = item['sku']",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "delete_extra_skus",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def delete_extra_skus(skus_to_delete: list):\n    if skus_to_delete:\n        message(f\"Encontrado {len(skus_to_delete)} SKUs para deletar.\")\n        session = requests.Session()\n        session.headers.update(HEADERS)\n        # Deletar todos os produtos e variantes encontrados\n        for item in skus_to_delete:\n            product_id = item['product_id']\n            variant_id = item['variant_id']\n            sku = item['sku']",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "find_extra_skus_to_delete",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def find_extra_skus_to_delete(sku_data: dict, refs: list, brand: str) -> list:\n    \"\"\"\n    Encontra SKUs que esto na Shopify mas no esto na lista de 'refs', para um determinado 'brand' (vendor).\n    Args:\n    - sku_data (dict): Dicionrio retornado pela funo get_all_skus_with_product_ids.\n    - refs (list): Lista de SKUs que deveriam existir.\n    - brand (str): O 'vendor' (marca) para filtrar.\n    Returns:\n    - list: Lista de dicionrios com 'sku', 'variant_id', 'product_id' que precisam ser deletados.\n    \"\"\"",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "get_variant_count",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def get_variant_count(session, product_id):\n    \"\"\"\n    Obtm o nmero de variantes de um produto.\n    Args:\n    - session: Sesso de requisio autenticada.\n    - product_id: ID do produto.\n    Returns:\n    - int: Nmero de variantes do produto.\n    \"\"\"\n    response = session.get(f\"{BASE_URL}products/{product_id}.json\", params={\"fields\": \"variants\"})",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "delete_variant",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def delete_variant(session, variant_id):\n    \"\"\"\n    Deleta uma variante especfica.\n    Args:\n    - session: Sesso de requisio autenticada.\n    - variant_id: ID da variante a ser deletada.\n    \"\"\"\n    response = session.delete(f\"{BASE_URL}variants/{variant_id}.json\")\n    if response.status_code != 200:\n        message(f\"Erro ao deletar variante {variant_id}: {response.status_code} - {response.text}\")",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "delete_product",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def delete_product(session, product_id):\n    \"\"\"\n    Deleta um produto especfico.\n    Args:\n    - session: Sesso de requisio autenticada.\n    - product_id: ID do produto a ser deletado.\n    \"\"\"\n    response = session.delete(f\"{BASE_URL}products/{product_id}.json\")\n    if response.status_code != 200:\n        message(f\"Erro ao deletar produto {product_id}: {response.status_code} - {response.text}\")",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "update_product_by_sku",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def update_product_by_sku(sku: str, product_data: dict, variant_data: dict, row: pd.Series, sku_data: dict) -> bool:\n    session = requests.Session()\n    session.headers.update(HEADERS)\n    if sku in sku_data:\n        variants = sku_data[sku]\n        product_id = variants[0]['product_id']\n        variant_id = variants[0]['variant_id']\n        # Atualiza o produto\n        product_success = update_product(session, product_id, product_data)\n        # Atualiza a variante",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "update_product",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def update_product(session, product_id: int, product_data: dict) -> bool:\n    url = f\"{BASE_URL}products/{product_id}.json\"\n    product_data['id'] = product_id\n    response = session.put(url, json={\"product\": product_data})\n    if response.status_code == 200:\n        message(f\"Produto {product_id} atualizado com sucesso.\")\n        return True\n    else:\n        error_message = response.json().get('errors', response.text)\n        message(f\"Erro ao atualizar o produto {product_id}: {response.status_code} - {error_message}\")",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "update_images",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def update_images(session, product_id: int, row: pd.Series) -> bool:\n    \"\"\"\n    Atualiza as imagens de um produto na Shopify, garantindo que apenas a nova imagem esteja associada ao produto.\n    \"\"\"\n    try:\n        # Obtm as imagens atuais do produto\n        response = session.get(f\"{BASE_URL}products/{product_id}/images.json\")\n        if response.status_code != 200:\n            message(f\"Erro ao obter imagens do produto {product_id}: {response.status_code} - {response.text}\")\n            return False",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "update_collections",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def update_collections(session, product_id: int, row: pd.Series) -> bool:\n    \"\"\"\n    Adiciona o produto a uma coleo manual na Shopify.\n    \"\"\"\n    try:\n        collection_title = row['collections_homepage'] if pd.notna(row['collections_homepage']) else \"Sem coleo\"\n        # Obtm todas as colees manuais (Custom Collections)\n        response = session.get(f\"{BASE_URL}custom_collections.json\", params={\"title\": collection_title})\n        if response.status_code != 200:\n            message(f\"Erro ao obter colees: {response.status_code} - {response.text}\")",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "update_variant",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def update_variant(session, product_id: int, variant_id: int, variant_data: dict) -> bool:\n    url = f\"{BASE_URL}variants/{variant_id}.json\"\n    variant_data['id'] = variant_id\n    response = session.put(url, json={\"variant\": variant_data})\n    if response.status_code == 200:\n        message(f\"Variante {variant_id} do produto {product_id} atualizada com sucesso.\")\n        return True\n    else:\n        try:\n            error_message = response.json().get('errors', response.text)",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "create_product",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def create_product(product_data: dict):\n    \"\"\"\n    Cria um novo produto na Shopify com os dados fornecidos.\n    Args:\n    - product_data (dict): Dados formatados do produto para criao.\n    Returns:\n    - dict: O produto criado retornado pela API Shopify, ou None em caso de erro.\n    \"\"\"\n    session = requests.Session()\n    session.headers.update(HEADERS)",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "get_product_by_sku",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def get_product_by_sku(sku: str):\n    \"\"\"\n    Obtm o produto com base no SKU.\n    \"\"\"\n    session = requests.Session()\n    session.headers.update(HEADERS)\n    params = {\n        \"fields\": \"id,variants\",\n        \"limit\": 250,\n        \"variants.sku\": sku",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "process_and_ingest_products",
        "kind": 2,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "def process_and_ingest_products(conf: dict, df: pd.DataFrame, refs: list, brand: str) -> None:\n    global CONF\n    CONF = conf\n    is_connected = test_connection()\n    if not is_connected:\n        raise ValueError(\"Sem conexo com a Shopify\") \n    sku_data = get_all_skus_with_product_ids()\n    # Encontra SKUs duplicadas e deleta\n    duplicate_skus = find_duplicate_skus(sku_data)\n    delete_duplicates_products(duplicate_skus)",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "MAX_RETRIES",
        "kind": 5,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "MAX_RETRIES = 3  # Nmero mximo de tentativas\nWAIT_SECONDS = 3  # Tempo de espera entre as tentativas em segundos\n@retry_on_failure(MAX_RETRIES, WAIT_SECONDS)\ndef test_connection() -> None:\n    \"\"\"\n    Testa a conexo com a API da Shopify.\n    \"\"\"\n    url = f\"{BASE_URL}products.json\"\n    response = requests.get(url, headers=HEADERS)\n    if response.status_code == 200:",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "WAIT_SECONDS",
        "kind": 5,
        "importPath": "src.lib.load.connection.shopify",
        "description": "src.lib.load.connection.shopify",
        "peekOfCode": "WAIT_SECONDS = 3  # Tempo de espera entre as tentativas em segundos\n@retry_on_failure(MAX_RETRIES, WAIT_SECONDS)\ndef test_connection() -> None:\n    \"\"\"\n    Testa a conexo com a API da Shopify.\n    \"\"\"\n    url = f\"{BASE_URL}products.json\"\n    response = requests.get(url, headers=HEADERS)\n    if response.status_code == 200:\n        message(\"Conexo bem-sucedida! A API est acessvel.\")",
        "detail": "src.lib.load.connection.shopify",
        "documentation": {}
    },
    {
        "label": "image_ingestion",
        "kind": 2,
        "importPath": "src.lib.load.image_ingestion",
        "description": "src.lib.load.image_ingestion",
        "peekOfCode": "def image_ingestion(df, conf):\n    global CONF\n    CONF = conf\n    file_path = CONF['data_path']\n    images_path = file_path + \"/img_csl/\"\n    dataindex_img_path = os.getenv('DATAINDEX_IMG_PATH')\n    images_server_path = dataindex_img_path + \"/imgs\"\n    git_pull(dataindex_img_path)\n    if not os.path.exists(images_server_path):\n        os.makedirs(images_server_path)",
        "detail": "src.lib.load.image_ingestion",
        "documentation": {}
    },
    {
        "label": "git_pull",
        "kind": 2,
        "importPath": "src.lib.load.image_ingestion",
        "description": "src.lib.load.image_ingestion",
        "peekOfCode": "def git_pull(project_dir):\n    try:\n        original_dir = os.getcwd()\n        os.chdir(project_dir)\n        subprocess.check_call(['git', 'checkout', '.'])\n        subprocess.check_call(['git', 'pull'])\n        print(\"Successful pull.\")\n    except subprocess.CalledProcessError as e:\n        print(f\"Error when running Git command: {e}\")\n    except Exception as e:",
        "detail": "src.lib.load.image_ingestion",
        "documentation": {}
    },
    {
        "label": "git_push",
        "kind": 2,
        "importPath": "src.lib.load.image_ingestion",
        "description": "src.lib.load.image_ingestion",
        "peekOfCode": "def git_push(project_dir):\n    original_dir = os.getcwd()\n    try:\n        os.chdir(project_dir)\n        if os.system('git add .') != 0:\n            print(\"Error staging files.\")\n            return\n        if os.system('git diff --cached --exit-code') == 0:\n            print(\"No changes to commit.\")\n            return",
        "detail": "src.lib.load.image_ingestion",
        "documentation": {}
    },
    {
        "label": "load",
        "kind": 2,
        "importPath": "src.lib.load.load",
        "description": "src.lib.load.load",
        "peekOfCode": "def load(conf):\n    # Carregar os DataFrames e adicionar a coluna 'transform'\n    df_products_transform_csl = read_df(conf['path_products_transform_csl'], dtype={'ref': str})\n    df_products_transform_csl['is_transform_data'] = 1\n    df_products_load_csl = create_or_read_df(conf['path_products_load_csl'], df_products_transform_csl.columns)\n    if (not df_products_load_csl.empty):\n        df_products_load_csl['is_transform_data'] = 0\n        # Unir os DataFrames\n        df_union = pd.concat([df_products_transform_csl, df_products_load_csl])\n        # Remover a coluna 'is_transform_data' apenas para identificar duplicatas",
        "detail": "src.lib.load.load",
        "documentation": {}
    },
    {
        "label": "load_product_info",
        "kind": 2,
        "importPath": "src.lib.transform.product_info",
        "description": "src.lib.transform.product_info",
        "peekOfCode": "def load_product_info(df: pd.DataFrame, conf: Dict) -> None:\n    \"\"\"\n    Inicializa o processo de extrao de metadados de produtos a partir de um DataFrame.\n    Args:\n        df (pd.DataFrame): DataFrame contendo as informaes dos produtos.\n    \"\"\"\n    message(\"RUNNING MODEL PREP...\")\n    global CONF, DATA_PATH\n    CONF = conf\n    DATA_PATH = conf[\"data_path\"]",
        "detail": "src.lib.transform.product_info",
        "documentation": {}
    },
    {
        "label": "extract_metadata_from_page",
        "kind": 2,
        "importPath": "src.lib.transform.product_info",
        "description": "src.lib.transform.product_info",
        "peekOfCode": "def extract_metadata_from_page(df: pd.DataFrame) -> None:\n    \"\"\"\n    Percorre cada linha do DataFrame e extrai as informaes do produto.\n    Args:\n        df (pd.DataFrame): DataFrame contendo as informaes dos produtos.\n    \"\"\"\n    for idx, row in df.iterrows():\n        ref: str = str(row['ref'])\n        product_url: str = row['product_url']\n        # Definir caminhos de arquivos",
        "detail": "src.lib.transform.product_info",
        "documentation": {}
    },
    {
        "label": "fetch_product_page_html",
        "kind": 2,
        "importPath": "src.lib.transform.product_info",
        "description": "src.lib.transform.product_info",
        "peekOfCode": "def fetch_product_page_html(page_path: str, product_url: str, force: bool = None) -> Optional[str]:\n    \"\"\"\n    Tenta ler o HTML da pgina do produto, atualiza a pgina se no encontrar o arquivo.\n    Args:\n        page_path (str): Caminho do arquivo HTML do produto.\n        product_url (str): URL do produto.\n    Returns:\n        Optional[str]: Texto HTML da pgina do produto, ou None se no encontrado.\n    \"\"\"\n    html_text: Optional[str] = read_file(page_path)",
        "detail": "src.lib.transform.product_info",
        "documentation": {}
    },
    {
        "label": "extract_description_from_html",
        "kind": 2,
        "importPath": "src.lib.transform.product_info",
        "description": "src.lib.transform.product_info",
        "peekOfCode": "def extract_description_from_html(html_text: Optional[str]) -> Optional[str]:\n    \"\"\"\n    Extrai a descrio do produto do HTML utilizando as tags configuradas.\n    Args:\n        html_text (Optional[str]): Texto HTML da pgina do produto.\n    Returns:\n        Optional[str]: Descrio extrada do HTML, ou None se no encontrada.\n    \"\"\"\n    description = \"\"\n    if html_text:",
        "detail": "src.lib.transform.product_info",
        "documentation": {}
    },
    {
        "label": "format_product_description",
        "kind": 2,
        "importPath": "src.lib.transform.product_info",
        "description": "src.lib.transform.product_info",
        "peekOfCode": "def format_product_description(row: pd.Series, description: str) -> str:\n    \"\"\"\n    Formata a descrio do produto incluindo o ttulo e a marca.\n    Args:\n        row (pd.Series): Linha do DataFrame contendo as informaes do produto.\n        description (str): Descrio extrada do HTML.\n    Returns:\n        str: Descrio formatada do produto.\n    \"\"\"\n    return f\"Produto: {row['title']}\\nMarca: {row['brand']}\\nDescrio:\\n{description}\"",
        "detail": "src.lib.transform.product_info",
        "documentation": {}
    },
    {
        "label": "get_product_description",
        "kind": 2,
        "importPath": "src.lib.transform.product_info",
        "description": "src.lib.transform.product_info",
        "peekOfCode": "def get_product_description(html_text: str, tag_map: Dict[str, str]) -> Optional[str]:\n    \"\"\"\n    Extrai a descrio do produto de um HTML usando um seletor de tag.\n    Args:\n        html_text (str): Texto HTML da pgina do produto.\n        tag_map (Dict[str, str]): Mapeamento da tag contendo o seletor de caminho ('path').\n    Returns:\n        Optional[str]: Descrio do produto em texto simples ou None se no encontrado ou invlido.\n    \"\"\"\n    try:",
        "detail": "src.lib.transform.product_info",
        "documentation": {}
    },
    {
        "label": "transform",
        "kind": 2,
        "importPath": "src.lib.transform.transform",
        "description": "src.lib.transform.transform",
        "peekOfCode": "def transform(conf, df):\n    message(\"START TRANSFORM\")\n    message(\"Filtro de nulos\")\n    df = filter_nulls(df)\n    message(\"Aplicando filtros de nome|preo|marca\")\n    df = apply_generic_filters(df, conf)\n    message(\"Criando coluna quantidade\")\n    df = create_quantity_column(df)\n    message(\"Removendo produtos da blacklist\")\n    df = remove_blacklisted_products(df)",
        "detail": "src.lib.transform.transform",
        "documentation": {}
    },
    {
        "label": "create_product_definition_col",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def create_product_definition_col(df, conf):\n    message(\"criada colunas de descrio do produto\")\n    # load_product_info(df, conf)\n    df[\"product_definition\"] = None\n    for idx, row in df.iterrows():\n        ref: str = str(row['ref'])\n        description_ai_path = F\"{conf['data_path']}/products/{ref}_description_ai.txt\"\n        if path_exists(description_ai_path):\n            description_ai = read_file(description_ai_path)\n        else:",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "ensure_columns_exist",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def ensure_columns_exist(df, columns):\n    for column in columns:\n        if column not in df.columns:\n            df[column] = np.nan  # Adiciona a coluna com valores NaN (nulos)\n    return df\ndef filter_nulls(df):\n    \"\"\"Filter rows with null values in specific columns and save them to a CSV file.\"\"\"\n    return df.dropna(subset=['title', 'price', 'image_url']).reset_index(drop=True)\ndef apply_generic_filters(df, conf):\n    \"\"\"Apply various data cleaning and transformation filters.\"\"\"",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "filter_nulls",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def filter_nulls(df):\n    \"\"\"Filter rows with null values in specific columns and save them to a CSV file.\"\"\"\n    return df.dropna(subset=['title', 'price', 'image_url']).reset_index(drop=True)\ndef apply_generic_filters(df, conf):\n    \"\"\"Apply various data cleaning and transformation filters.\"\"\"\n    df['title_extract'] = df['title']\n    df['name'] = df['title'].str.lower()\n    df['price'] = df['price'].str.replace('R$', '').str.replace(' ', '')\n    df['brand'] = conf['brand']\n    df['price_numeric'] = df['price'].str.replace(',', '.').astype(float)",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "apply_generic_filters",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def apply_generic_filters(df, conf):\n    \"\"\"Apply various data cleaning and transformation filters.\"\"\"\n    df['title_extract'] = df['title']\n    df['name'] = df['title'].str.lower()\n    df['price'] = df['price'].str.replace('R$', '').str.replace(' ', '')\n    df['brand'] = conf['brand']\n    df['price_numeric'] = df['price'].str.replace(',', '.').astype(float)\n    df['title'] = df['title'].apply(clean_text).apply(remove_spaces)\n    return df\ndef create_quantity_column(df):",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "create_quantity_column",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def create_quantity_column(df):\n    \"\"\"Extract and convert quantity information into a uniform format.\"\"\"\n    # Garantir que sempre retornamos dois elementos para evitar o erro de tamanho de coluna\n    df['quantity_unit'] = df['name'].apply(lambda text: find_pattern_for_quantity(text))\n    # Separar a coluna 'quantity_unit' em 'quantity' e 'unit'\n    df[['quantity', 'unit']] = pd.DataFrame(df['quantity_unit'].tolist(), index=df.index)\n    # Aplicar converso para gramas\n    df['quantity'] = df[['quantity', 'unit']].apply(convert_to_grams, axis=1)\n    # Calcular o preo por quantidade\n    df['price_qnt'] = df.apply(relation_qnt_price, axis=1)",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "remove_blacklisted_products",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def remove_blacklisted_products(df):\n    \"\"\"Remove products based on a blacklist.\"\"\"\n    return df[~df['title'].apply(lambda x: find_in_text_with_wordlist(x, BLACK_LIST))]\ndef find_pattern_for_quantity(text):\n    pattern = r'(\\d+[.,]?\\d*)\\s*(kg|g|gr|gramas)'\n    matches = re.findall(pattern, text, re.IGNORECASE)\n    quantity, unit = None, None\n    if len(matches) == 1:\n        quantity, unit = matches[0]\n        quantity = str(quantity).replace(',', '.')",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "find_pattern_for_quantity",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def find_pattern_for_quantity(text):\n    pattern = r'(\\d+[.,]?\\d*)\\s*(kg|g|gr|gramas)'\n    matches = re.findall(pattern, text, re.IGNORECASE)\n    quantity, unit = None, None\n    if len(matches) == 1:\n        quantity, unit = matches[0]\n        quantity = str(quantity).replace(',', '.')\n        if unit in ['g', 'gr', 'gramas'] and \".\" in quantity:\n            quantity = quantity.replace(\".\", \"\")\n        quantity = float(quantity)",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "convert_to_grams",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def convert_to_grams(row):\n    value = row['quantity']\n    unit = row['unit']\n    if pd.notna(value):\n        if unit in ['kg']:\n            value = float(value) * 1000\n        try:\n            value = int(float(value))\n        except ValueError:\n            pass",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "relation_qnt_price",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def relation_qnt_price(row):\n    resultado = (row['price_numeric'] / row['quantity']) if (row['quantity'] > 0) else -1\n    if resultado < 0:\n        return np.nan\n    return round(resultado, 3)\ndef image_processing(df, data_path):\n    message(\"image_processing\")\n    path_img_tmp = data_path + \"/img_tmp/\"\n    path_img_hash = data_path + \"/img_hash/\"\n    path_img_csl = data_path + \"/img_csl/\"",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "image_processing",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def image_processing(df, data_path):\n    message(\"image_processing\")\n    path_img_tmp = data_path + \"/img_tmp/\"\n    path_img_hash = data_path + \"/img_hash/\"\n    path_img_csl = data_path + \"/img_csl/\"\n    create_directory_if_not_exists(path_img_hash)\n    create_directory_if_not_exists(path_img_csl)\n    refs = sorted(df['ref'])\n    dict_imgs = {i.split(\".\")[0]: i for i in list_directory(path_img_tmp) if i.split(\".\")[0] in refs}\n    dict_imgs = dict(sorted(dict_imgs.items(), key=lambda item: item[1]))",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "filter_df_price_when_alter_price",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def filter_df_price_when_alter_price(df, refs):\n    for ref in refs:\n        df_temp = df[df[\"ref\"] == ref].sort_values('ing_date')\n        last_price = False\n        for idx, row in df_temp.iterrows():\n            price = row['price_numeric']\n            is_alter_price = False\n            if ((not last_price) | bool(last_price != price)):\n                last_price = price\n                is_alter_price = True",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "create_price_discount_percent_col",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def create_price_discount_percent_col(df, data_path):\n    df_new = deepcopy(df)\n    refs = df['ref'].values\n    path = f\"{data_path}/history\"\n    df_temp = read_and_stack_historical_csvs_dataframes(path, False, dtype={'ref': str})\n    if (df_temp.empty):\n        df[\"price_discount_percent\"] = 0\n        df[\"compare_at_price\"] = None\n        return df\n    df_temp = df_temp[df_temp[\"ref\"].isin(refs)]",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "create_product_collection_col",
        "kind": 2,
        "importPath": "src.lib.transform.transform_functions",
        "description": "src.lib.transform.transform_functions",
        "peekOfCode": "def create_product_collection_col(df):\n    collections_homepage_flag = {\n        'whey': True, \n        'barrinha': True, \n        'creatina': True, \n        'pretreino': True\n    }\n    df[\"collections\"] = None\n    df[\"collections_homepage\"] = None\n    for idx, row in df.iterrows():",
        "detail": "src.lib.transform.transform_functions",
        "documentation": {}
    },
    {
        "label": "status_tag",
        "kind": 2,
        "importPath": "src.lib.utils.data_quality",
        "description": "src.lib.utils.data_quality",
        "peekOfCode": "def status_tag(page, data, kill_job=True):\n    errors = []\n    if not is_price(data[\"price\"]):\n        errors.append(\"ERRO: Invalid price format.\")\n    if not check_url_existence(data[\"image_url\"]):\n        errors.append(\"ERRO: Image URL does not exist.\")\n    if not check_url_existence(data[\"product_url\"]):\n        errors.append(\"ERRO: Product URL does not exist.\")\n    if errors:\n        for error in errors:",
        "detail": "src.lib.utils.data_quality",
        "documentation": {}
    },
    {
        "label": "data_history_analysis",
        "kind": 2,
        "importPath": "src.lib.utils.data_quality",
        "description": "src.lib.utils.data_quality",
        "peekOfCode": "def data_history_analysis(conf, df):\n    history_path = conf['data_path'] + \"/history\"\n    create_directory_if_not_exists(history_path)\n    if (not has_files(history_path)):\n        save_history_data(conf, df)\n        return True\n    message(\"CARREGANDO DATAFRAME HISTORICO...\")\n    message(history_path)\n    df_history = read_and_stack_historical_csvs_dataframes(history_path, True, dtype={'ref': str})\n    message(\"ANALISE volume\")",
        "detail": "src.lib.utils.data_quality",
        "documentation": {}
    },
    {
        "label": "volume_analysis",
        "kind": 2,
        "importPath": "src.lib.utils.data_quality",
        "description": "src.lib.utils.data_quality",
        "peekOfCode": "def volume_analysis(df_history, df, alert_threshold=0.1, error_threshold=0.2):\n    volume_history = len(df_history)\n    volume_current = len(df)\n    if volume_history == 0:\n        return True, True\n    volume_change = abs((volume_current / volume_history) - 1)\n    message(f\"volume_change: {volume_change}\")\n    volume_error = volume_change < error_threshold\n    volume_alert = volume_change < alert_threshold\n    return volume_error, volume_alert",
        "detail": "src.lib.utils.data_quality",
        "documentation": {}
    },
    {
        "label": "title_analysis",
        "kind": 2,
        "importPath": "src.lib.utils.data_quality",
        "description": "src.lib.utils.data_quality",
        "peekOfCode": "def title_analysis(df_history, df):\n    df_history_title = df_history[[\"ref\", \"title\"]]\n    df_title = df[[\"ref\", \"title\"]]\n    result_df_title = df_history_title.merge(df_title, on='ref', how='inner')\n    if (result_df_title.empty):\n        message(\"ERRO RESULT_DF_TITLE.EMPTY\")\n        return False, False, df\n    result_df_title['diff_percent'] = result_df_title.apply(lambda row: calc_string_diff_in_df_col(row['title_x'], row['title_y']), axis=1).astype(float)\n    threshold_erro = 0.60\n    threshold_alert = 0.20",
        "detail": "src.lib.utils.data_quality",
        "documentation": {}
    },
    {
        "label": "price_analysis",
        "kind": 2,
        "importPath": "src.lib.utils.data_quality",
        "description": "src.lib.utils.data_quality",
        "peekOfCode": "def price_analysis(df_history, df):\n    df_history_price = df_history.groupby('ref')['price_numeric'].agg(['mean', 'max', 'min']).reset_index()\n    df_price = df[['ref', 'price_numeric']]\n    result_df_price = df_history_price.merge(df_price, on='ref', how='inner')\n    result_df_price['diff_percent'] = abs((result_df_price['price_numeric'] / result_df_price['mean']) - 1)\n    threshold_erro = 0.70\n    threshold_alert = 0.40\n    result_df_price['price_erro'] = result_df_price['diff_percent'] <= threshold_erro\n    result_df_price['price_alert'] = result_df_price['diff_percent'] <= threshold_alert\n    df_erro = result_df_price.sort_values('diff_percent')",
        "detail": "src.lib.utils.data_quality",
        "documentation": {}
    },
    {
        "label": "save_history_data",
        "kind": 2,
        "importPath": "src.lib.utils.data_quality",
        "description": "src.lib.utils.data_quality",
        "peekOfCode": "def save_history_data(conf, df):\n    history_path = conf['data_path'] + \"/history\"\n    data_atual = date.today()\n    formatted_date = data_atual.strftime(DATE_FORMAT)\n    create_directory_if_not_exists(history_path)\n    df.to_csv(f\"{history_path}/products_load_csl_{formatted_date}.csv\", index=False)\n    message(f\"Saved historical data in {history_path}/products_load_csl_{formatted_date}.csv\")\ndef is_price(string):\n    if not isinstance(string, str):\n        return False",
        "detail": "src.lib.utils.data_quality",
        "documentation": {}
    },
    {
        "label": "is_price",
        "kind": 2,
        "importPath": "src.lib.utils.data_quality",
        "description": "src.lib.utils.data_quality",
        "peekOfCode": "def is_price(string):\n    if not isinstance(string, str):\n        return False\n    pattern = r\"\"\"\n    (R\\$\\s?\\d{1,3}(?:\\.\\d{3})*[,.]\\d{2})|  # BRL: R$\n    (\\s?\\d{1,3}(?:\\.\\d{3})*,\\d{2})|       # EUR: \n    (\\$\\s?\\d{1,3}(?:,\\d{3})*\\.\\d{2})|      # USD: $\n    (\\s?\\d{1,3}(?:,\\d{3})*\\.\\d{2})        # GBP: \n    \"\"\"\n    return bool(re.match(pattern, string, re.VERBOSE))",
        "detail": "src.lib.utils.data_quality",
        "documentation": {}
    },
    {
        "label": "format_column_date",
        "kind": 2,
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "peekOfCode": "def format_column_date(df, column):\n    df[column] = pd.to_datetime(df[column], format=DATE_FORMAT, dayfirst=True)\n    df[column] = df[column].dt.strftime(DATE_FORMAT)\n    return df\ndef create_or_read_df(path, columns=None, dtype=None):\n    message(f\"create_or_read_df\")\n    # Verifica se o arquivo existe\n    if os.path.exists(path):\n        # Verifica se o arquivo est vazio\n        if os.path.getsize(path) > 0:",
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "create_or_read_df",
        "kind": 2,
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "peekOfCode": "def create_or_read_df(path, columns=None, dtype=None):\n    message(f\"create_or_read_df\")\n    # Verifica se o arquivo existe\n    if os.path.exists(path):\n        # Verifica se o arquivo est vazio\n        if os.path.getsize(path) > 0:\n            message(f\"read file: {path}\")\n            try:\n                # L o arquivo CSV\n                if dtype:",
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_df",
        "kind": 2,
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "peekOfCode": "def read_df(path, dtype=None):\n    \"\"\"\n    Reads a DataFrame from a CSV file.\n    Parameters:\n    path (str): The path to the CSV file.\n    dtype (dict, optional): A dictionary specifying column data types.\n    Returns:\n    DataFrame: The DataFrame read from the CSV file.\n    \"\"\"\n    if path_exists(path):",
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "filter_dataframe_for_columns",
        "kind": 2,
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "peekOfCode": "def filter_dataframe_for_columns(df: pd.DataFrame, columns: List[str], keywords: List[str], blacklist: Optional[List[str]] = None) -> pd.DataFrame:\n    \"\"\"Filters a DataFrame for specified columns based on keywords and an optional blacklist to exclude certain terms\"\"\"\n    global_mask = pd.Series([False] * len(df), index=df.index)\n    for col in columns:\n        df[col] = df[col].astype(str).fillna('')\n        global_mask |= df[col].str.contains('|'.join(keywords), case=False)\n    filtered_df = df[global_mask]\n    if blacklist:\n        for col in columns:\n            blacklist_mask = ~filtered_df[col].str.contains('|'.join(blacklist), case=False)",
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "drop_duplicates_for_columns",
        "kind": 2,
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "peekOfCode": "def drop_duplicates_for_columns(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n    \"\"\"Drop duplicates based on specific columns\"\"\"\n    return df.drop_duplicates(subset=columns)\ndef calc_string_diff_in_df_col(title_x, title_y):\n    distance = levenshtein(title_x, title_y)\n    max_len = max(len(title_x), len(title_y))\n    percent_diff = (distance / max_len) if max_len != 0 else 0\n    return percent_diff\ndef read_and_stack_historical_csvs_dataframes(history_data_path, get_only_last, dtype=None):\n    # Usa glob para encontrar todos os arquivos CSV no diretrio",
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "calc_string_diff_in_df_col",
        "kind": 2,
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "peekOfCode": "def calc_string_diff_in_df_col(title_x, title_y):\n    distance = levenshtein(title_x, title_y)\n    max_len = max(len(title_x), len(title_y))\n    percent_diff = (distance / max_len) if max_len != 0 else 0\n    return percent_diff\ndef read_and_stack_historical_csvs_dataframes(history_data_path, get_only_last, dtype=None):\n    # Usa glob para encontrar todos os arquivos CSV no diretrio\n    csv_files = glob(os.path.join(history_data_path, '*.csv'))\n    csv_files = sorted(csv_files, reverse=True)\n    if get_only_last and csv_files:",
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_and_stack_historical_csvs_dataframes",
        "kind": 2,
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "peekOfCode": "def read_and_stack_historical_csvs_dataframes(history_data_path, get_only_last, dtype=None):\n    # Usa glob para encontrar todos os arquivos CSV no diretrio\n    csv_files = glob(os.path.join(history_data_path, '*.csv'))\n    csv_files = sorted(csv_files, reverse=True)\n    if get_only_last and csv_files:\n        # Encontra o arquivo CSV mais recentemente modificado\n        latest_file = csv_files[0]\n        message(latest_file)\n        return read_df(latest_file, dtype)\n    elif csv_files:",
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "read_and_stack_csvs_dataframes",
        "kind": 2,
        "importPath": "src.lib.utils.dataframe",
        "description": "src.lib.utils.dataframe",
        "peekOfCode": "def read_and_stack_csvs_dataframes(data_path: str, pages: list, file_name: str, dtype=None) -> pd.DataFrame:\n    pages_path = [f\"{data_path}/{page}\" for page in pages]\n    df_temp = []\n    for path in pages_path:\n        file_path = f\"{path}/{file_name}\"\n        if os.path.exists(file_path):\n            df_temp.append(read_df(file_path, dtype))\n        else:\n            print(f\"Arquivo {file_path} no encontrado, pulando para o prximo.\")\n    if df_temp:",
        "detail": "src.lib.utils.dataframe",
        "documentation": {}
    },
    {
        "label": "save_file",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def save_file(text, path):\n    create_file_if_not_exists(path, text)\n    with open(path, \"w\") as file:\n        message(\"file path: \" + path)\n        file.write(str(text))\ndef save_file_with_line_breaks(file_path, text):\n    # Quebra a string em linhas onde houver \\n\n    create_file_if_not_exists(file_path, text)\n    lines = text.split(\"\\n\")\n    # Abre o arquivo para escrita",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "save_file_with_line_breaks",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def save_file_with_line_breaks(file_path, text):\n    # Quebra a string em linhas onde houver \\n\n    create_file_if_not_exists(file_path, text)\n    lines = text.split(\"\\n\")\n    # Abre o arquivo para escrita\n    with open(file_path, \"w\") as file:\n        # Grava cada linha no arquivo\n        for line in lines:\n            file.write(line + \"\\n\") \ndef read_file(file_path):",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "read_file",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def read_file(file_path):\n    \"\"\"Reads a file and returns its contents as a string.\"\"\"\n    try:\n        with open(file_path, 'r') as file:\n            return file.read()\n    except FileNotFoundError:\n        return None\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return None",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "read_json",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def read_json(file_path: str) -> Optional[Any]:\n    \"\"\"Reads a JSON file and returns its content or None in case of an error.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as file:\n            return json.load(file)\n    except FileNotFoundError:\n        message(f\"The file {file_path} was not found.\")\n    except json.JSONDecodeError:\n        message(f\"Error decoding the JSON file {file_path}.\")\n    except Exception as e:",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "save_json",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def save_json(file_name: str, data: Any) -> None:\n    \"\"\"Saves data to a JSON file.\"\"\"\n    with open(file_name, 'w', encoding='utf-8') as file:\n        json.dump(data, file, ensure_ascii=False)\ndef delete_file(file_path: str) -> None:\n    \"\"\"Deletes a file if it exists, logging the outcome.\"\"\"\n    try:\n        os.remove(file_path)\n        message(f\"File {file_path} has been deleted successfully\")\n    except FileNotFoundError:",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "delete_file",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def delete_file(file_path: str) -> None:\n    \"\"\"Deletes a file if it exists, logging the outcome.\"\"\"\n    try:\n        os.remove(file_path)\n        message(f\"File {file_path} has been deleted successfully\")\n    except FileNotFoundError:\n        message(f\"The file {file_path} does not exist\")\n    except Exception as e:\n        message(f\"An error occurred: {e}\")\ndef file_modified_within_x_hours(file_path, hours):",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "file_modified_within_x_hours",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def file_modified_within_x_hours(file_path, hours):\n    # Check if the file exists\n    if not os.path.isfile(file_path):\n        message(\"File not exist\")\n        return False\n    # Get the current time\n    now = datetime.now()\n    # Get the last modification time of the file\n    last_modification = datetime.fromtimestamp(os.path.getmtime(file_path))\n    print(last_modification)",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "path_exists",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def path_exists(path: str) -> bool:\n    \"\"\"Checks if a path exists.\"\"\"\n    message(f\"check - {path}\")\n    return os.path.exists(path)\ndef create_file_if_not_exists(file_path: str, text: Optional[str] = None) -> None:\n    \"\"\"Creates a file if it doesn't exist. Optionally writes text to it.\"\"\"\n    if not path_exists(file_path):\n        try:\n            with open(file_path, mode='a', encoding='utf-8') as file:\n                if text:",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "create_file_if_not_exists",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def create_file_if_not_exists(file_path: str, text: Optional[str] = None) -> None:\n    \"\"\"Creates a file if it doesn't exist. Optionally writes text to it.\"\"\"\n    if not path_exists(file_path):\n        try:\n            with open(file_path, mode='a', encoding='utf-8') as file:\n                if text:\n                    file.write(text + \"\\n\")\n                    message(f\"write '{text}' successfully.\")\n                message(f\"File '{file_path}' created successfully.\")\n        except FileExistsError:",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "create_directory_if_not_exists",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def create_directory_if_not_exists(directory_path):\n    if not path_exists(directory_path):\n        try:\n            os.makedirs(directory_path)\n            message(f\"Directory '{directory_path}' created successfully.\")\n        except OSError as error:\n            message(f\"Error creating directory '{directory_path}': {error}\")\ndef download_image(image_url, image_path, image_name):\n    message(f\"Download: {image_url}\")\n    response = requests.get(image_url)",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "download_image",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def download_image(image_url, image_path, image_name):\n    message(f\"Download: {image_url}\")\n    response = requests.get(image_url)\n    if response.status_code == 200:\n        # Obtendo o tipo de contedo da resposta\n        content_type = response.headers['Content-Type']\n        # Determinando a extenso com base no tipo de contedo\n        if 'image/jpeg' in content_type:\n            extension = '.jpg'\n        elif 'image/png' in content_type:",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "save_images",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def save_images(image_urls, image_path, image_names):\n    with ThreadPoolExecutor(max_workers=10) as executor:\n        # Mapeia cada tarefa futura para a respectiva URL usando um dicionrio\n        future_to_url = {executor.submit(download_image, url, image_path, name): url for url, name in zip(image_urls, image_names)}\n        # Itera sobre as tarefas concludas conforme elas so finalizadas\n        for future in as_completed(future_to_url):\n            url = future_to_url[future]\n            try:\n                result = future.result()  # Obtm o resultado da tarefa\n                if result:",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "file_exists",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def file_exists(directory, filename):\n    file_path = os.path.join(directory, filename)\n    message(file_path)\n    return os.path.exists(file_path)\ndef file_exists_with_modification_time(directory, filename):\n    file_path = os.path.join(directory, filename)\n    if os.path.exists(file_path):\n        # Obtm o timestamp da ltima modificao do arquivo\n        modification_time = os.path.getmtime(file_path)\n        # Converte o timestamp para um formato de data legvel",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "file_exists_with_modification_time",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def file_exists_with_modification_time(directory, filename):\n    file_path = os.path.join(directory, filename)\n    if os.path.exists(file_path):\n        # Obtm o timestamp da ltima modificao do arquivo\n        modification_time = os.path.getmtime(file_path)\n        # Converte o timestamp para um formato de data legvel\n        readable_time = datetime.fromtimestamp(modification_time)\n        return True, readable_time  # Retorna True e a data de modificao\n    else:\n        return False, None  # Retorna False e None se o arquivo no existir",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "delete_directory_and_contents",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def delete_directory_and_contents(directory_path):\n    if not os.path.exists(directory_path):\n        message(\"Directory does not exist.\")\n        return\n    shutil.rmtree(directory_path)\n    message(f\"Directory and all contents deleted: {directory_path}\")\ndef get_old_files_by_percent(directory_path, sort_ascending=True, percentage=5):\n    all_files = [file for file in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, file))]\n    files_info = []\n    for file in all_files:",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "get_old_files_by_percent",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def get_old_files_by_percent(directory_path, sort_ascending=True, percentage=5):\n    all_files = [file for file in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, file))]\n    files_info = []\n    for file in all_files:\n        file_path = os.path.join(directory_path, file)\n        last_modification_time = os.path.getmtime(file_path)\n        last_modification_date = datetime.fromtimestamp(last_modification_time)\n        files_info.append((file, last_modification_date))\n    files_info.sort(key=lambda x: x[1], reverse=not sort_ascending)\n    files_count = len(files_info)",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "list_directory",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def list_directory(path):\n    try:\n        # Check if the path is a valid directory\n        if os.path.isdir(path):\n            contents = os.listdir(path)\n            message(f\"Contents of directory '{path}':\")\n            items = []\n            for item in contents:\n                items.append(item)\n            return items",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "has_files",
        "kind": 2,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "def has_files(directory):\n    items = os.listdir(directory)\n    for item in items:\n        item_path = os.path.join(directory, item)\n        if os.path.isfile(item_path):\n            return True\n    return False",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "DATE_FORMAT",
        "kind": 5,
        "importPath": "src.lib.utils.file_system",
        "description": "src.lib.utils.file_system",
        "peekOfCode": "DATE_FORMAT = \"%Y-%m-%d\"\ndef save_file(text, path):\n    create_file_if_not_exists(path, text)\n    with open(path, \"w\") as file:\n        message(\"file path: \" + path)\n        file.write(str(text))\ndef save_file_with_line_breaks(file_path, text):\n    # Quebra a string em linhas onde houver \\n\n    create_file_if_not_exists(file_path, text)\n    lines = text.split(\"\\n\")",
        "detail": "src.lib.utils.file_system",
        "documentation": {}
    },
    {
        "label": "get_pages_with_status_true",
        "kind": 2,
        "importPath": "src.lib.utils.general_functions",
        "description": "src.lib.utils.general_functions",
        "peekOfCode": "def get_pages_with_status_true(conf, return_job_name=True):\n    pages = list_directory(conf[\"pages_path\"])\n    pages_data_path = []\n    for page in pages:\n        module_name = f\"src.jobs.slave_page.pages.{conf['country']}.{page}.conf\"\n        page_conf = importlib.import_module(module_name)\n        if page_conf.STATUS:\n            value = page_conf.JOB_NAME if return_job_name else page_conf.BRAND\n            pages_data_path.append(value)\n    return sorted(pages_data_path)",
        "detail": "src.lib.utils.general_functions",
        "documentation": {}
    },
    {
        "label": "convert_image",
        "kind": 2,
        "importPath": "src.lib.utils.image_functions",
        "description": "src.lib.utils.image_functions",
        "peekOfCode": "def convert_image(image_path, save_path, output_format='webp'):\n    if (not os.path.isfile(image_path)):\n        raise FileNotFoundError(f\"The file {image_path} does not exist.\")\n    with Image.open(image_path) as img:\n        img.save(save_path + '.' + output_format, output_format.upper())\ndef calculate_precise_image_hash(image_path):\n    with open(image_path, \"rb\") as image_file:\n        image_data = image_file.read()\n        image_hash = hashlib.sha256(image_data).hexdigest()\n    return image_hash",
        "detail": "src.lib.utils.image_functions",
        "documentation": {}
    },
    {
        "label": "calculate_precise_image_hash",
        "kind": 2,
        "importPath": "src.lib.utils.image_functions",
        "description": "src.lib.utils.image_functions",
        "peekOfCode": "def calculate_precise_image_hash(image_path):\n    with open(image_path, \"rb\") as image_file:\n        image_data = image_file.read()\n        image_hash = hashlib.sha256(image_data).hexdigest()\n    return image_hash",
        "detail": "src.lib.utils.image_functions",
        "documentation": {}
    },
    {
        "label": "setup_logging",
        "kind": 2,
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "peekOfCode": "def setup_logging(log_file: str = 'app.log') -> None:\n    \"\"\"\n    Configura o sistema de logging para registrar mensagens em um arquivo e no console.\n    Args:\n        log_file (str): Caminho para o arquivo de log. Padro  'app.log'.\n    \"\"\"\n    # Configurao bsica para o arquivo de log\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(levelname)s - %(message)s',",
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "message",
        "kind": 2,
        "importPath": "src.lib.utils.log",
        "description": "src.lib.utils.log",
        "peekOfCode": "def message(msg: Union[str, Dict], level: str = 'info') -> None:\n    \"\"\"\n    Registra uma mensagem no log. Aceita strings ou dicionrios.\n    Args:\n        msg (Union[str, Dict]): Mensagem a ser registrada. Pode ser uma string ou um dicionrio.\n        level (str): Nvel de logging ('debug', 'info', 'warning', 'error', 'critical'). Padro  'info'.\n    \"\"\"\n    logger = logging.getLogger()\n    # Serializa dicionrios para JSON\n    if isinstance(msg, dict):",
        "detail": "src.lib.utils.log",
        "documentation": {}
    },
    {
        "label": "flatten_list",
        "kind": 2,
        "importPath": "src.lib.utils.py_functions",
        "description": "src.lib.utils.py_functions",
        "peekOfCode": "def flatten_list(list_of_lists):\n    if list_of_lists is None:\n        return []\n    flattened_list = []\n    for element in list_of_lists:\n        if isinstance(element, list):\n            for subelement in element:\n                flattened_list.append(subelement)\n        else:\n            flattened_list.append(element)",
        "detail": "src.lib.utils.py_functions",
        "documentation": {}
    },
    {
        "label": "find_in_text_with_wordlist",
        "kind": 2,
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "peekOfCode": "def find_in_text_with_wordlist(text, wordlist):\n    match = None\n    for word in wordlist:\n        clean_word = clean_text(word)\n        text = clean_text(text)\n        match = re.search(clean_word, clean_text(text))  # Expresso regular para encontrar dgitos\n        if match:\n            break\n    if match:\n        return True",
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "levenshtein",
        "kind": 2,
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "peekOfCode": "def levenshtein(s1, s2):\n    if len(s1) < len(s2):\n        return levenshtein(s2, s1)\n    if len(s2) == 0:\n        return len(s1)\n    previous_row = range(len(s2) + 1)\n    for i, c1 in enumerate(s1):\n        current_row = [i + 1]\n        for j, c2 in enumerate(s2):\n            insertions = previous_row[j + 1] + 1",
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "encode_to_base64",
        "kind": 2,
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "peekOfCode": "def encode_to_base64(value: str) -> str:\n    \"\"\"Encodes a string to Base64.\"\"\"\n    return base64.b64encode(value.encode('utf-8')).decode('utf-8')\ndef generate_numeric_hash(data: str) -> int:\n    \"\"\"Generates a numeric hash value for the given data.\"\"\"\n    hash_value = hash(data)\n    return abs(hash_value)\ndef generate_hash(value):\n    return hashlib.sha256(value.encode()).hexdigest()[:8]\ndef remove_spaces(text):",
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "generate_numeric_hash",
        "kind": 2,
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "peekOfCode": "def generate_numeric_hash(data: str) -> int:\n    \"\"\"Generates a numeric hash value for the given data.\"\"\"\n    hash_value = hash(data)\n    return abs(hash_value)\ndef generate_hash(value):\n    return hashlib.sha256(value.encode()).hexdigest()[:8]\ndef remove_spaces(text):\n    return re.sub(r'\\s+', ' ', text).strip()\ndef clean_string_break_line(value):\n    return remove_spaces(str(value).replace('\\n', '').replace('\\xa0', ' '))",
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "generate_hash",
        "kind": 2,
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "peekOfCode": "def generate_hash(value):\n    return hashlib.sha256(value.encode()).hexdigest()[:8]\ndef remove_spaces(text):\n    return re.sub(r'\\s+', ' ', text).strip()\ndef clean_string_break_line(value):\n    return remove_spaces(str(value).replace('\\n', '').replace('\\xa0', ' '))\ndef clean_text(text: str, clean_spaces: bool = False, remove_final_s: bool = False, \n               remove_break_line: bool = True, remove_accents: bool = True, \n               add_space_first: bool = False) -> Optional[str]:\n    \"\"\"Cleans and formats text based on the provided parameters.\"\"\"",
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "remove_spaces",
        "kind": 2,
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "peekOfCode": "def remove_spaces(text):\n    return re.sub(r'\\s+', ' ', text).strip()\ndef clean_string_break_line(value):\n    return remove_spaces(str(value).replace('\\n', '').replace('\\xa0', ' '))\ndef clean_text(text: str, clean_spaces: bool = False, remove_final_s: bool = False, \n               remove_break_line: bool = True, remove_accents: bool = True, \n               add_space_first: bool = False) -> Optional[str]:\n    \"\"\"Cleans and formats text based on the provided parameters.\"\"\"\n    if not isinstance(text, str):\n        return None",
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "clean_string_break_line",
        "kind": 2,
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "peekOfCode": "def clean_string_break_line(value):\n    return remove_spaces(str(value).replace('\\n', '').replace('\\xa0', ' '))\ndef clean_text(text: str, clean_spaces: bool = False, remove_final_s: bool = False, \n               remove_break_line: bool = True, remove_accents: bool = True, \n               add_space_first: bool = False) -> Optional[str]:\n    \"\"\"Cleans and formats text based on the provided parameters.\"\"\"\n    if not isinstance(text, str):\n        return None\n    if remove_accents:\n        text = ''.join(c for c in unicodedata.normalize('NFKD', text) if not unicodedata.combining(c))",
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "clean_text",
        "kind": 2,
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "peekOfCode": "def clean_text(text: str, clean_spaces: bool = False, remove_final_s: bool = False, \n               remove_break_line: bool = True, remove_accents: bool = True, \n               add_space_first: bool = False) -> Optional[str]:\n    \"\"\"Cleans and formats text based on the provided parameters.\"\"\"\n    if not isinstance(text, str):\n        return None\n    if remove_accents:\n        text = ''.join(c for c in unicodedata.normalize('NFKD', text) if not unicodedata.combining(c))\n    text = re.sub(r'[^\\w\\s]', ' ', text)\n    if remove_break_line:",
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "find_in_text_with_wordlist",
        "kind": 2,
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "peekOfCode": "def find_in_text_with_wordlist(text, wordlist):\n    match = None\n    for word in wordlist:\n        clean_word = clean_text(word)\n        text = clean_text(text)\n        match = re.search(clean_word, clean_text(text))  # Expresso regular para encontrar dgitos\n        if match:\n            break\n    if match:\n        return True",
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "DATE_FORMAT",
        "kind": 5,
        "importPath": "src.lib.utils.text_functions",
        "description": "src.lib.utils.text_functions",
        "peekOfCode": "DATE_FORMAT = \"%Y-%m-%d\"\ndef find_in_text_with_wordlist(text, wordlist):\n    match = None\n    for word in wordlist:\n        clean_word = clean_text(word)\n        text = clean_text(text)\n        match = re.search(clean_word, clean_text(text))  # Expresso regular para encontrar dgitos\n        if match:\n            break\n    if match:",
        "detail": "src.lib.utils.text_functions",
        "documentation": {}
    },
    {
        "label": "check_url_existence",
        "kind": 2,
        "importPath": "src.lib.utils.web_functions",
        "description": "src.lib.utils.web_functions",
        "peekOfCode": "def check_url_existence(url, timeout=5):\n    ua = UserAgent()\n    headers = {'User-Agent': ua.random}\n    try:\n        # Primeiro, tenta com o mtodo HEAD\n        response = requests.head(url, headers=headers, timeout=timeout)\n        if response.status_code == 405:  # Mtodo no permitido\n            # Tenta com GET se HEAD no for permitido\n            response = requests.get(url, headers=headers, timeout=timeout)\n        return 200 <= response.status_code < 400  # Inclui redirecionamentos",
        "detail": "src.lib.utils.web_functions",
        "documentation": {}
    },
    {
        "label": "get_dictionary",
        "kind": 2,
        "importPath": "src.lib.wordlist.brazil.dictionary",
        "description": "src.lib.wordlist.brazil.dictionary",
        "peekOfCode": "def get_dictionary(local):\n    conjugacoes = np.genfromtxt(f'{local}/src/lib/wordlist/brazil/conjugacoes.txt', dtype=str)\n    dicionario = np.genfromtxt(f'{local}/src/lib/wordlist/brazil/palavras.txt', dtype=str)\n    personal_pronouns = [\"Eu\", \"Tu\", \"Ele\", \"Ela\", \"Ns\", \"Vs\", \"Eles\", \"Elas\", \"Mim\", \"Ti\", \"Si\", \"Consigo\"]\n    oblique_pronouns = [\"Me\", \"Te\", \"Se\", \"Nos\", \"Vos\", \"O\", \"A\", \"Lhe\", \"Os\", \"As\", \"Nos\", \"Vos\", \"Se\", \"Convosco\", \"Lhes\", \"Contigo\"]\n    demonstrative_pronouns = [\"Este\", \"Esse\", \"Aquele\", \"Esta\", \"Essa\", \"Aquela\", \"Isto\", \"Isso\", \"Aquilo\", \"Estes\", \"Esses\", \"Aqueles\", \"Estas\", \"Essas\", \"Aquelas\", \"Iste\"]\n    possessive_pronouns = [\"Meu\", \"Teu\", \"Seu\", \"Nosso\", \"Vosso\", \"Seu\", \"Minha\", \"Tua\", \"Sua\", \"Nossa\", \"Vossa\", \"Sua\", \"Meus\", \"Teus\", \"Seus\", \"Nossos\", \"Vossos\", \"Minhas\", \"Tuas\", \"Suas\", \"Nossas\", \"Vossas\"]\n    indefinite_pronouns = [\"Algum\", \"Ningum\", \"Todo\", \"Algum\", \"Nenhum\", \"Outro\", \"Muito\", \"Pouco\", \"Tanto\", \"Cada\", \"Algo\", \"Tudo\", \"Nada\", \"Cada um\", \"Qualquer\", \"Poucos\", \"Muitos\", \"Vrios\", \"Outrem\"]\n    relative_pronouns = [\"Que\", \"Qual\", \"Quem\", \"Onde\", \"Cujo\", \"O qual\", \"Cuja\", \"Quanto\"]\n    interrogative_pronouns = [\"Quem\", \"O que\", \"Qual\", \"Quanto\", \"Onde\", \"Quando\", \"Como\", \"Por que\", \"Qualquer coisa\", \"Quanto a\"]",
        "detail": "src.lib.wordlist.brazil.dictionary",
        "documentation": {}
    },
    {
        "label": "get_synonyms",
        "kind": 2,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "def get_synonyms(component_list):\n    keywords_list = []\n    for component, attributes in component_list.items():\n        keywords_list.append(attributes.get(\"subject\"))\n    return keywords_list\ndef get_word_index_in_text(word, text, add_space_firts):\n    text_temp = deepcopy(text)\n    word_clean = clean_text(word, False, False, False, True, False)\n    space = \" \" if not add_space_firts else \"\"\n    matches = re.finditer(space + word_clean, text_temp)",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "get_word_index_in_text",
        "kind": 2,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "def get_word_index_in_text(word, text, add_space_firts):\n    text_temp = deepcopy(text)\n    word_clean = clean_text(word, False, False, False, True, False)\n    space = \" \" if not add_space_firts else \"\"\n    matches = re.finditer(space + word_clean, text_temp)\n    locations = []\n    for match in matches:\n        start_index = match.start()\n        locations.append(start_index)\n    return locations",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "get_back_words",
        "kind": 2,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "def get_back_words(text_accents, locations):\n    size_max = 30\n    slice_min = lambda value: value if value >= 0 else 0\n    back_words = []\n    for location in locations:\n        start = slice_min(location - size_max)\n        back_words_aux = (text_accents[start:location].replace(\"\\n\", \"\"))\n        back_words_aux = [i for i in back_words_aux.split(\" \") if i != '']\n        back_words.append(back_words_aux)\n    return back_words",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "find_subject_in_wordlist",
        "kind": 2,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "def find_subject_in_wordlist(word, wordlist):\n    for values in wordlist.values():\n        subject = values['subject']\n        if (word in subject):\n            return subject\ndef remove_prepositions_pronouns(text, pronouns):\n    pronouns = set(pronouns)\n    for pronoun in pronouns:\n        space_pronoun = \" \" * len(pronoun)\n        text = text.replace(pronoun, space_pronoun)",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "remove_prepositions_pronouns",
        "kind": 2,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "def remove_prepositions_pronouns(text, pronouns):\n    pronouns = set(pronouns)\n    for pronoun in pronouns:\n        space_pronoun = \" \" * len(pronoun)\n        text = text.replace(pronoun, space_pronoun)\n    return text\nBLACK_LIST = [\n    \"regata\",\n    \"camiseta\",\n    \"coqueteleira\",",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "BLACK_LIST",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "BLACK_LIST = [\n    \"regata\",\n    \"camiseta\",\n    \"coqueteleira\",\n    \"mochila\",\n    \"garraf\",\n    \"bone\",\n    \"marmita\",\n    \"marmiteira\",\n    \"galao\",",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "SUPPLEMENT_COMPONENT_LIST",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "SUPPLEMENT_COMPONENT_LIST = {\n    \"nac\": {\n        \"subject\": [\n            \"acetil\",\n            \"nacetil\",\n            \"n acetil\",\n            \"cisteina\",\n            \"l cisteina\",\n            \"lcisteina\",\n            \"nac\",",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "COLLECTION",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "COLLECTION = {\n    'brazil': [\n        \"promocao\",\n        \"whey\",\n        \"creatina\",\n        \"barrinha\",\n        \"pretreino\",\n    ]\n}\npersonal_pronouns = [\"Eu\", \"Tu\", \"Ele\", \"Ela\", \"Ns\", \"Vs\", \"Eles\", \"Elas\", \"Mim\", \"Ti\", \"Si\", \"Consigo\"]",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "personal_pronouns",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "personal_pronouns = [\"Eu\", \"Tu\", \"Ele\", \"Ela\", \"Ns\", \"Vs\", \"Eles\", \"Elas\", \"Mim\", \"Ti\", \"Si\", \"Consigo\"]\noblique_pronouns = [\"Me\", \"Te\", \"Se\", \"Nos\", \"Vos\", \"O\", \"A\", \"Lhe\", \"Os\", \"As\", \"Nos\", \"Vos\", \"Se\", \"Convosco\", \"Lhes\", \"Contigo\"]\ndemonstrative_pronouns = [\"Este\", \"Esse\", \"Aquele\", \"Esta\", \"Essa\", \"Aquela\", \"Isto\", \"Isso\", \"Aquilo\", \"Estes\", \"Esses\", \"Aqueles\", \"Estas\", \"Essas\", \"Aquelas\", \"Iste\"]\npossessive_pronouns = [\"Meu\", \"Teu\", \"Seu\", \"Nosso\", \"Vosso\", \"Seu\", \"Minha\", \"Tua\", \"Sua\", \"Nossa\", \"Vossa\", \"Sua\", \"Meus\", \"Teus\", \"Seus\", \"Nossos\", \"Vossos\", \"Minhas\", \"Tuas\", \"Suas\", \"Nossas\", \"Vossas\"]\nindefinite_pronouns = [\"Algum\", \"Ningum\", \"Todo\", \"Algum\", \"Nenhum\", \"Outro\", \"Muito\", \"Pouco\", \"Tanto\", \"Cada\", \"Algo\", \"Tudo\", \"Nada\", \"Cada um\", \"Qualquer\", \"Poucos\", \"Muitos\", \"Vrios\", \"Outrem\"]\nrelative_pronouns = [\"Que\", \"Qual\", \"Quem\", \"Onde\", \"Cujo\", \"O qual\", \"Cuja\", \"Quanto\"]\ninterrogative_pronouns = [\"Quem\", \"O que\", \"Qual\", \"Quanto\", \"Onde\", \"Quando\", \"Como\", \"Por que\", \"Qualquer coisa\", \"Quanto a\"]\nprepositions = [\"A\", \"Ante\", \"At\", \"Aps\", \"Com\", \"Contra\", \"De\", \"Desde\", \"Em\", \"Entre\", \"Para\", \"Por\", \"Perante\", \"Sem\", \"Sob\", \"Sobre\", \"Trs\", \"Conforme\", \"Contudo\", \"Durante\", \"Exceto\", \"Mediant\", \"Menos\", \"Salvo\", \"Segundo\", \"Visto\"]\nBRAZIL_PRONOUNS = personal_pronouns + oblique_pronouns + demonstrative_pronouns + possessive_pronouns + indefinite_pronouns + relative_pronouns + interrogative_pronouns + prepositions\nBRAZIL_CONECTORES = ['a', 'o', 'e', 'ou', 'nem', 'mas', 'porque', 'como', 'apesar', 'alm', 'entretanto', 'porm', 'todavia', 'logo', 'portanto', 'assim', 'contudo', 'embora', 'ainda', 'tambm', 'quer', 'seja', 'isto', 'aquilo']",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "oblique_pronouns",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "oblique_pronouns = [\"Me\", \"Te\", \"Se\", \"Nos\", \"Vos\", \"O\", \"A\", \"Lhe\", \"Os\", \"As\", \"Nos\", \"Vos\", \"Se\", \"Convosco\", \"Lhes\", \"Contigo\"]\ndemonstrative_pronouns = [\"Este\", \"Esse\", \"Aquele\", \"Esta\", \"Essa\", \"Aquela\", \"Isto\", \"Isso\", \"Aquilo\", \"Estes\", \"Esses\", \"Aqueles\", \"Estas\", \"Essas\", \"Aquelas\", \"Iste\"]\npossessive_pronouns = [\"Meu\", \"Teu\", \"Seu\", \"Nosso\", \"Vosso\", \"Seu\", \"Minha\", \"Tua\", \"Sua\", \"Nossa\", \"Vossa\", \"Sua\", \"Meus\", \"Teus\", \"Seus\", \"Nossos\", \"Vossos\", \"Minhas\", \"Tuas\", \"Suas\", \"Nossas\", \"Vossas\"]\nindefinite_pronouns = [\"Algum\", \"Ningum\", \"Todo\", \"Algum\", \"Nenhum\", \"Outro\", \"Muito\", \"Pouco\", \"Tanto\", \"Cada\", \"Algo\", \"Tudo\", \"Nada\", \"Cada um\", \"Qualquer\", \"Poucos\", \"Muitos\", \"Vrios\", \"Outrem\"]\nrelative_pronouns = [\"Que\", \"Qual\", \"Quem\", \"Onde\", \"Cujo\", \"O qual\", \"Cuja\", \"Quanto\"]\ninterrogative_pronouns = [\"Quem\", \"O que\", \"Qual\", \"Quanto\", \"Onde\", \"Quando\", \"Como\", \"Por que\", \"Qualquer coisa\", \"Quanto a\"]\nprepositions = [\"A\", \"Ante\", \"At\", \"Aps\", \"Com\", \"Contra\", \"De\", \"Desde\", \"Em\", \"Entre\", \"Para\", \"Por\", \"Perante\", \"Sem\", \"Sob\", \"Sobre\", \"Trs\", \"Conforme\", \"Contudo\", \"Durante\", \"Exceto\", \"Mediant\", \"Menos\", \"Salvo\", \"Segundo\", \"Visto\"]\nBRAZIL_PRONOUNS = personal_pronouns + oblique_pronouns + demonstrative_pronouns + possessive_pronouns + indefinite_pronouns + relative_pronouns + interrogative_pronouns + prepositions\nBRAZIL_CONECTORES = ['a', 'o', 'e', 'ou', 'nem', 'mas', 'porque', 'como', 'apesar', 'alm', 'entretanto', 'porm', 'todavia', 'logo', 'portanto', 'assim', 'contudo', 'embora', 'ainda', 'tambm', 'quer', 'seja', 'isto', 'aquilo']\nPRONOUNS = {",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "demonstrative_pronouns",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "demonstrative_pronouns = [\"Este\", \"Esse\", \"Aquele\", \"Esta\", \"Essa\", \"Aquela\", \"Isto\", \"Isso\", \"Aquilo\", \"Estes\", \"Esses\", \"Aqueles\", \"Estas\", \"Essas\", \"Aquelas\", \"Iste\"]\npossessive_pronouns = [\"Meu\", \"Teu\", \"Seu\", \"Nosso\", \"Vosso\", \"Seu\", \"Minha\", \"Tua\", \"Sua\", \"Nossa\", \"Vossa\", \"Sua\", \"Meus\", \"Teus\", \"Seus\", \"Nossos\", \"Vossos\", \"Minhas\", \"Tuas\", \"Suas\", \"Nossas\", \"Vossas\"]\nindefinite_pronouns = [\"Algum\", \"Ningum\", \"Todo\", \"Algum\", \"Nenhum\", \"Outro\", \"Muito\", \"Pouco\", \"Tanto\", \"Cada\", \"Algo\", \"Tudo\", \"Nada\", \"Cada um\", \"Qualquer\", \"Poucos\", \"Muitos\", \"Vrios\", \"Outrem\"]\nrelative_pronouns = [\"Que\", \"Qual\", \"Quem\", \"Onde\", \"Cujo\", \"O qual\", \"Cuja\", \"Quanto\"]\ninterrogative_pronouns = [\"Quem\", \"O que\", \"Qual\", \"Quanto\", \"Onde\", \"Quando\", \"Como\", \"Por que\", \"Qualquer coisa\", \"Quanto a\"]\nprepositions = [\"A\", \"Ante\", \"At\", \"Aps\", \"Com\", \"Contra\", \"De\", \"Desde\", \"Em\", \"Entre\", \"Para\", \"Por\", \"Perante\", \"Sem\", \"Sob\", \"Sobre\", \"Trs\", \"Conforme\", \"Contudo\", \"Durante\", \"Exceto\", \"Mediant\", \"Menos\", \"Salvo\", \"Segundo\", \"Visto\"]\nBRAZIL_PRONOUNS = personal_pronouns + oblique_pronouns + demonstrative_pronouns + possessive_pronouns + indefinite_pronouns + relative_pronouns + interrogative_pronouns + prepositions\nBRAZIL_CONECTORES = ['a', 'o', 'e', 'ou', 'nem', 'mas', 'porque', 'como', 'apesar', 'alm', 'entretanto', 'porm', 'todavia', 'logo', 'portanto', 'assim', 'contudo', 'embora', 'ainda', 'tambm', 'quer', 'seja', 'isto', 'aquilo']\nPRONOUNS = {\n    \"brazil\": BRAZIL_PRONOUNS,",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "possessive_pronouns",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "possessive_pronouns = [\"Meu\", \"Teu\", \"Seu\", \"Nosso\", \"Vosso\", \"Seu\", \"Minha\", \"Tua\", \"Sua\", \"Nossa\", \"Vossa\", \"Sua\", \"Meus\", \"Teus\", \"Seus\", \"Nossos\", \"Vossos\", \"Minhas\", \"Tuas\", \"Suas\", \"Nossas\", \"Vossas\"]\nindefinite_pronouns = [\"Algum\", \"Ningum\", \"Todo\", \"Algum\", \"Nenhum\", \"Outro\", \"Muito\", \"Pouco\", \"Tanto\", \"Cada\", \"Algo\", \"Tudo\", \"Nada\", \"Cada um\", \"Qualquer\", \"Poucos\", \"Muitos\", \"Vrios\", \"Outrem\"]\nrelative_pronouns = [\"Que\", \"Qual\", \"Quem\", \"Onde\", \"Cujo\", \"O qual\", \"Cuja\", \"Quanto\"]\ninterrogative_pronouns = [\"Quem\", \"O que\", \"Qual\", \"Quanto\", \"Onde\", \"Quando\", \"Como\", \"Por que\", \"Qualquer coisa\", \"Quanto a\"]\nprepositions = [\"A\", \"Ante\", \"At\", \"Aps\", \"Com\", \"Contra\", \"De\", \"Desde\", \"Em\", \"Entre\", \"Para\", \"Por\", \"Perante\", \"Sem\", \"Sob\", \"Sobre\", \"Trs\", \"Conforme\", \"Contudo\", \"Durante\", \"Exceto\", \"Mediant\", \"Menos\", \"Salvo\", \"Segundo\", \"Visto\"]\nBRAZIL_PRONOUNS = personal_pronouns + oblique_pronouns + demonstrative_pronouns + possessive_pronouns + indefinite_pronouns + relative_pronouns + interrogative_pronouns + prepositions\nBRAZIL_CONECTORES = ['a', 'o', 'e', 'ou', 'nem', 'mas', 'porque', 'como', 'apesar', 'alm', 'entretanto', 'porm', 'todavia', 'logo', 'portanto', 'assim', 'contudo', 'embora', 'ainda', 'tambm', 'quer', 'seja', 'isto', 'aquilo']\nPRONOUNS = {\n    \"brazil\": BRAZIL_PRONOUNS,\n}",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "indefinite_pronouns",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "indefinite_pronouns = [\"Algum\", \"Ningum\", \"Todo\", \"Algum\", \"Nenhum\", \"Outro\", \"Muito\", \"Pouco\", \"Tanto\", \"Cada\", \"Algo\", \"Tudo\", \"Nada\", \"Cada um\", \"Qualquer\", \"Poucos\", \"Muitos\", \"Vrios\", \"Outrem\"]\nrelative_pronouns = [\"Que\", \"Qual\", \"Quem\", \"Onde\", \"Cujo\", \"O qual\", \"Cuja\", \"Quanto\"]\ninterrogative_pronouns = [\"Quem\", \"O que\", \"Qual\", \"Quanto\", \"Onde\", \"Quando\", \"Como\", \"Por que\", \"Qualquer coisa\", \"Quanto a\"]\nprepositions = [\"A\", \"Ante\", \"At\", \"Aps\", \"Com\", \"Contra\", \"De\", \"Desde\", \"Em\", \"Entre\", \"Para\", \"Por\", \"Perante\", \"Sem\", \"Sob\", \"Sobre\", \"Trs\", \"Conforme\", \"Contudo\", \"Durante\", \"Exceto\", \"Mediant\", \"Menos\", \"Salvo\", \"Segundo\", \"Visto\"]\nBRAZIL_PRONOUNS = personal_pronouns + oblique_pronouns + demonstrative_pronouns + possessive_pronouns + indefinite_pronouns + relative_pronouns + interrogative_pronouns + prepositions\nBRAZIL_CONECTORES = ['a', 'o', 'e', 'ou', 'nem', 'mas', 'porque', 'como', 'apesar', 'alm', 'entretanto', 'porm', 'todavia', 'logo', 'portanto', 'assim', 'contudo', 'embora', 'ainda', 'tambm', 'quer', 'seja', 'isto', 'aquilo']\nPRONOUNS = {\n    \"brazil\": BRAZIL_PRONOUNS,\n}\nWORDLIST = {",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "relative_pronouns",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "relative_pronouns = [\"Que\", \"Qual\", \"Quem\", \"Onde\", \"Cujo\", \"O qual\", \"Cuja\", \"Quanto\"]\ninterrogative_pronouns = [\"Quem\", \"O que\", \"Qual\", \"Quanto\", \"Onde\", \"Quando\", \"Como\", \"Por que\", \"Qualquer coisa\", \"Quanto a\"]\nprepositions = [\"A\", \"Ante\", \"At\", \"Aps\", \"Com\", \"Contra\", \"De\", \"Desde\", \"Em\", \"Entre\", \"Para\", \"Por\", \"Perante\", \"Sem\", \"Sob\", \"Sobre\", \"Trs\", \"Conforme\", \"Contudo\", \"Durante\", \"Exceto\", \"Mediant\", \"Menos\", \"Salvo\", \"Segundo\", \"Visto\"]\nBRAZIL_PRONOUNS = personal_pronouns + oblique_pronouns + demonstrative_pronouns + possessive_pronouns + indefinite_pronouns + relative_pronouns + interrogative_pronouns + prepositions\nBRAZIL_CONECTORES = ['a', 'o', 'e', 'ou', 'nem', 'mas', 'porque', 'como', 'apesar', 'alm', 'entretanto', 'porm', 'todavia', 'logo', 'portanto', 'assim', 'contudo', 'embora', 'ainda', 'tambm', 'quer', 'seja', 'isto', 'aquilo']\nPRONOUNS = {\n    \"brazil\": BRAZIL_PRONOUNS,\n}\nWORDLIST = {\n    \"supplement\": SUPPLEMENT_COMPONENT_LIST,",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "interrogative_pronouns",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "interrogative_pronouns = [\"Quem\", \"O que\", \"Qual\", \"Quanto\", \"Onde\", \"Quando\", \"Como\", \"Por que\", \"Qualquer coisa\", \"Quanto a\"]\nprepositions = [\"A\", \"Ante\", \"At\", \"Aps\", \"Com\", \"Contra\", \"De\", \"Desde\", \"Em\", \"Entre\", \"Para\", \"Por\", \"Perante\", \"Sem\", \"Sob\", \"Sobre\", \"Trs\", \"Conforme\", \"Contudo\", \"Durante\", \"Exceto\", \"Mediant\", \"Menos\", \"Salvo\", \"Segundo\", \"Visto\"]\nBRAZIL_PRONOUNS = personal_pronouns + oblique_pronouns + demonstrative_pronouns + possessive_pronouns + indefinite_pronouns + relative_pronouns + interrogative_pronouns + prepositions\nBRAZIL_CONECTORES = ['a', 'o', 'e', 'ou', 'nem', 'mas', 'porque', 'como', 'apesar', 'alm', 'entretanto', 'porm', 'todavia', 'logo', 'portanto', 'assim', 'contudo', 'embora', 'ainda', 'tambm', 'quer', 'seja', 'isto', 'aquilo']\nPRONOUNS = {\n    \"brazil\": BRAZIL_PRONOUNS,\n}\nWORDLIST = {\n    \"supplement\": SUPPLEMENT_COMPONENT_LIST,\n}",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "prepositions",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "prepositions = [\"A\", \"Ante\", \"At\", \"Aps\", \"Com\", \"Contra\", \"De\", \"Desde\", \"Em\", \"Entre\", \"Para\", \"Por\", \"Perante\", \"Sem\", \"Sob\", \"Sobre\", \"Trs\", \"Conforme\", \"Contudo\", \"Durante\", \"Exceto\", \"Mediant\", \"Menos\", \"Salvo\", \"Segundo\", \"Visto\"]\nBRAZIL_PRONOUNS = personal_pronouns + oblique_pronouns + demonstrative_pronouns + possessive_pronouns + indefinite_pronouns + relative_pronouns + interrogative_pronouns + prepositions\nBRAZIL_CONECTORES = ['a', 'o', 'e', 'ou', 'nem', 'mas', 'porque', 'como', 'apesar', 'alm', 'entretanto', 'porm', 'todavia', 'logo', 'portanto', 'assim', 'contudo', 'embora', 'ainda', 'tambm', 'quer', 'seja', 'isto', 'aquilo']\nPRONOUNS = {\n    \"brazil\": BRAZIL_PRONOUNS,\n}\nWORDLIST = {\n    \"supplement\": SUPPLEMENT_COMPONENT_LIST,\n}",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "BRAZIL_PRONOUNS",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "BRAZIL_PRONOUNS = personal_pronouns + oblique_pronouns + demonstrative_pronouns + possessive_pronouns + indefinite_pronouns + relative_pronouns + interrogative_pronouns + prepositions\nBRAZIL_CONECTORES = ['a', 'o', 'e', 'ou', 'nem', 'mas', 'porque', 'como', 'apesar', 'alm', 'entretanto', 'porm', 'todavia', 'logo', 'portanto', 'assim', 'contudo', 'embora', 'ainda', 'tambm', 'quer', 'seja', 'isto', 'aquilo']\nPRONOUNS = {\n    \"brazil\": BRAZIL_PRONOUNS,\n}\nWORDLIST = {\n    \"supplement\": SUPPLEMENT_COMPONENT_LIST,\n}",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "BRAZIL_CONECTORES",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "BRAZIL_CONECTORES = ['a', 'o', 'e', 'ou', 'nem', 'mas', 'porque', 'como', 'apesar', 'alm', 'entretanto', 'porm', 'todavia', 'logo', 'portanto', 'assim', 'contudo', 'embora', 'ainda', 'tambm', 'quer', 'seja', 'isto', 'aquilo']\nPRONOUNS = {\n    \"brazil\": BRAZIL_PRONOUNS,\n}\nWORDLIST = {\n    \"supplement\": SUPPLEMENT_COMPONENT_LIST,\n}",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "PRONOUNS",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "PRONOUNS = {\n    \"brazil\": BRAZIL_PRONOUNS,\n}\nWORDLIST = {\n    \"supplement\": SUPPLEMENT_COMPONENT_LIST,\n}",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "WORDLIST",
        "kind": 5,
        "importPath": "src.lib.wordlist.wordlist",
        "description": "src.lib.wordlist.wordlist",
        "peekOfCode": "WORDLIST = {\n    \"supplement\": SUPPLEMENT_COMPONENT_LIST,\n}",
        "detail": "src.lib.wordlist.wordlist",
        "documentation": {}
    },
    {
        "label": "find_similar_images",
        "kind": 2,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "def find_similar_images(userpaths, hashfunc=imagehash.average_hash):\n\tdef is_image(filename):\n\t\tf = filename.lower()\n\t\treturn f.endswith('.png') or f.endswith('.jpg') or \\\n\t\t\tf.endswith('.jpeg') or f.endswith('.bmp') or \\\n\t\t\tf.endswith('.gif') or '.jpg' in f or f.endswith('.svg')\n\timage_filenames = []\n\tfor userpath in userpaths:\n\t\timage_filenames += [os.path.join(userpath, path) for path in os.listdir(userpath) if is_image(path)]\n\timages = {}",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\t\tf",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\t\tf = filename.lower()\n\t\treturn f.endswith('.png') or f.endswith('.jpg') or \\\n\t\t\tf.endswith('.jpeg') or f.endswith('.bmp') or \\\n\t\t\tf.endswith('.gif') or '.jpg' in f or f.endswith('.svg')\n\timage_filenames = []\n\tfor userpath in userpaths:\n\t\timage_filenames += [os.path.join(userpath, path) for path in os.listdir(userpath) if is_image(path)]\n\timages = {}\n\tfor img in sorted(image_filenames):\n\t\ttry:",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\timage_filenames",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\timage_filenames = []\n\tfor userpath in userpaths:\n\t\timage_filenames += [os.path.join(userpath, path) for path in os.listdir(userpath) if is_image(path)]\n\timages = {}\n\tfor img in sorted(image_filenames):\n\t\ttry:\n\t\t\thash = hashfunc(Image.open(img))\n\t\texcept Exception as e:\n\t\t\tprint('Problem:', e, 'with', img)\n\t\t\tcontinue",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\timages",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\timages = {}\n\tfor img in sorted(image_filenames):\n\t\ttry:\n\t\t\thash = hashfunc(Image.open(img))\n\t\texcept Exception as e:\n\t\t\tprint('Problem:', e, 'with', img)\n\t\t\tcontinue\n\t\tif hash in images:\n\t\t\tprint(img, '  already exists as', ' '.join(images[hash]))\n\t\t\tif 'dupPictures' in img:",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\t\t\thash",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\t\t\thash = hashfunc(Image.open(img))\n\t\texcept Exception as e:\n\t\t\tprint('Problem:', e, 'with', img)\n\t\t\tcontinue\n\t\tif hash in images:\n\t\t\tprint(img, '  already exists as', ' '.join(images[hash]))\n\t\t\tif 'dupPictures' in img:\n\t\t\t\tprint('rm -v', img)\n\t\timages[hash] = images.get(hash, []) + [img]\n\t# for k, img_list in six.iteritems(images):",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\t\timages[hash]",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\t\timages[hash] = images.get(hash, []) + [img]\n\t# for k, img_list in six.iteritems(images):\n\t# \tif len(img_list) > 1:\n\t# \t\tprint(\" \".join(img_list))\nif __name__ == '__main__':  # noqa: C901\n\timport os\n\timport sys\n\tdef usage():\n\t\tsys.stderr.write(\"\"\"SYNOPSIS: %s [ahash|phash|dhash|...] [<directory>]\nIdentifies similar images in the directory.",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\thashmethod",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\thashmethod = sys.argv[1] if len(sys.argv) > 1 else usage()\n\tif hashmethod == 'ahash':\n\t\thashfunc = imagehash.average_hash\n\telif hashmethod == 'phash':\n\t\thashfunc = imagehash.phash\n\telif hashmethod == 'dhash':\n\t\thashfunc = imagehash.dhash\n\telif hashmethod == 'whash-haar':\n\t\thashfunc = imagehash.whash\n\telif hashmethod == 'whash-db4':",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\t\thashfunc",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\t\thashfunc = imagehash.average_hash\n\telif hashmethod == 'phash':\n\t\thashfunc = imagehash.phash\n\telif hashmethod == 'dhash':\n\t\thashfunc = imagehash.dhash\n\telif hashmethod == 'whash-haar':\n\t\thashfunc = imagehash.whash\n\telif hashmethod == 'whash-db4':\n\t\tdef hashfunc(img):\n\t\t\treturn imagehash.whash(img, mode='db4')",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\t\thashfunc",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\t\thashfunc = imagehash.phash\n\telif hashmethod == 'dhash':\n\t\thashfunc = imagehash.dhash\n\telif hashmethod == 'whash-haar':\n\t\thashfunc = imagehash.whash\n\telif hashmethod == 'whash-db4':\n\t\tdef hashfunc(img):\n\t\t\treturn imagehash.whash(img, mode='db4')\n\telif hashmethod == 'colorhash':\n\t\thashfunc = imagehash.colorhash",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\t\thashfunc",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\t\thashfunc = imagehash.dhash\n\telif hashmethod == 'whash-haar':\n\t\thashfunc = imagehash.whash\n\telif hashmethod == 'whash-db4':\n\t\tdef hashfunc(img):\n\t\t\treturn imagehash.whash(img, mode='db4')\n\telif hashmethod == 'colorhash':\n\t\thashfunc = imagehash.colorhash\n\telif hashmethod == 'crop-resistant':\n\t\thashfunc = imagehash.crop_resistant_hash",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\t\thashfunc",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\t\thashfunc = imagehash.whash\n\telif hashmethod == 'whash-db4':\n\t\tdef hashfunc(img):\n\t\t\treturn imagehash.whash(img, mode='db4')\n\telif hashmethod == 'colorhash':\n\t\thashfunc = imagehash.colorhash\n\telif hashmethod == 'crop-resistant':\n\t\thashfunc = imagehash.crop_resistant_hash\n\telse:\n\t\tusage()",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\t\thashfunc",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\t\thashfunc = imagehash.colorhash\n\telif hashmethod == 'crop-resistant':\n\t\thashfunc = imagehash.crop_resistant_hash\n\telse:\n\t\tusage()\n\tuserpaths = sys.argv[2:] if len(sys.argv) > 2 else '.'\n\tfind_similar_images(userpaths=userpaths, hashfunc=hashfunc)",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\t\thashfunc",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\t\thashfunc = imagehash.crop_resistant_hash\n\telse:\n\t\tusage()\n\tuserpaths = sys.argv[2:] if len(sys.argv) > 2 else '.'\n\tfind_similar_images(userpaths=userpaths, hashfunc=hashfunc)",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "\tuserpaths",
        "kind": 5,
        "importPath": "venv.bin.find_similar_images",
        "description": "venv.bin.find_similar_images",
        "peekOfCode": "\tuserpaths = sys.argv[2:] if len(sys.argv) > 2 else '.'\n\tfind_similar_images(userpaths=userpaths, hashfunc=hashfunc)",
        "detail": "venv.bin.find_similar_images",
        "documentation": {}
    },
    {
        "label": "parse_arguments",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def parse_arguments():\n    \"\"\"\n    Configura e retorna os argumentos da linha de comando.\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"Processa os argumentos do trabalho.\")\n    parser.add_argument(\"--job_type\", type=str, help=\"\")\n    parser.add_argument(\"--job_name\", type=str, help=\"Nome do trabalho a ser executado.\")\n    parser.add_argument(\"--page_name\", type=str, help=\"Nome da pgina.\")\n    parser.add_argument(\"--exec_type\", type=str, required=True, choices=[\"extract\", \"transform\", \"load\", \"false\"], help=\"Tipo de trabalho.\")\n    parser.add_argument(\"--exec_flag\", type=str, default=\"\", help=\"Opes adicionais.\")",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "configure_system",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def configure_system(args):\n    \"\"\"\n    Configura o sistema com base nos argumentos fornecidos.\n    \"\"\"\n    message(\"CONFIGURE SYSTEM\")\n    # Configuraes especficas para tipos de trabalho\n    if args.exec_type in [\"extract\", \"transform\"]:\n        configure_display()\n    # Configura o servidor de imagens\n    configure_image_server()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "run_job",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def run_job(args):\n    \"\"\"\n    Importa dinamicamente e executa o mdulo de trabalho especificado.\n    Mostra o caminho completo e a stack trace em caso de erro.\n    \"\"\"\n    try:\n        # Define o caminho do mdulo do job\n        module_path = f\"src.jobs.{args.job_type}.{args.job_name}.job\"\n        # Importa o mdulo dinamicamente\n        job_module = importlib.import_module(module_path)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def main():\n    message(\"START SYSTEM\")\n    # Analisa os argumentos da linha de comando\n    args = parse_arguments()\n    print(args)\n    # Executa o job\n    run_job(args)\nif __name__ == \"__main__\":\n    main()",
        "detail": "main",
        "documentation": {}
    }
]